{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584393ad",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8950ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from gcn.models import GCN\n",
    "from gcn.utils import load_data, accuracy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0fff4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e6f03980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "adj, features, labels, idx_train, idx_val, idx_test, idx, idx_map = load_data(split=[0.8, 0.1, 0.1], path=\"./cora/\")\n",
    "# split dataset into train, validation and test for 8:1:1\n",
    "\n",
    "if use_cuda:\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c91bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if not fastmode:\n",
    "        # Evaluate validation set performance separately,\n",
    "        # deactivates dropout during validation run.\n",
    "        model.eval()\n",
    "        output = model(features, adj)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_train.item(), loss_val.item(), acc_train.item(), acc_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "df536dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    return acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "146f1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "lr = 1e-3  # Initial learning rate.\n",
    "weight_decay = 5e-4  # Weight decay (L2 loss on parameters).\n",
    "hidden = 16  # Number of hidden units.\n",
    "dropout = 0.5 # Dropout rate (1 - keep probability).\n",
    "epochs = 2500  # Number of epochs to train.\n",
    "fastmode = False # Validate during training pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0c447e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2880f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 1.9256 acc_train: 0.1556 loss_val: 1.9314 acc_val: 0.1513 time: 0.0107s\n",
      "Epoch: 0002 loss_train: 1.9276 acc_train: 0.1556 loss_val: 1.9300 acc_val: 0.1513 time: 0.0073s\n",
      "Epoch: 0003 loss_train: 1.9270 acc_train: 0.1556 loss_val: 1.9286 acc_val: 0.1513 time: 0.0069s\n",
      "Epoch: 0004 loss_train: 1.9233 acc_train: 0.1556 loss_val: 1.9272 acc_val: 0.1513 time: 0.0072s\n",
      "Epoch: 0005 loss_train: 1.9266 acc_train: 0.1556 loss_val: 1.9258 acc_val: 0.1513 time: 0.0075s\n",
      "Epoch: 0006 loss_train: 1.9195 acc_train: 0.1556 loss_val: 1.9244 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0007 loss_train: 1.9214 acc_train: 0.1556 loss_val: 1.9230 acc_val: 0.1513 time: 0.0067s\n",
      "Epoch: 0008 loss_train: 1.9190 acc_train: 0.1556 loss_val: 1.9216 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0009 loss_train: 1.9178 acc_train: 0.1556 loss_val: 1.9202 acc_val: 0.1513 time: 0.0069s\n",
      "Epoch: 0010 loss_train: 1.9153 acc_train: 0.1556 loss_val: 1.9188 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0011 loss_train: 1.9169 acc_train: 0.1556 loss_val: 1.9175 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0012 loss_train: 1.9151 acc_train: 0.1556 loss_val: 1.9161 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0013 loss_train: 1.9113 acc_train: 0.1556 loss_val: 1.9147 acc_val: 0.1513 time: 0.0072s\n",
      "Epoch: 0014 loss_train: 1.9121 acc_train: 0.1556 loss_val: 1.9133 acc_val: 0.1513 time: 0.0067s\n",
      "Epoch: 0015 loss_train: 1.9064 acc_train: 0.1556 loss_val: 1.9120 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0016 loss_train: 1.9092 acc_train: 0.1556 loss_val: 1.9106 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0017 loss_train: 1.9051 acc_train: 0.1556 loss_val: 1.9092 acc_val: 0.1513 time: 0.0072s\n",
      "Epoch: 0018 loss_train: 1.9095 acc_train: 0.1556 loss_val: 1.9079 acc_val: 0.1513 time: 0.0064s\n",
      "Epoch: 0019 loss_train: 1.9044 acc_train: 0.1556 loss_val: 1.9065 acc_val: 0.1513 time: 0.0068s\n",
      "Epoch: 0020 loss_train: 1.9025 acc_train: 0.1556 loss_val: 1.9052 acc_val: 0.1513 time: 0.0072s\n",
      "Epoch: 0021 loss_train: 1.9072 acc_train: 0.1551 loss_val: 1.9038 acc_val: 0.1513 time: 0.0068s\n",
      "Epoch: 0022 loss_train: 1.8998 acc_train: 0.1556 loss_val: 1.9025 acc_val: 0.1513 time: 0.0073s\n",
      "Epoch: 0023 loss_train: 1.8987 acc_train: 0.1556 loss_val: 1.9011 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0024 loss_train: 1.8987 acc_train: 0.1556 loss_val: 1.8998 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0025 loss_train: 1.9013 acc_train: 0.1556 loss_val: 1.8985 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0026 loss_train: 1.8966 acc_train: 0.1556 loss_val: 1.8972 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0027 loss_train: 1.8957 acc_train: 0.1556 loss_val: 1.8958 acc_val: 0.1513 time: 0.0065s\n",
      "Epoch: 0028 loss_train: 1.8990 acc_train: 0.1556 loss_val: 1.8945 acc_val: 0.1513 time: 0.0068s\n",
      "Epoch: 0029 loss_train: 1.8940 acc_train: 0.1556 loss_val: 1.8932 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0030 loss_train: 1.8915 acc_train: 0.1556 loss_val: 1.8919 acc_val: 0.1513 time: 0.0065s\n",
      "Epoch: 0031 loss_train: 1.8950 acc_train: 0.1556 loss_val: 1.8906 acc_val: 0.1513 time: 0.0069s\n",
      "Epoch: 0032 loss_train: 1.8913 acc_train: 0.1556 loss_val: 1.8894 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0033 loss_train: 1.8885 acc_train: 0.1560 loss_val: 1.8881 acc_val: 0.1513 time: 0.0065s\n",
      "Epoch: 0034 loss_train: 1.8896 acc_train: 0.1560 loss_val: 1.8868 acc_val: 0.1513 time: 0.0067s\n",
      "Epoch: 0035 loss_train: 1.8858 acc_train: 0.1556 loss_val: 1.8855 acc_val: 0.1513 time: 0.0068s\n",
      "Epoch: 0036 loss_train: 1.8847 acc_train: 0.1574 loss_val: 1.8842 acc_val: 0.1513 time: 0.0064s\n",
      "Epoch: 0037 loss_train: 1.8811 acc_train: 0.1574 loss_val: 1.8829 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0038 loss_train: 1.8856 acc_train: 0.1570 loss_val: 1.8816 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0039 loss_train: 1.8818 acc_train: 0.1560 loss_val: 1.8804 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0040 loss_train: 1.8825 acc_train: 0.1570 loss_val: 1.8791 acc_val: 0.1513 time: 0.0069s\n",
      "Epoch: 0041 loss_train: 1.8826 acc_train: 0.1565 loss_val: 1.8779 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0042 loss_train: 1.8780 acc_train: 0.1574 loss_val: 1.8766 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0043 loss_train: 1.8792 acc_train: 0.1602 loss_val: 1.8754 acc_val: 0.1513 time: 0.0068s\n",
      "Epoch: 0044 loss_train: 1.8745 acc_train: 0.1597 loss_val: 1.8742 acc_val: 0.1513 time: 0.0069s\n",
      "Epoch: 0045 loss_train: 1.8769 acc_train: 0.1597 loss_val: 1.8729 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0046 loss_train: 1.8741 acc_train: 0.1574 loss_val: 1.8717 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0047 loss_train: 1.8732 acc_train: 0.1611 loss_val: 1.8705 acc_val: 0.1513 time: 0.0067s\n",
      "Epoch: 0048 loss_train: 1.8720 acc_train: 0.1653 loss_val: 1.8693 acc_val: 0.1513 time: 0.0064s\n",
      "Epoch: 0049 loss_train: 1.8707 acc_train: 0.1616 loss_val: 1.8681 acc_val: 0.1513 time: 0.0068s\n",
      "Epoch: 0050 loss_train: 1.8709 acc_train: 0.1653 loss_val: 1.8669 acc_val: 0.1513 time: 0.0067s\n",
      "Epoch: 0051 loss_train: 1.8722 acc_train: 0.1648 loss_val: 1.8656 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0052 loss_train: 1.8740 acc_train: 0.1639 loss_val: 1.8644 acc_val: 0.1513 time: 0.0082s\n",
      "Epoch: 0053 loss_train: 1.8681 acc_train: 0.1796 loss_val: 1.8632 acc_val: 0.1513 time: 0.0072s\n",
      "Epoch: 0054 loss_train: 1.8641 acc_train: 0.1916 loss_val: 1.8620 acc_val: 0.1513 time: 0.0069s\n",
      "Epoch: 0055 loss_train: 1.8684 acc_train: 0.1704 loss_val: 1.8608 acc_val: 0.1513 time: 0.0070s\n",
      "Epoch: 0056 loss_train: 1.8623 acc_train: 0.1865 loss_val: 1.8596 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0057 loss_train: 1.8625 acc_train: 0.1828 loss_val: 1.8584 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0058 loss_train: 1.8671 acc_train: 0.1810 loss_val: 1.8571 acc_val: 0.1513 time: 0.0067s\n",
      "Epoch: 0059 loss_train: 1.8662 acc_train: 0.1967 loss_val: 1.8560 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0060 loss_train: 1.8614 acc_train: 0.2064 loss_val: 1.8548 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0061 loss_train: 1.8614 acc_train: 0.2165 loss_val: 1.8536 acc_val: 0.1513 time: 0.0071s\n",
      "Epoch: 0062 loss_train: 1.8626 acc_train: 0.2073 loss_val: 1.8525 acc_val: 0.1513 time: 0.0065s\n",
      "Epoch: 0063 loss_train: 1.8611 acc_train: 0.2031 loss_val: 1.8513 acc_val: 0.1513 time: 0.0066s\n",
      "Epoch: 0064 loss_train: 1.8508 acc_train: 0.2415 loss_val: 1.8501 acc_val: 0.1624 time: 0.0070s\n",
      "Epoch: 0065 loss_train: 1.8543 acc_train: 0.2387 loss_val: 1.8490 acc_val: 0.1771 time: 0.0068s\n",
      "Epoch: 0066 loss_train: 1.8551 acc_train: 0.2401 loss_val: 1.8478 acc_val: 0.1845 time: 0.0068s\n",
      "Epoch: 0067 loss_train: 1.8516 acc_train: 0.2521 loss_val: 1.8467 acc_val: 0.2030 time: 0.0067s\n",
      "Epoch: 0068 loss_train: 1.8506 acc_train: 0.2544 loss_val: 1.8455 acc_val: 0.2288 time: 0.0067s\n",
      "Epoch: 0069 loss_train: 1.8560 acc_train: 0.2345 loss_val: 1.8444 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0070 loss_train: 1.8506 acc_train: 0.2793 loss_val: 1.8432 acc_val: 0.3321 time: 0.0066s\n",
      "Epoch: 0071 loss_train: 1.8531 acc_train: 0.2608 loss_val: 1.8421 acc_val: 0.3616 time: 0.0065s\n",
      "Epoch: 0072 loss_train: 1.8536 acc_train: 0.2655 loss_val: 1.8410 acc_val: 0.3838 time: 0.0071s\n",
      "Epoch: 0073 loss_train: 1.8491 acc_train: 0.2812 loss_val: 1.8399 acc_val: 0.3985 time: 0.0072s\n",
      "Epoch: 0074 loss_train: 1.8465 acc_train: 0.3070 loss_val: 1.8388 acc_val: 0.4022 time: 0.0065s\n",
      "Epoch: 0075 loss_train: 1.8468 acc_train: 0.2793 loss_val: 1.8377 acc_val: 0.3801 time: 0.0067s\n",
      "Epoch: 0076 loss_train: 1.8430 acc_train: 0.3042 loss_val: 1.8366 acc_val: 0.3616 time: 0.0070s\n",
      "Epoch: 0077 loss_train: 1.8429 acc_train: 0.2821 loss_val: 1.8356 acc_val: 0.3579 time: 0.0078s\n",
      "Epoch: 0078 loss_train: 1.8431 acc_train: 0.2946 loss_val: 1.8345 acc_val: 0.3358 time: 0.0068s\n",
      "Epoch: 0079 loss_train: 1.8366 acc_train: 0.3061 loss_val: 1.8334 acc_val: 0.3284 time: 0.0069s\n",
      "Epoch: 0080 loss_train: 1.8475 acc_train: 0.2932 loss_val: 1.8324 acc_val: 0.3210 time: 0.0066s\n",
      "Epoch: 0081 loss_train: 1.8384 acc_train: 0.3061 loss_val: 1.8313 acc_val: 0.3173 time: 0.0069s\n",
      "Epoch: 0082 loss_train: 1.8353 acc_train: 0.3264 loss_val: 1.8303 acc_val: 0.3063 time: 0.0066s\n",
      "Epoch: 0083 loss_train: 1.8404 acc_train: 0.3130 loss_val: 1.8292 acc_val: 0.3063 time: 0.0065s\n",
      "Epoch: 0084 loss_train: 1.8359 acc_train: 0.3195 loss_val: 1.8282 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0085 loss_train: 1.8293 acc_train: 0.3195 loss_val: 1.8272 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0086 loss_train: 1.8307 acc_train: 0.2946 loss_val: 1.8261 acc_val: 0.2989 time: 0.0064s\n",
      "Epoch: 0087 loss_train: 1.8303 acc_train: 0.3139 loss_val: 1.8251 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0088 loss_train: 1.8266 acc_train: 0.3135 loss_val: 1.8241 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0089 loss_train: 1.8318 acc_train: 0.3163 loss_val: 1.8231 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0090 loss_train: 1.8331 acc_train: 0.3209 loss_val: 1.8222 acc_val: 0.2989 time: 0.0071s\n",
      "Epoch: 0091 loss_train: 1.8280 acc_train: 0.3047 loss_val: 1.8212 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0092 loss_train: 1.8255 acc_train: 0.3019 loss_val: 1.8202 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0093 loss_train: 1.8270 acc_train: 0.3139 loss_val: 1.8193 acc_val: 0.2989 time: 0.0071s\n",
      "Epoch: 0094 loss_train: 1.8306 acc_train: 0.3070 loss_val: 1.8183 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0095 loss_train: 1.8305 acc_train: 0.3066 loss_val: 1.8174 acc_val: 0.2989 time: 0.0065s\n",
      "Epoch: 0096 loss_train: 1.8260 acc_train: 0.3149 loss_val: 1.8164 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0097 loss_train: 1.8285 acc_train: 0.3052 loss_val: 1.8155 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0098 loss_train: 1.8235 acc_train: 0.3116 loss_val: 1.8146 acc_val: 0.2989 time: 0.0066s\n",
      "Epoch: 0099 loss_train: 1.8257 acc_train: 0.3056 loss_val: 1.8137 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0100 loss_train: 1.8181 acc_train: 0.2950 loss_val: 1.8128 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0101 loss_train: 1.8195 acc_train: 0.3070 loss_val: 1.8119 acc_val: 0.2989 time: 0.0068s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0102 loss_train: 1.8224 acc_train: 0.3033 loss_val: 1.8111 acc_val: 0.2989 time: 0.0073s\n",
      "Epoch: 0103 loss_train: 1.8156 acc_train: 0.3089 loss_val: 1.8102 acc_val: 0.2989 time: 0.0071s\n",
      "Epoch: 0104 loss_train: 1.8175 acc_train: 0.3029 loss_val: 1.8093 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0105 loss_train: 1.8169 acc_train: 0.3084 loss_val: 1.8084 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0106 loss_train: 1.8170 acc_train: 0.3047 loss_val: 1.8075 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0107 loss_train: 1.8137 acc_train: 0.3107 loss_val: 1.8067 acc_val: 0.2989 time: 0.0064s\n",
      "Epoch: 0108 loss_train: 1.8127 acc_train: 0.3084 loss_val: 1.8058 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0109 loss_train: 1.8141 acc_train: 0.3098 loss_val: 1.8050 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0110 loss_train: 1.8237 acc_train: 0.3015 loss_val: 1.8041 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0111 loss_train: 1.8153 acc_train: 0.3084 loss_val: 1.8033 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0112 loss_train: 1.8070 acc_train: 0.3047 loss_val: 1.8025 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0113 loss_train: 1.8050 acc_train: 0.3070 loss_val: 1.8017 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0114 loss_train: 1.8108 acc_train: 0.3010 loss_val: 1.8009 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0115 loss_train: 1.8115 acc_train: 0.3038 loss_val: 1.8001 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0116 loss_train: 1.8122 acc_train: 0.3019 loss_val: 1.7992 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0117 loss_train: 1.8028 acc_train: 0.3061 loss_val: 1.7984 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0118 loss_train: 1.8076 acc_train: 0.3107 loss_val: 1.7977 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0119 loss_train: 1.8068 acc_train: 0.3042 loss_val: 1.7969 acc_val: 0.2952 time: 0.0063s\n",
      "Epoch: 0120 loss_train: 1.8045 acc_train: 0.3015 loss_val: 1.7961 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0121 loss_train: 1.8143 acc_train: 0.3024 loss_val: 1.7953 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0122 loss_train: 1.8040 acc_train: 0.3075 loss_val: 1.7945 acc_val: 0.2952 time: 0.0064s\n",
      "Epoch: 0123 loss_train: 1.8034 acc_train: 0.3038 loss_val: 1.7938 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0124 loss_train: 1.7997 acc_train: 0.3010 loss_val: 1.7931 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0125 loss_train: 1.8044 acc_train: 0.3015 loss_val: 1.7923 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0126 loss_train: 1.8005 acc_train: 0.3052 loss_val: 1.7916 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0127 loss_train: 1.7949 acc_train: 0.3033 loss_val: 1.7908 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0128 loss_train: 1.7995 acc_train: 0.3056 loss_val: 1.7901 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0129 loss_train: 1.7935 acc_train: 0.3015 loss_val: 1.7894 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0130 loss_train: 1.7988 acc_train: 0.3024 loss_val: 1.7887 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0131 loss_train: 1.7930 acc_train: 0.3033 loss_val: 1.7879 acc_val: 0.2952 time: 0.0065s\n",
      "Epoch: 0132 loss_train: 1.7927 acc_train: 0.3033 loss_val: 1.7872 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0133 loss_train: 1.7933 acc_train: 0.3033 loss_val: 1.7865 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0134 loss_train: 1.8002 acc_train: 0.3038 loss_val: 1.7858 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0135 loss_train: 1.7967 acc_train: 0.3061 loss_val: 1.7851 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0136 loss_train: 1.7910 acc_train: 0.3047 loss_val: 1.7843 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0137 loss_train: 1.7926 acc_train: 0.3047 loss_val: 1.7836 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0138 loss_train: 1.7873 acc_train: 0.3024 loss_val: 1.7829 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0139 loss_train: 1.7863 acc_train: 0.3047 loss_val: 1.7822 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0140 loss_train: 1.7917 acc_train: 0.3010 loss_val: 1.7815 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0141 loss_train: 1.7892 acc_train: 0.3033 loss_val: 1.7808 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0142 loss_train: 1.7860 acc_train: 0.3061 loss_val: 1.7801 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0143 loss_train: 1.7911 acc_train: 0.3015 loss_val: 1.7794 acc_val: 0.2952 time: 0.0065s\n",
      "Epoch: 0144 loss_train: 1.7800 acc_train: 0.3089 loss_val: 1.7787 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0145 loss_train: 1.7925 acc_train: 0.3015 loss_val: 1.7780 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0146 loss_train: 1.7760 acc_train: 0.3029 loss_val: 1.7773 acc_val: 0.2952 time: 0.0063s\n",
      "Epoch: 0147 loss_train: 1.7924 acc_train: 0.3033 loss_val: 1.7766 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0148 loss_train: 1.7913 acc_train: 0.3019 loss_val: 1.7759 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0149 loss_train: 1.7838 acc_train: 0.3019 loss_val: 1.7752 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0150 loss_train: 1.7834 acc_train: 0.3047 loss_val: 1.7745 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0151 loss_train: 1.7821 acc_train: 0.3038 loss_val: 1.7738 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0152 loss_train: 1.7741 acc_train: 0.3029 loss_val: 1.7732 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0153 loss_train: 1.7741 acc_train: 0.3015 loss_val: 1.7725 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0154 loss_train: 1.7867 acc_train: 0.3029 loss_val: 1.7718 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0155 loss_train: 1.7804 acc_train: 0.3019 loss_val: 1.7711 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0156 loss_train: 1.7707 acc_train: 0.3033 loss_val: 1.7704 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0157 loss_train: 1.7798 acc_train: 0.3042 loss_val: 1.7697 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0158 loss_train: 1.7653 acc_train: 0.3052 loss_val: 1.7690 acc_val: 0.2952 time: 0.0065s\n",
      "Epoch: 0159 loss_train: 1.7779 acc_train: 0.3042 loss_val: 1.7684 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0160 loss_train: 1.7760 acc_train: 0.3038 loss_val: 1.7677 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0161 loss_train: 1.7744 acc_train: 0.3047 loss_val: 1.7670 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0162 loss_train: 1.7751 acc_train: 0.3038 loss_val: 1.7664 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0163 loss_train: 1.7754 acc_train: 0.3033 loss_val: 1.7657 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0164 loss_train: 1.7764 acc_train: 0.3042 loss_val: 1.7651 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0165 loss_train: 1.7672 acc_train: 0.3029 loss_val: 1.7644 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0166 loss_train: 1.7690 acc_train: 0.3029 loss_val: 1.7638 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0167 loss_train: 1.7684 acc_train: 0.3029 loss_val: 1.7631 acc_val: 0.2952 time: 0.0065s\n",
      "Epoch: 0168 loss_train: 1.7601 acc_train: 0.3052 loss_val: 1.7624 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0169 loss_train: 1.7677 acc_train: 0.3038 loss_val: 1.7618 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0170 loss_train: 1.7689 acc_train: 0.3024 loss_val: 1.7611 acc_val: 0.2952 time: 0.0064s\n",
      "Epoch: 0171 loss_train: 1.7598 acc_train: 0.3052 loss_val: 1.7605 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0172 loss_train: 1.7734 acc_train: 0.3029 loss_val: 1.7598 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0173 loss_train: 1.7755 acc_train: 0.3010 loss_val: 1.7592 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0174 loss_train: 1.7616 acc_train: 0.3029 loss_val: 1.7585 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0175 loss_train: 1.7618 acc_train: 0.3029 loss_val: 1.7578 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0176 loss_train: 1.7670 acc_train: 0.3015 loss_val: 1.7572 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0177 loss_train: 1.7661 acc_train: 0.3038 loss_val: 1.7565 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0178 loss_train: 1.7649 acc_train: 0.3024 loss_val: 1.7558 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0179 loss_train: 1.7616 acc_train: 0.3033 loss_val: 1.7551 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0180 loss_train: 1.7585 acc_train: 0.3033 loss_val: 1.7545 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0181 loss_train: 1.7573 acc_train: 0.3033 loss_val: 1.7538 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0182 loss_train: 1.7575 acc_train: 0.3042 loss_val: 1.7531 acc_val: 0.2952 time: 0.0065s\n",
      "Epoch: 0183 loss_train: 1.7635 acc_train: 0.3038 loss_val: 1.7524 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0184 loss_train: 1.7568 acc_train: 0.3038 loss_val: 1.7518 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0185 loss_train: 1.7604 acc_train: 0.3024 loss_val: 1.7511 acc_val: 0.2952 time: 0.0064s\n",
      "Epoch: 0186 loss_train: 1.7512 acc_train: 0.3029 loss_val: 1.7504 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0187 loss_train: 1.7564 acc_train: 0.3042 loss_val: 1.7497 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0188 loss_train: 1.7596 acc_train: 0.3015 loss_val: 1.7490 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0189 loss_train: 1.7474 acc_train: 0.3033 loss_val: 1.7483 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0190 loss_train: 1.7440 acc_train: 0.3038 loss_val: 1.7476 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0191 loss_train: 1.7473 acc_train: 0.3038 loss_val: 1.7469 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0192 loss_train: 1.7383 acc_train: 0.3042 loss_val: 1.7462 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0193 loss_train: 1.7474 acc_train: 0.3015 loss_val: 1.7455 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0194 loss_train: 1.7474 acc_train: 0.3042 loss_val: 1.7448 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0195 loss_train: 1.7438 acc_train: 0.3019 loss_val: 1.7440 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0196 loss_train: 1.7460 acc_train: 0.3047 loss_val: 1.7433 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0197 loss_train: 1.7491 acc_train: 0.3033 loss_val: 1.7426 acc_val: 0.2952 time: 0.0064s\n",
      "Epoch: 0198 loss_train: 1.7427 acc_train: 0.3038 loss_val: 1.7419 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0199 loss_train: 1.7444 acc_train: 0.3033 loss_val: 1.7412 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0200 loss_train: 1.7428 acc_train: 0.3024 loss_val: 1.7405 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0201 loss_train: 1.7410 acc_train: 0.3024 loss_val: 1.7398 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0202 loss_train: 1.7499 acc_train: 0.3047 loss_val: 1.7390 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0203 loss_train: 1.7428 acc_train: 0.3024 loss_val: 1.7383 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0204 loss_train: 1.7489 acc_train: 0.3038 loss_val: 1.7376 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0205 loss_train: 1.7331 acc_train: 0.3052 loss_val: 1.7368 acc_val: 0.2952 time: 0.0067s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0206 loss_train: 1.7303 acc_train: 0.3038 loss_val: 1.7360 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0207 loss_train: 1.7410 acc_train: 0.3029 loss_val: 1.7353 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0208 loss_train: 1.7443 acc_train: 0.3033 loss_val: 1.7346 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0209 loss_train: 1.7332 acc_train: 0.3033 loss_val: 1.7338 acc_val: 0.2952 time: 0.0064s\n",
      "Epoch: 0210 loss_train: 1.7441 acc_train: 0.3024 loss_val: 1.7331 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0211 loss_train: 1.7294 acc_train: 0.3042 loss_val: 1.7323 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0212 loss_train: 1.7338 acc_train: 0.3019 loss_val: 1.7316 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0213 loss_train: 1.7404 acc_train: 0.3047 loss_val: 1.7308 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0214 loss_train: 1.7479 acc_train: 0.3047 loss_val: 1.7300 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0215 loss_train: 1.7304 acc_train: 0.3033 loss_val: 1.7293 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0216 loss_train: 1.7342 acc_train: 0.3061 loss_val: 1.7285 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0217 loss_train: 1.7310 acc_train: 0.3056 loss_val: 1.7278 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0218 loss_train: 1.7274 acc_train: 0.3052 loss_val: 1.7270 acc_val: 0.2952 time: 0.0063s\n",
      "Epoch: 0219 loss_train: 1.7259 acc_train: 0.3066 loss_val: 1.7262 acc_val: 0.2952 time: 0.0067s\n",
      "Epoch: 0220 loss_train: 1.7336 acc_train: 0.3042 loss_val: 1.7255 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0221 loss_train: 1.7311 acc_train: 0.3019 loss_val: 1.7247 acc_val: 0.2952 time: 0.0064s\n",
      "Epoch: 0222 loss_train: 1.7222 acc_train: 0.3079 loss_val: 1.7239 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0223 loss_train: 1.7232 acc_train: 0.3056 loss_val: 1.7231 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0224 loss_train: 1.7180 acc_train: 0.3029 loss_val: 1.7223 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0225 loss_train: 1.7186 acc_train: 0.3061 loss_val: 1.7215 acc_val: 0.2952 time: 0.0068s\n",
      "Epoch: 0226 loss_train: 1.7237 acc_train: 0.3033 loss_val: 1.7207 acc_val: 0.2952 time: 0.0069s\n",
      "Epoch: 0227 loss_train: 1.7252 acc_train: 0.3029 loss_val: 1.7199 acc_val: 0.2952 time: 0.0066s\n",
      "Epoch: 0228 loss_train: 1.7193 acc_train: 0.3079 loss_val: 1.7191 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0229 loss_train: 1.7323 acc_train: 0.3033 loss_val: 1.7182 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0230 loss_train: 1.7294 acc_train: 0.3052 loss_val: 1.7174 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0231 loss_train: 1.7156 acc_train: 0.3038 loss_val: 1.7166 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0232 loss_train: 1.7266 acc_train: 0.3061 loss_val: 1.7158 acc_val: 0.2989 time: 0.0075s\n",
      "Epoch: 0233 loss_train: 1.7078 acc_train: 0.3061 loss_val: 1.7150 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0234 loss_train: 1.7165 acc_train: 0.3047 loss_val: 1.7142 acc_val: 0.2989 time: 0.0072s\n",
      "Epoch: 0235 loss_train: 1.7213 acc_train: 0.3061 loss_val: 1.7133 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0236 loss_train: 1.7127 acc_train: 0.3056 loss_val: 1.7125 acc_val: 0.2989 time: 0.0066s\n",
      "Epoch: 0237 loss_train: 1.7117 acc_train: 0.3056 loss_val: 1.7117 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0238 loss_train: 1.7167 acc_train: 0.3079 loss_val: 1.7108 acc_val: 0.2989 time: 0.0072s\n",
      "Epoch: 0239 loss_train: 1.7102 acc_train: 0.3107 loss_val: 1.7099 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0240 loss_train: 1.7092 acc_train: 0.3084 loss_val: 1.7091 acc_val: 0.2989 time: 0.0074s\n",
      "Epoch: 0241 loss_train: 1.7073 acc_train: 0.3070 loss_val: 1.7082 acc_val: 0.2989 time: 0.0071s\n",
      "Epoch: 0242 loss_train: 1.7061 acc_train: 0.3075 loss_val: 1.7073 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0243 loss_train: 1.7082 acc_train: 0.3121 loss_val: 1.7064 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0244 loss_train: 1.7125 acc_train: 0.3079 loss_val: 1.7055 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0245 loss_train: 1.7027 acc_train: 0.3079 loss_val: 1.7046 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0246 loss_train: 1.7079 acc_train: 0.3047 loss_val: 1.7038 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0247 loss_train: 1.6999 acc_train: 0.3093 loss_val: 1.7029 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0248 loss_train: 1.6998 acc_train: 0.3056 loss_val: 1.7019 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0249 loss_train: 1.7066 acc_train: 0.3070 loss_val: 1.7010 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0250 loss_train: 1.6972 acc_train: 0.3052 loss_val: 1.7001 acc_val: 0.2989 time: 0.0072s\n",
      "Epoch: 0251 loss_train: 1.6966 acc_train: 0.3052 loss_val: 1.6992 acc_val: 0.2989 time: 0.0064s\n",
      "Epoch: 0252 loss_train: 1.7023 acc_train: 0.3093 loss_val: 1.6983 acc_val: 0.2989 time: 0.0066s\n",
      "Epoch: 0253 loss_train: 1.7094 acc_train: 0.3089 loss_val: 1.6973 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0254 loss_train: 1.6925 acc_train: 0.3084 loss_val: 1.6964 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0255 loss_train: 1.6863 acc_train: 0.3093 loss_val: 1.6954 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0256 loss_train: 1.6955 acc_train: 0.3079 loss_val: 1.6945 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0257 loss_train: 1.7003 acc_train: 0.3102 loss_val: 1.6935 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0258 loss_train: 1.6939 acc_train: 0.3093 loss_val: 1.6926 acc_val: 0.2989 time: 0.0082s\n",
      "Epoch: 0259 loss_train: 1.6919 acc_train: 0.3126 loss_val: 1.6916 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0260 loss_train: 1.6834 acc_train: 0.3130 loss_val: 1.6906 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0261 loss_train: 1.6940 acc_train: 0.3102 loss_val: 1.6897 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0262 loss_train: 1.6831 acc_train: 0.3121 loss_val: 1.6887 acc_val: 0.2989 time: 0.0072s\n",
      "Epoch: 0263 loss_train: 1.6891 acc_train: 0.3075 loss_val: 1.6878 acc_val: 0.2989 time: 0.0066s\n",
      "Epoch: 0264 loss_train: 1.6845 acc_train: 0.3158 loss_val: 1.6868 acc_val: 0.2989 time: 0.0071s\n",
      "Epoch: 0265 loss_train: 1.6790 acc_train: 0.3153 loss_val: 1.6858 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0266 loss_train: 1.6804 acc_train: 0.3107 loss_val: 1.6848 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0267 loss_train: 1.6745 acc_train: 0.3121 loss_val: 1.6839 acc_val: 0.2989 time: 0.0071s\n",
      "Epoch: 0268 loss_train: 1.6815 acc_train: 0.3139 loss_val: 1.6829 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0269 loss_train: 1.6846 acc_train: 0.3116 loss_val: 1.6819 acc_val: 0.2989 time: 0.0066s\n",
      "Epoch: 0270 loss_train: 1.6788 acc_train: 0.3163 loss_val: 1.6810 acc_val: 0.2989 time: 0.0071s\n",
      "Epoch: 0271 loss_train: 1.6843 acc_train: 0.3172 loss_val: 1.6800 acc_val: 0.2989 time: 0.0069s\n",
      "Epoch: 0272 loss_train: 1.6827 acc_train: 0.3116 loss_val: 1.6790 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0273 loss_train: 1.6808 acc_train: 0.3172 loss_val: 1.6780 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0274 loss_train: 1.6723 acc_train: 0.3153 loss_val: 1.6770 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0275 loss_train: 1.6747 acc_train: 0.3163 loss_val: 1.6760 acc_val: 0.2989 time: 0.0063s\n",
      "Epoch: 0276 loss_train: 1.6709 acc_train: 0.3181 loss_val: 1.6750 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0277 loss_train: 1.6695 acc_train: 0.3259 loss_val: 1.6739 acc_val: 0.2989 time: 0.0068s\n",
      "Epoch: 0278 loss_train: 1.6830 acc_train: 0.3089 loss_val: 1.6729 acc_val: 0.2989 time: 0.0064s\n",
      "Epoch: 0279 loss_train: 1.6689 acc_train: 0.3139 loss_val: 1.6718 acc_val: 0.2989 time: 0.0067s\n",
      "Epoch: 0280 loss_train: 1.6669 acc_train: 0.3163 loss_val: 1.6707 acc_val: 0.2989 time: 0.0070s\n",
      "Epoch: 0281 loss_train: 1.6706 acc_train: 0.3181 loss_val: 1.6697 acc_val: 0.3026 time: 0.0070s\n",
      "Epoch: 0282 loss_train: 1.6586 acc_train: 0.3135 loss_val: 1.6686 acc_val: 0.3026 time: 0.0069s\n",
      "Epoch: 0283 loss_train: 1.6732 acc_train: 0.3130 loss_val: 1.6675 acc_val: 0.3026 time: 0.0079s\n",
      "Epoch: 0284 loss_train: 1.6581 acc_train: 0.3181 loss_val: 1.6664 acc_val: 0.3026 time: 0.0069s\n",
      "Epoch: 0285 loss_train: 1.6670 acc_train: 0.3176 loss_val: 1.6653 acc_val: 0.3026 time: 0.0069s\n",
      "Epoch: 0286 loss_train: 1.6685 acc_train: 0.3227 loss_val: 1.6643 acc_val: 0.3026 time: 0.0073s\n",
      "Epoch: 0287 loss_train: 1.6649 acc_train: 0.3135 loss_val: 1.6631 acc_val: 0.3026 time: 0.0070s\n",
      "Epoch: 0288 loss_train: 1.6666 acc_train: 0.3135 loss_val: 1.6620 acc_val: 0.3026 time: 0.0069s\n",
      "Epoch: 0289 loss_train: 1.6617 acc_train: 0.3176 loss_val: 1.6609 acc_val: 0.3026 time: 0.0070s\n",
      "Epoch: 0290 loss_train: 1.6515 acc_train: 0.3227 loss_val: 1.6598 acc_val: 0.3026 time: 0.0065s\n",
      "Epoch: 0291 loss_train: 1.6655 acc_train: 0.3204 loss_val: 1.6587 acc_val: 0.3063 time: 0.0070s\n",
      "Epoch: 0292 loss_train: 1.6493 acc_train: 0.3232 loss_val: 1.6576 acc_val: 0.3063 time: 0.0067s\n",
      "Epoch: 0293 loss_train: 1.6547 acc_train: 0.3209 loss_val: 1.6565 acc_val: 0.3063 time: 0.0065s\n",
      "Epoch: 0294 loss_train: 1.6534 acc_train: 0.3149 loss_val: 1.6554 acc_val: 0.3063 time: 0.0069s\n",
      "Epoch: 0295 loss_train: 1.6623 acc_train: 0.3232 loss_val: 1.6543 acc_val: 0.3063 time: 0.0071s\n",
      "Epoch: 0296 loss_train: 1.6508 acc_train: 0.3241 loss_val: 1.6532 acc_val: 0.3063 time: 0.0065s\n",
      "Epoch: 0297 loss_train: 1.6483 acc_train: 0.3273 loss_val: 1.6520 acc_val: 0.3063 time: 0.0068s\n",
      "Epoch: 0298 loss_train: 1.6609 acc_train: 0.3186 loss_val: 1.6509 acc_val: 0.3063 time: 0.0071s\n",
      "Epoch: 0299 loss_train: 1.6453 acc_train: 0.3246 loss_val: 1.6498 acc_val: 0.3063 time: 0.0068s\n",
      "Epoch: 0300 loss_train: 1.6431 acc_train: 0.3278 loss_val: 1.6487 acc_val: 0.3063 time: 0.0067s\n",
      "Epoch: 0301 loss_train: 1.6548 acc_train: 0.3250 loss_val: 1.6476 acc_val: 0.3063 time: 0.0068s\n",
      "Epoch: 0302 loss_train: 1.6383 acc_train: 0.3343 loss_val: 1.6464 acc_val: 0.3063 time: 0.0067s\n",
      "Epoch: 0303 loss_train: 1.6388 acc_train: 0.3236 loss_val: 1.6453 acc_val: 0.3063 time: 0.0072s\n",
      "Epoch: 0304 loss_train: 1.6516 acc_train: 0.3218 loss_val: 1.6442 acc_val: 0.3063 time: 0.0068s\n",
      "Epoch: 0305 loss_train: 1.6401 acc_train: 0.3232 loss_val: 1.6430 acc_val: 0.3063 time: 0.0066s\n",
      "Epoch: 0306 loss_train: 1.6442 acc_train: 0.3278 loss_val: 1.6419 acc_val: 0.3063 time: 0.0069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0307 loss_train: 1.6411 acc_train: 0.3315 loss_val: 1.6407 acc_val: 0.3063 time: 0.0076s\n",
      "Epoch: 0308 loss_train: 1.6376 acc_train: 0.3250 loss_val: 1.6396 acc_val: 0.3063 time: 0.0069s\n",
      "Epoch: 0309 loss_train: 1.6378 acc_train: 0.3255 loss_val: 1.6384 acc_val: 0.3063 time: 0.0068s\n",
      "Epoch: 0310 loss_train: 1.6354 acc_train: 0.3403 loss_val: 1.6372 acc_val: 0.3063 time: 0.0070s\n",
      "Epoch: 0311 loss_train: 1.6341 acc_train: 0.3292 loss_val: 1.6360 acc_val: 0.3063 time: 0.0068s\n",
      "Epoch: 0312 loss_train: 1.6325 acc_train: 0.3398 loss_val: 1.6348 acc_val: 0.3063 time: 0.0067s\n",
      "Epoch: 0313 loss_train: 1.6291 acc_train: 0.3352 loss_val: 1.6336 acc_val: 0.3063 time: 0.0069s\n",
      "Epoch: 0314 loss_train: 1.6316 acc_train: 0.3329 loss_val: 1.6323 acc_val: 0.3063 time: 0.0071s\n",
      "Epoch: 0315 loss_train: 1.6327 acc_train: 0.3407 loss_val: 1.6311 acc_val: 0.3063 time: 0.0071s\n",
      "Epoch: 0316 loss_train: 1.6218 acc_train: 0.3393 loss_val: 1.6300 acc_val: 0.3063 time: 0.0066s\n",
      "Epoch: 0317 loss_train: 1.6329 acc_train: 0.3319 loss_val: 1.6288 acc_val: 0.3063 time: 0.0066s\n",
      "Epoch: 0318 loss_train: 1.6183 acc_train: 0.3407 loss_val: 1.6276 acc_val: 0.3063 time: 0.0071s\n",
      "Epoch: 0319 loss_train: 1.6121 acc_train: 0.3458 loss_val: 1.6264 acc_val: 0.3063 time: 0.0071s\n",
      "Epoch: 0320 loss_train: 1.6256 acc_train: 0.3283 loss_val: 1.6252 acc_val: 0.3063 time: 0.0065s\n",
      "Epoch: 0321 loss_train: 1.6160 acc_train: 0.3435 loss_val: 1.6240 acc_val: 0.3100 time: 0.0070s\n",
      "Epoch: 0322 loss_train: 1.6192 acc_train: 0.3403 loss_val: 1.6228 acc_val: 0.3100 time: 0.0068s\n",
      "Epoch: 0323 loss_train: 1.6133 acc_train: 0.3283 loss_val: 1.6216 acc_val: 0.3100 time: 0.0068s\n",
      "Epoch: 0324 loss_train: 1.6166 acc_train: 0.3366 loss_val: 1.6204 acc_val: 0.3100 time: 0.0068s\n",
      "Epoch: 0325 loss_train: 1.6085 acc_train: 0.3421 loss_val: 1.6193 acc_val: 0.3100 time: 0.0068s\n",
      "Epoch: 0326 loss_train: 1.6152 acc_train: 0.3333 loss_val: 1.6181 acc_val: 0.3100 time: 0.0067s\n",
      "Epoch: 0327 loss_train: 1.6136 acc_train: 0.3435 loss_val: 1.6169 acc_val: 0.3100 time: 0.0073s\n",
      "Epoch: 0328 loss_train: 1.6240 acc_train: 0.3430 loss_val: 1.6157 acc_val: 0.3100 time: 0.0070s\n",
      "Epoch: 0329 loss_train: 1.6149 acc_train: 0.3430 loss_val: 1.6145 acc_val: 0.3137 time: 0.0064s\n",
      "Epoch: 0330 loss_train: 1.6154 acc_train: 0.3463 loss_val: 1.6133 acc_val: 0.3137 time: 0.0069s\n",
      "Epoch: 0331 loss_train: 1.6196 acc_train: 0.3329 loss_val: 1.6121 acc_val: 0.3137 time: 0.0070s\n",
      "Epoch: 0332 loss_train: 1.6110 acc_train: 0.3366 loss_val: 1.6109 acc_val: 0.3137 time: 0.0070s\n",
      "Epoch: 0333 loss_train: 1.6130 acc_train: 0.3523 loss_val: 1.6097 acc_val: 0.3137 time: 0.0073s\n",
      "Epoch: 0334 loss_train: 1.6060 acc_train: 0.3343 loss_val: 1.6085 acc_val: 0.3137 time: 0.0070s\n",
      "Epoch: 0335 loss_train: 1.6040 acc_train: 0.3430 loss_val: 1.6073 acc_val: 0.3137 time: 0.0071s\n",
      "Epoch: 0336 loss_train: 1.6052 acc_train: 0.3444 loss_val: 1.6060 acc_val: 0.3137 time: 0.0070s\n",
      "Epoch: 0337 loss_train: 1.5912 acc_train: 0.3389 loss_val: 1.6048 acc_val: 0.3137 time: 0.0064s\n",
      "Epoch: 0338 loss_train: 1.6085 acc_train: 0.3435 loss_val: 1.6035 acc_val: 0.3137 time: 0.0073s\n",
      "Epoch: 0339 loss_train: 1.5938 acc_train: 0.3495 loss_val: 1.6023 acc_val: 0.3137 time: 0.0071s\n",
      "Epoch: 0340 loss_train: 1.6030 acc_train: 0.3490 loss_val: 1.6010 acc_val: 0.3137 time: 0.0067s\n",
      "Epoch: 0341 loss_train: 1.5876 acc_train: 0.3453 loss_val: 1.5998 acc_val: 0.3137 time: 0.0067s\n",
      "Epoch: 0342 loss_train: 1.5906 acc_train: 0.3495 loss_val: 1.5985 acc_val: 0.3137 time: 0.0070s\n",
      "Epoch: 0343 loss_train: 1.5936 acc_train: 0.3495 loss_val: 1.5973 acc_val: 0.3137 time: 0.0067s\n",
      "Epoch: 0344 loss_train: 1.5992 acc_train: 0.3620 loss_val: 1.5960 acc_val: 0.3137 time: 0.0067s\n",
      "Epoch: 0345 loss_train: 1.5895 acc_train: 0.3583 loss_val: 1.5947 acc_val: 0.3137 time: 0.0066s\n",
      "Epoch: 0346 loss_train: 1.5950 acc_train: 0.3518 loss_val: 1.5935 acc_val: 0.3137 time: 0.0067s\n",
      "Epoch: 0347 loss_train: 1.5856 acc_train: 0.3560 loss_val: 1.5922 acc_val: 0.3137 time: 0.0073s\n",
      "Epoch: 0348 loss_train: 1.5857 acc_train: 0.3513 loss_val: 1.5908 acc_val: 0.3137 time: 0.0068s\n",
      "Epoch: 0349 loss_train: 1.5807 acc_train: 0.3583 loss_val: 1.5895 acc_val: 0.3173 time: 0.0065s\n",
      "Epoch: 0350 loss_train: 1.5822 acc_train: 0.3583 loss_val: 1.5882 acc_val: 0.3173 time: 0.0070s\n",
      "Epoch: 0351 loss_train: 1.5767 acc_train: 0.3629 loss_val: 1.5869 acc_val: 0.3173 time: 0.0071s\n",
      "Epoch: 0352 loss_train: 1.5843 acc_train: 0.3578 loss_val: 1.5856 acc_val: 0.3173 time: 0.0066s\n",
      "Epoch: 0353 loss_train: 1.5890 acc_train: 0.3453 loss_val: 1.5842 acc_val: 0.3210 time: 0.0068s\n",
      "Epoch: 0354 loss_train: 1.5859 acc_train: 0.3620 loss_val: 1.5829 acc_val: 0.3210 time: 0.0070s\n",
      "Epoch: 0355 loss_train: 1.5768 acc_train: 0.3633 loss_val: 1.5816 acc_val: 0.3210 time: 0.0068s\n",
      "Epoch: 0356 loss_train: 1.5767 acc_train: 0.3509 loss_val: 1.5802 acc_val: 0.3247 time: 0.0067s\n",
      "Epoch: 0357 loss_train: 1.5778 acc_train: 0.3638 loss_val: 1.5789 acc_val: 0.3247 time: 0.0068s\n",
      "Epoch: 0358 loss_train: 1.5687 acc_train: 0.3596 loss_val: 1.5776 acc_val: 0.3284 time: 0.0067s\n",
      "Epoch: 0359 loss_train: 1.5574 acc_train: 0.3781 loss_val: 1.5763 acc_val: 0.3284 time: 0.0079s\n",
      "Epoch: 0360 loss_train: 1.5610 acc_train: 0.3712 loss_val: 1.5750 acc_val: 0.3284 time: 0.0072s\n",
      "Epoch: 0361 loss_train: 1.5709 acc_train: 0.3698 loss_val: 1.5737 acc_val: 0.3284 time: 0.0068s\n",
      "Epoch: 0362 loss_train: 1.5573 acc_train: 0.3809 loss_val: 1.5724 acc_val: 0.3284 time: 0.0075s\n",
      "Epoch: 0363 loss_train: 1.5640 acc_train: 0.3684 loss_val: 1.5711 acc_val: 0.3284 time: 0.0072s\n",
      "Epoch: 0364 loss_train: 1.5743 acc_train: 0.3693 loss_val: 1.5698 acc_val: 0.3284 time: 0.0066s\n",
      "Epoch: 0365 loss_train: 1.5533 acc_train: 0.3781 loss_val: 1.5685 acc_val: 0.3284 time: 0.0070s\n",
      "Epoch: 0366 loss_train: 1.5540 acc_train: 0.3707 loss_val: 1.5673 acc_val: 0.3321 time: 0.0070s\n",
      "Epoch: 0367 loss_train: 1.5606 acc_train: 0.3749 loss_val: 1.5660 acc_val: 0.3321 time: 0.0068s\n",
      "Epoch: 0368 loss_train: 1.5598 acc_train: 0.3495 loss_val: 1.5647 acc_val: 0.3321 time: 0.0068s\n",
      "Epoch: 0369 loss_train: 1.5582 acc_train: 0.3661 loss_val: 1.5634 acc_val: 0.3321 time: 0.0068s\n",
      "Epoch: 0370 loss_train: 1.5556 acc_train: 0.3684 loss_val: 1.5620 acc_val: 0.3321 time: 0.0064s\n",
      "Epoch: 0371 loss_train: 1.5579 acc_train: 0.3841 loss_val: 1.5607 acc_val: 0.3321 time: 0.0068s\n",
      "Epoch: 0372 loss_train: 1.5541 acc_train: 0.3740 loss_val: 1.5594 acc_val: 0.3321 time: 0.0068s\n",
      "Epoch: 0373 loss_train: 1.5512 acc_train: 0.3901 loss_val: 1.5581 acc_val: 0.3321 time: 0.0067s\n",
      "Epoch: 0374 loss_train: 1.5623 acc_train: 0.3624 loss_val: 1.5568 acc_val: 0.3321 time: 0.0072s\n",
      "Epoch: 0375 loss_train: 1.5457 acc_train: 0.3846 loss_val: 1.5555 acc_val: 0.3321 time: 0.0069s\n",
      "Epoch: 0376 loss_train: 1.5510 acc_train: 0.3841 loss_val: 1.5541 acc_val: 0.3321 time: 0.0066s\n",
      "Epoch: 0377 loss_train: 1.5471 acc_train: 0.3730 loss_val: 1.5528 acc_val: 0.3321 time: 0.0070s\n",
      "Epoch: 0378 loss_train: 1.5511 acc_train: 0.3786 loss_val: 1.5515 acc_val: 0.3321 time: 0.0072s\n",
      "Epoch: 0379 loss_train: 1.5475 acc_train: 0.3860 loss_val: 1.5501 acc_val: 0.3321 time: 0.0065s\n",
      "Epoch: 0380 loss_train: 1.5479 acc_train: 0.3818 loss_val: 1.5488 acc_val: 0.3321 time: 0.0068s\n",
      "Epoch: 0381 loss_train: 1.5428 acc_train: 0.3804 loss_val: 1.5474 acc_val: 0.3395 time: 0.0070s\n",
      "Epoch: 0382 loss_train: 1.5466 acc_train: 0.3781 loss_val: 1.5461 acc_val: 0.3395 time: 0.0069s\n",
      "Epoch: 0383 loss_train: 1.5527 acc_train: 0.3753 loss_val: 1.5448 acc_val: 0.3395 time: 0.0069s\n",
      "Epoch: 0384 loss_train: 1.5296 acc_train: 0.3786 loss_val: 1.5435 acc_val: 0.3395 time: 0.0067s\n",
      "Epoch: 0385 loss_train: 1.5376 acc_train: 0.3823 loss_val: 1.5421 acc_val: 0.3395 time: 0.0076s\n",
      "Epoch: 0386 loss_train: 1.5430 acc_train: 0.3758 loss_val: 1.5408 acc_val: 0.3395 time: 0.0072s\n",
      "Epoch: 0387 loss_train: 1.5406 acc_train: 0.3910 loss_val: 1.5395 acc_val: 0.3395 time: 0.0067s\n",
      "Epoch: 0388 loss_train: 1.5258 acc_train: 0.3860 loss_val: 1.5382 acc_val: 0.3395 time: 0.0065s\n",
      "Epoch: 0389 loss_train: 1.5351 acc_train: 0.3864 loss_val: 1.5369 acc_val: 0.3395 time: 0.0071s\n",
      "Epoch: 0390 loss_train: 1.5336 acc_train: 0.4030 loss_val: 1.5356 acc_val: 0.3432 time: 0.0071s\n",
      "Epoch: 0391 loss_train: 1.5363 acc_train: 0.3906 loss_val: 1.5343 acc_val: 0.3432 time: 0.0065s\n",
      "Epoch: 0392 loss_train: 1.5282 acc_train: 0.3855 loss_val: 1.5330 acc_val: 0.3432 time: 0.0069s\n",
      "Epoch: 0393 loss_train: 1.5314 acc_train: 0.3841 loss_val: 1.5317 acc_val: 0.3432 time: 0.0071s\n",
      "Epoch: 0394 loss_train: 1.5207 acc_train: 0.3887 loss_val: 1.5304 acc_val: 0.3432 time: 0.0067s\n",
      "Epoch: 0395 loss_train: 1.5209 acc_train: 0.3920 loss_val: 1.5291 acc_val: 0.3432 time: 0.0067s\n",
      "Epoch: 0396 loss_train: 1.5229 acc_train: 0.3938 loss_val: 1.5278 acc_val: 0.3432 time: 0.0067s\n",
      "Epoch: 0397 loss_train: 1.5198 acc_train: 0.4017 loss_val: 1.5265 acc_val: 0.3469 time: 0.0067s\n",
      "Epoch: 0398 loss_train: 1.5133 acc_train: 0.4007 loss_val: 1.5251 acc_val: 0.3469 time: 0.0071s\n",
      "Epoch: 0399 loss_train: 1.5368 acc_train: 0.3689 loss_val: 1.5238 acc_val: 0.3469 time: 0.0068s\n",
      "Epoch: 0400 loss_train: 1.5262 acc_train: 0.3994 loss_val: 1.5225 acc_val: 0.3469 time: 0.0065s\n",
      "Epoch: 0401 loss_train: 1.5225 acc_train: 0.3938 loss_val: 1.5212 acc_val: 0.3542 time: 0.0074s\n",
      "Epoch: 0402 loss_train: 1.5120 acc_train: 0.3957 loss_val: 1.5199 acc_val: 0.3542 time: 0.0073s\n",
      "Epoch: 0403 loss_train: 1.5235 acc_train: 0.3961 loss_val: 1.5186 acc_val: 0.3542 time: 0.0064s\n",
      "Epoch: 0404 loss_train: 1.5083 acc_train: 0.4137 loss_val: 1.5173 acc_val: 0.3542 time: 0.0067s\n",
      "Epoch: 0405 loss_train: 1.5120 acc_train: 0.3970 loss_val: 1.5160 acc_val: 0.3542 time: 0.0069s\n",
      "Epoch: 0406 loss_train: 1.5019 acc_train: 0.4003 loss_val: 1.5148 acc_val: 0.3542 time: 0.0068s\n",
      "Epoch: 0407 loss_train: 1.5193 acc_train: 0.4054 loss_val: 1.5135 acc_val: 0.3542 time: 0.0066s\n",
      "Epoch: 0408 loss_train: 1.5124 acc_train: 0.4054 loss_val: 1.5122 acc_val: 0.3542 time: 0.0071s\n",
      "Epoch: 0409 loss_train: 1.5071 acc_train: 0.4132 loss_val: 1.5109 acc_val: 0.3542 time: 0.0068s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0410 loss_train: 1.4983 acc_train: 0.4017 loss_val: 1.5097 acc_val: 0.3542 time: 0.0076s\n",
      "Epoch: 0411 loss_train: 1.5052 acc_train: 0.3998 loss_val: 1.5084 acc_val: 0.3542 time: 0.0068s\n",
      "Epoch: 0412 loss_train: 1.4974 acc_train: 0.4164 loss_val: 1.5071 acc_val: 0.3542 time: 0.0068s\n",
      "Epoch: 0413 loss_train: 1.5023 acc_train: 0.3998 loss_val: 1.5059 acc_val: 0.3542 time: 0.0071s\n",
      "Epoch: 0414 loss_train: 1.4985 acc_train: 0.4081 loss_val: 1.5046 acc_val: 0.3542 time: 0.0069s\n",
      "Epoch: 0415 loss_train: 1.4936 acc_train: 0.4067 loss_val: 1.5033 acc_val: 0.3542 time: 0.0068s\n",
      "Epoch: 0416 loss_train: 1.4944 acc_train: 0.4026 loss_val: 1.5021 acc_val: 0.3542 time: 0.0069s\n",
      "Epoch: 0417 loss_train: 1.4916 acc_train: 0.4072 loss_val: 1.5008 acc_val: 0.3542 time: 0.0066s\n",
      "Epoch: 0418 loss_train: 1.4943 acc_train: 0.3970 loss_val: 1.4995 acc_val: 0.3542 time: 0.0070s\n",
      "Epoch: 0419 loss_train: 1.4868 acc_train: 0.4026 loss_val: 1.4982 acc_val: 0.3542 time: 0.0067s\n",
      "Epoch: 0420 loss_train: 1.4935 acc_train: 0.4155 loss_val: 1.4970 acc_val: 0.3542 time: 0.0065s\n",
      "Epoch: 0421 loss_train: 1.4802 acc_train: 0.4201 loss_val: 1.4957 acc_val: 0.3542 time: 0.0068s\n",
      "Epoch: 0422 loss_train: 1.4904 acc_train: 0.4137 loss_val: 1.4944 acc_val: 0.3542 time: 0.0071s\n",
      "Epoch: 0423 loss_train: 1.5009 acc_train: 0.4054 loss_val: 1.4931 acc_val: 0.3542 time: 0.0065s\n",
      "Epoch: 0424 loss_train: 1.4889 acc_train: 0.4035 loss_val: 1.4918 acc_val: 0.3579 time: 0.0069s\n",
      "Epoch: 0425 loss_train: 1.4851 acc_train: 0.4215 loss_val: 1.4905 acc_val: 0.3579 time: 0.0070s\n",
      "Epoch: 0426 loss_train: 1.4820 acc_train: 0.4220 loss_val: 1.4892 acc_val: 0.3579 time: 0.0069s\n",
      "Epoch: 0427 loss_train: 1.4844 acc_train: 0.4187 loss_val: 1.4878 acc_val: 0.3579 time: 0.0069s\n",
      "Epoch: 0428 loss_train: 1.4809 acc_train: 0.4197 loss_val: 1.4865 acc_val: 0.3616 time: 0.0068s\n",
      "Epoch: 0429 loss_train: 1.4820 acc_train: 0.4151 loss_val: 1.4852 acc_val: 0.3616 time: 0.0066s\n",
      "Epoch: 0430 loss_train: 1.4839 acc_train: 0.4109 loss_val: 1.4839 acc_val: 0.3616 time: 0.0071s\n",
      "Epoch: 0431 loss_train: 1.4764 acc_train: 0.4298 loss_val: 1.4826 acc_val: 0.3616 time: 0.0067s\n",
      "Epoch: 0432 loss_train: 1.4755 acc_train: 0.4155 loss_val: 1.4814 acc_val: 0.3616 time: 0.0065s\n",
      "Epoch: 0433 loss_train: 1.4746 acc_train: 0.4146 loss_val: 1.4801 acc_val: 0.3653 time: 0.0069s\n",
      "Epoch: 0434 loss_train: 1.4754 acc_train: 0.4169 loss_val: 1.4788 acc_val: 0.3653 time: 0.0070s\n",
      "Epoch: 0435 loss_train: 1.4693 acc_train: 0.4229 loss_val: 1.4775 acc_val: 0.3764 time: 0.0064s\n",
      "Epoch: 0436 loss_train: 1.4732 acc_train: 0.4215 loss_val: 1.4762 acc_val: 0.3764 time: 0.0075s\n",
      "Epoch: 0437 loss_train: 1.4706 acc_train: 0.4247 loss_val: 1.4749 acc_val: 0.3764 time: 0.0068s\n",
      "Epoch: 0438 loss_train: 1.4616 acc_train: 0.4220 loss_val: 1.4736 acc_val: 0.3764 time: 0.0068s\n",
      "Epoch: 0439 loss_train: 1.4619 acc_train: 0.4280 loss_val: 1.4724 acc_val: 0.3838 time: 0.0067s\n",
      "Epoch: 0440 loss_train: 1.4731 acc_train: 0.4266 loss_val: 1.4711 acc_val: 0.3838 time: 0.0066s\n",
      "Epoch: 0441 loss_train: 1.4622 acc_train: 0.4252 loss_val: 1.4698 acc_val: 0.3838 time: 0.0068s\n",
      "Epoch: 0442 loss_train: 1.4676 acc_train: 0.4326 loss_val: 1.4686 acc_val: 0.3838 time: 0.0072s\n",
      "Epoch: 0443 loss_train: 1.4607 acc_train: 0.4307 loss_val: 1.4673 acc_val: 0.3838 time: 0.0068s\n",
      "Epoch: 0444 loss_train: 1.4667 acc_train: 0.4247 loss_val: 1.4660 acc_val: 0.3838 time: 0.0064s\n",
      "Epoch: 0445 loss_train: 1.4623 acc_train: 0.4363 loss_val: 1.4648 acc_val: 0.3838 time: 0.0069s\n",
      "Epoch: 0446 loss_train: 1.4483 acc_train: 0.4464 loss_val: 1.4635 acc_val: 0.3875 time: 0.0072s\n",
      "Epoch: 0447 loss_train: 1.4644 acc_train: 0.4469 loss_val: 1.4622 acc_val: 0.3875 time: 0.0065s\n",
      "Epoch: 0448 loss_train: 1.4494 acc_train: 0.4381 loss_val: 1.4609 acc_val: 0.3875 time: 0.0069s\n",
      "Epoch: 0449 loss_train: 1.4601 acc_train: 0.4344 loss_val: 1.4597 acc_val: 0.3875 time: 0.0072s\n",
      "Epoch: 0450 loss_train: 1.4604 acc_train: 0.4234 loss_val: 1.4584 acc_val: 0.3875 time: 0.0068s\n",
      "Epoch: 0451 loss_train: 1.4467 acc_train: 0.4543 loss_val: 1.4571 acc_val: 0.3875 time: 0.0068s\n",
      "Epoch: 0452 loss_train: 1.4492 acc_train: 0.4404 loss_val: 1.4558 acc_val: 0.3875 time: 0.0069s\n",
      "Epoch: 0453 loss_train: 1.4367 acc_train: 0.4409 loss_val: 1.4545 acc_val: 0.3875 time: 0.0065s\n",
      "Epoch: 0454 loss_train: 1.4390 acc_train: 0.4515 loss_val: 1.4531 acc_val: 0.3838 time: 0.0071s\n",
      "Epoch: 0455 loss_train: 1.4431 acc_train: 0.4626 loss_val: 1.4518 acc_val: 0.3875 time: 0.0066s\n",
      "Epoch: 0456 loss_train: 1.4332 acc_train: 0.4506 loss_val: 1.4504 acc_val: 0.3911 time: 0.0067s\n",
      "Epoch: 0457 loss_train: 1.4482 acc_train: 0.4474 loss_val: 1.4491 acc_val: 0.3911 time: 0.0071s\n",
      "Epoch: 0458 loss_train: 1.4429 acc_train: 0.4561 loss_val: 1.4477 acc_val: 0.3911 time: 0.0072s\n",
      "Epoch: 0459 loss_train: 1.4479 acc_train: 0.4358 loss_val: 1.4463 acc_val: 0.3911 time: 0.0065s\n",
      "Epoch: 0460 loss_train: 1.4387 acc_train: 0.4460 loss_val: 1.4450 acc_val: 0.3911 time: 0.0068s\n",
      "Epoch: 0461 loss_train: 1.4406 acc_train: 0.4474 loss_val: 1.4436 acc_val: 0.3948 time: 0.0070s\n",
      "Epoch: 0462 loss_train: 1.4495 acc_train: 0.4603 loss_val: 1.4421 acc_val: 0.3948 time: 0.0079s\n",
      "Epoch: 0463 loss_train: 1.4348 acc_train: 0.4594 loss_val: 1.4408 acc_val: 0.3948 time: 0.0067s\n",
      "Epoch: 0464 loss_train: 1.4347 acc_train: 0.4617 loss_val: 1.4394 acc_val: 0.3985 time: 0.0069s\n",
      "Epoch: 0465 loss_train: 1.4387 acc_train: 0.4580 loss_val: 1.4380 acc_val: 0.4022 time: 0.0070s\n",
      "Epoch: 0466 loss_train: 1.4211 acc_train: 0.4608 loss_val: 1.4366 acc_val: 0.4022 time: 0.0072s\n",
      "Epoch: 0467 loss_train: 1.4370 acc_train: 0.4640 loss_val: 1.4352 acc_val: 0.4022 time: 0.0067s\n",
      "Epoch: 0468 loss_train: 1.4309 acc_train: 0.4705 loss_val: 1.4338 acc_val: 0.4022 time: 0.0065s\n",
      "Epoch: 0469 loss_train: 1.4207 acc_train: 0.4935 loss_val: 1.4324 acc_val: 0.4059 time: 0.0074s\n",
      "Epoch: 0470 loss_train: 1.4178 acc_train: 0.4811 loss_val: 1.4310 acc_val: 0.4059 time: 0.0072s\n",
      "Epoch: 0471 loss_train: 1.4137 acc_train: 0.4612 loss_val: 1.4297 acc_val: 0.4096 time: 0.0064s\n",
      "Epoch: 0472 loss_train: 1.4174 acc_train: 0.4908 loss_val: 1.4283 acc_val: 0.4133 time: 0.0067s\n",
      "Epoch: 0473 loss_train: 1.4191 acc_train: 0.4931 loss_val: 1.4269 acc_val: 0.4133 time: 0.0071s\n",
      "Epoch: 0474 loss_train: 1.4201 acc_train: 0.4691 loss_val: 1.4255 acc_val: 0.4170 time: 0.0068s\n",
      "Epoch: 0475 loss_train: 1.4140 acc_train: 0.4843 loss_val: 1.4241 acc_val: 0.4170 time: 0.0067s\n",
      "Epoch: 0476 loss_train: 1.4095 acc_train: 0.4885 loss_val: 1.4227 acc_val: 0.4244 time: 0.0067s\n",
      "Epoch: 0477 loss_train: 1.4193 acc_train: 0.4977 loss_val: 1.4214 acc_val: 0.4280 time: 0.0066s\n",
      "Epoch: 0478 loss_train: 1.4098 acc_train: 0.4968 loss_val: 1.4200 acc_val: 0.4317 time: 0.0070s\n",
      "Epoch: 0479 loss_train: 1.4086 acc_train: 0.5005 loss_val: 1.4186 acc_val: 0.4354 time: 0.0066s\n",
      "Epoch: 0480 loss_train: 1.4194 acc_train: 0.5023 loss_val: 1.4172 acc_val: 0.4354 time: 0.0065s\n",
      "Epoch: 0481 loss_train: 1.4026 acc_train: 0.4977 loss_val: 1.4158 acc_val: 0.4354 time: 0.0077s\n",
      "Epoch: 0482 loss_train: 1.4096 acc_train: 0.4875 loss_val: 1.4144 acc_val: 0.4391 time: 0.0071s\n",
      "Epoch: 0483 loss_train: 1.4114 acc_train: 0.4972 loss_val: 1.4129 acc_val: 0.4428 time: 0.0065s\n",
      "Epoch: 0484 loss_train: 1.4114 acc_train: 0.5014 loss_val: 1.4115 acc_val: 0.4428 time: 0.0068s\n",
      "Epoch: 0485 loss_train: 1.4008 acc_train: 0.5212 loss_val: 1.4101 acc_val: 0.4465 time: 0.0071s\n",
      "Epoch: 0486 loss_train: 1.4134 acc_train: 0.4940 loss_val: 1.4087 acc_val: 0.4465 time: 0.0069s\n",
      "Epoch: 0487 loss_train: 1.3990 acc_train: 0.5009 loss_val: 1.4073 acc_val: 0.4465 time: 0.0095s\n",
      "Epoch: 0488 loss_train: 1.3908 acc_train: 0.5268 loss_val: 1.4058 acc_val: 0.4465 time: 0.0071s\n",
      "Epoch: 0489 loss_train: 1.3953 acc_train: 0.5314 loss_val: 1.4044 acc_val: 0.4613 time: 0.0066s\n",
      "Epoch: 0490 loss_train: 1.3876 acc_train: 0.5212 loss_val: 1.4030 acc_val: 0.4613 time: 0.0069s\n",
      "Epoch: 0491 loss_train: 1.4012 acc_train: 0.5245 loss_val: 1.4015 acc_val: 0.4760 time: 0.0067s\n",
      "Epoch: 0492 loss_train: 1.3945 acc_train: 0.5189 loss_val: 1.4001 acc_val: 0.4760 time: 0.0065s\n",
      "Epoch: 0493 loss_train: 1.3818 acc_train: 0.5171 loss_val: 1.3986 acc_val: 0.4760 time: 0.0073s\n",
      "Epoch: 0494 loss_train: 1.3959 acc_train: 0.5240 loss_val: 1.3971 acc_val: 0.4834 time: 0.0069s\n",
      "Epoch: 0495 loss_train: 1.3968 acc_train: 0.5102 loss_val: 1.3957 acc_val: 0.4945 time: 0.0067s\n",
      "Epoch: 0496 loss_train: 1.3958 acc_train: 0.5466 loss_val: 1.3942 acc_val: 0.4945 time: 0.0067s\n",
      "Epoch: 0497 loss_train: 1.3791 acc_train: 0.5517 loss_val: 1.3927 acc_val: 0.4945 time: 0.0068s\n",
      "Epoch: 0498 loss_train: 1.3906 acc_train: 0.5351 loss_val: 1.3912 acc_val: 0.4982 time: 0.0068s\n",
      "Epoch: 0499 loss_train: 1.3712 acc_train: 0.5379 loss_val: 1.3897 acc_val: 0.4982 time: 0.0070s\n",
      "Epoch: 0500 loss_train: 1.3965 acc_train: 0.5143 loss_val: 1.3883 acc_val: 0.5092 time: 0.0067s\n",
      "Epoch: 0501 loss_train: 1.3701 acc_train: 0.5623 loss_val: 1.3868 acc_val: 0.5092 time: 0.0064s\n",
      "Epoch: 0502 loss_train: 1.3716 acc_train: 0.5416 loss_val: 1.3853 acc_val: 0.5092 time: 0.0069s\n",
      "Epoch: 0503 loss_train: 1.3834 acc_train: 0.5485 loss_val: 1.3839 acc_val: 0.5166 time: 0.0071s\n",
      "Epoch: 0504 loss_train: 1.3750 acc_train: 0.5623 loss_val: 1.3825 acc_val: 0.5203 time: 0.0066s\n",
      "Epoch: 0505 loss_train: 1.3663 acc_train: 0.5494 loss_val: 1.3811 acc_val: 0.5203 time: 0.0069s\n",
      "Epoch: 0506 loss_train: 1.3786 acc_train: 0.5582 loss_val: 1.3797 acc_val: 0.5203 time: 0.0071s\n",
      "Epoch: 0507 loss_train: 1.3687 acc_train: 0.5669 loss_val: 1.3782 acc_val: 0.5203 time: 0.0069s\n",
      "Epoch: 0508 loss_train: 1.3596 acc_train: 0.5702 loss_val: 1.3768 acc_val: 0.5203 time: 0.0066s\n",
      "Epoch: 0509 loss_train: 1.3641 acc_train: 0.5729 loss_val: 1.3754 acc_val: 0.5203 time: 0.0067s\n",
      "Epoch: 0510 loss_train: 1.3745 acc_train: 0.5605 loss_val: 1.3740 acc_val: 0.5203 time: 0.0068s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0511 loss_train: 1.3691 acc_train: 0.5683 loss_val: 1.3726 acc_val: 0.5240 time: 0.0076s\n",
      "Epoch: 0512 loss_train: 1.3603 acc_train: 0.5780 loss_val: 1.3711 acc_val: 0.5240 time: 0.0067s\n",
      "Epoch: 0513 loss_train: 1.3594 acc_train: 0.5762 loss_val: 1.3697 acc_val: 0.5240 time: 0.0065s\n",
      "Epoch: 0514 loss_train: 1.3558 acc_train: 0.5757 loss_val: 1.3682 acc_val: 0.5240 time: 0.0074s\n",
      "Epoch: 0515 loss_train: 1.3632 acc_train: 0.5831 loss_val: 1.3667 acc_val: 0.5240 time: 0.0073s\n",
      "Epoch: 0516 loss_train: 1.3586 acc_train: 0.5683 loss_val: 1.3653 acc_val: 0.5240 time: 0.0064s\n",
      "Epoch: 0517 loss_train: 1.3476 acc_train: 0.5965 loss_val: 1.3638 acc_val: 0.5240 time: 0.0066s\n",
      "Epoch: 0518 loss_train: 1.3713 acc_train: 0.5656 loss_val: 1.3624 acc_val: 0.5240 time: 0.0070s\n",
      "Epoch: 0519 loss_train: 1.3707 acc_train: 0.5651 loss_val: 1.3609 acc_val: 0.5240 time: 0.0068s\n",
      "Epoch: 0520 loss_train: 1.3565 acc_train: 0.5743 loss_val: 1.3595 acc_val: 0.5240 time: 0.0069s\n",
      "Epoch: 0521 loss_train: 1.3522 acc_train: 0.5743 loss_val: 1.3580 acc_val: 0.5240 time: 0.0067s\n",
      "Epoch: 0522 loss_train: 1.3484 acc_train: 0.5845 loss_val: 1.3566 acc_val: 0.5277 time: 0.0071s\n",
      "Epoch: 0523 loss_train: 1.3555 acc_train: 0.5808 loss_val: 1.3551 acc_val: 0.5314 time: 0.0072s\n",
      "Epoch: 0524 loss_train: 1.3520 acc_train: 0.5702 loss_val: 1.3537 acc_val: 0.5314 time: 0.0068s\n",
      "Epoch: 0525 loss_train: 1.3639 acc_train: 0.5734 loss_val: 1.3523 acc_val: 0.5314 time: 0.0066s\n",
      "Epoch: 0526 loss_train: 1.3465 acc_train: 0.5799 loss_val: 1.3510 acc_val: 0.5351 time: 0.0073s\n",
      "Epoch: 0527 loss_train: 1.3534 acc_train: 0.5970 loss_val: 1.3496 acc_val: 0.5387 time: 0.0069s\n",
      "Epoch: 0528 loss_train: 1.3426 acc_train: 0.6122 loss_val: 1.3482 acc_val: 0.5387 time: 0.0065s\n",
      "Epoch: 0529 loss_train: 1.3586 acc_train: 0.6016 loss_val: 1.3469 acc_val: 0.5387 time: 0.0069s\n",
      "Epoch: 0530 loss_train: 1.3345 acc_train: 0.6048 loss_val: 1.3455 acc_val: 0.5387 time: 0.0071s\n",
      "Epoch: 0531 loss_train: 1.3376 acc_train: 0.5970 loss_val: 1.3441 acc_val: 0.5424 time: 0.0068s\n",
      "Epoch: 0532 loss_train: 1.3198 acc_train: 0.6094 loss_val: 1.3426 acc_val: 0.5424 time: 0.0069s\n",
      "Epoch: 0533 loss_train: 1.3438 acc_train: 0.5937 loss_val: 1.3412 acc_val: 0.5424 time: 0.0068s\n",
      "Epoch: 0534 loss_train: 1.3444 acc_train: 0.5988 loss_val: 1.3398 acc_val: 0.5461 time: 0.0066s\n",
      "Epoch: 0535 loss_train: 1.3455 acc_train: 0.6048 loss_val: 1.3384 acc_val: 0.5461 time: 0.0071s\n",
      "Epoch: 0536 loss_train: 1.3226 acc_train: 0.6076 loss_val: 1.3369 acc_val: 0.5498 time: 0.0067s\n",
      "Epoch: 0537 loss_train: 1.3239 acc_train: 0.6108 loss_val: 1.3355 acc_val: 0.5535 time: 0.0075s\n",
      "Epoch: 0538 loss_train: 1.3427 acc_train: 0.5900 loss_val: 1.3341 acc_val: 0.5535 time: 0.0069s\n",
      "Epoch: 0539 loss_train: 1.3333 acc_train: 0.6043 loss_val: 1.3327 acc_val: 0.5535 time: 0.0070s\n",
      "Epoch: 0540 loss_train: 1.3220 acc_train: 0.6163 loss_val: 1.3312 acc_val: 0.5535 time: 0.0065s\n",
      "Epoch: 0541 loss_train: 1.3258 acc_train: 0.6071 loss_val: 1.3298 acc_val: 0.5572 time: 0.0068s\n",
      "Epoch: 0542 loss_train: 1.3266 acc_train: 0.5983 loss_val: 1.3284 acc_val: 0.5609 time: 0.0070s\n",
      "Epoch: 0543 loss_train: 1.3243 acc_train: 0.6237 loss_val: 1.3270 acc_val: 0.5646 time: 0.0068s\n",
      "Epoch: 0544 loss_train: 1.3276 acc_train: 0.5919 loss_val: 1.3256 acc_val: 0.5646 time: 0.0066s\n",
      "Epoch: 0545 loss_train: 1.3237 acc_train: 0.6131 loss_val: 1.3242 acc_val: 0.5646 time: 0.0071s\n",
      "Epoch: 0546 loss_train: 1.3222 acc_train: 0.6066 loss_val: 1.3229 acc_val: 0.5609 time: 0.0066s\n",
      "Epoch: 0547 loss_train: 1.3258 acc_train: 0.5979 loss_val: 1.3215 acc_val: 0.5609 time: 0.0071s\n",
      "Epoch: 0548 loss_train: 1.3119 acc_train: 0.6117 loss_val: 1.3202 acc_val: 0.5609 time: 0.0068s\n",
      "Epoch: 0549 loss_train: 1.3028 acc_train: 0.6334 loss_val: 1.3188 acc_val: 0.5609 time: 0.0069s\n",
      "Epoch: 0550 loss_train: 1.3100 acc_train: 0.6113 loss_val: 1.3175 acc_val: 0.5609 time: 0.0075s\n",
      "Epoch: 0551 loss_train: 1.3198 acc_train: 0.6237 loss_val: 1.3162 acc_val: 0.5609 time: 0.0071s\n",
      "Epoch: 0552 loss_train: 1.2990 acc_train: 0.6404 loss_val: 1.3148 acc_val: 0.5609 time: 0.0069s\n",
      "Epoch: 0553 loss_train: 1.3136 acc_train: 0.6233 loss_val: 1.3135 acc_val: 0.5609 time: 0.0069s\n",
      "Epoch: 0554 loss_train: 1.3133 acc_train: 0.6182 loss_val: 1.3121 acc_val: 0.5646 time: 0.0070s\n",
      "Epoch: 0555 loss_train: 1.2968 acc_train: 0.6367 loss_val: 1.3108 acc_val: 0.5683 time: 0.0068s\n",
      "Epoch: 0556 loss_train: 1.3053 acc_train: 0.6071 loss_val: 1.3095 acc_val: 0.5720 time: 0.0066s\n",
      "Epoch: 0557 loss_train: 1.3047 acc_train: 0.6136 loss_val: 1.3081 acc_val: 0.5720 time: 0.0067s\n",
      "Epoch: 0558 loss_train: 1.3164 acc_train: 0.6288 loss_val: 1.3068 acc_val: 0.5720 time: 0.0070s\n",
      "Epoch: 0559 loss_train: 1.2916 acc_train: 0.6330 loss_val: 1.3055 acc_val: 0.5756 time: 0.0071s\n",
      "Epoch: 0560 loss_train: 1.3030 acc_train: 0.6140 loss_val: 1.3042 acc_val: 0.5756 time: 0.0067s\n",
      "Epoch: 0561 loss_train: 1.2914 acc_train: 0.6283 loss_val: 1.3029 acc_val: 0.5756 time: 0.0066s\n",
      "Epoch: 0562 loss_train: 1.2825 acc_train: 0.6357 loss_val: 1.3015 acc_val: 0.5756 time: 0.0076s\n",
      "Epoch: 0563 loss_train: 1.3030 acc_train: 0.6307 loss_val: 1.3002 acc_val: 0.5756 time: 0.0072s\n",
      "Epoch: 0564 loss_train: 1.2788 acc_train: 0.6440 loss_val: 1.2989 acc_val: 0.5756 time: 0.0070s\n",
      "Epoch: 0565 loss_train: 1.2890 acc_train: 0.6283 loss_val: 1.2975 acc_val: 0.5756 time: 0.0067s\n",
      "Epoch: 0566 loss_train: 1.2851 acc_train: 0.6380 loss_val: 1.2961 acc_val: 0.5756 time: 0.0070s\n",
      "Epoch: 0567 loss_train: 1.2961 acc_train: 0.6464 loss_val: 1.2948 acc_val: 0.5793 time: 0.0068s\n",
      "Epoch: 0568 loss_train: 1.3004 acc_train: 0.6265 loss_val: 1.2935 acc_val: 0.5867 time: 0.0071s\n",
      "Epoch: 0569 loss_train: 1.2842 acc_train: 0.6247 loss_val: 1.2921 acc_val: 0.5904 time: 0.0068s\n",
      "Epoch: 0570 loss_train: 1.2858 acc_train: 0.6413 loss_val: 1.2908 acc_val: 0.5904 time: 0.0066s\n",
      "Epoch: 0571 loss_train: 1.2743 acc_train: 0.6427 loss_val: 1.2895 acc_val: 0.5904 time: 0.0070s\n",
      "Epoch: 0572 loss_train: 1.2971 acc_train: 0.6464 loss_val: 1.2882 acc_val: 0.5904 time: 0.0068s\n",
      "Epoch: 0573 loss_train: 1.2888 acc_train: 0.6353 loss_val: 1.2869 acc_val: 0.5941 time: 0.0064s\n",
      "Epoch: 0574 loss_train: 1.2927 acc_train: 0.6404 loss_val: 1.2857 acc_val: 0.5941 time: 0.0070s\n",
      "Epoch: 0575 loss_train: 1.2733 acc_train: 0.6496 loss_val: 1.2844 acc_val: 0.5941 time: 0.0072s\n",
      "Epoch: 0576 loss_train: 1.2857 acc_train: 0.6436 loss_val: 1.2832 acc_val: 0.5941 time: 0.0066s\n",
      "Epoch: 0577 loss_train: 1.2672 acc_train: 0.6593 loss_val: 1.2819 acc_val: 0.5941 time: 0.0071s\n",
      "Epoch: 0578 loss_train: 1.2768 acc_train: 0.6427 loss_val: 1.2806 acc_val: 0.5941 time: 0.0072s\n",
      "Epoch: 0579 loss_train: 1.2939 acc_train: 0.6422 loss_val: 1.2793 acc_val: 0.5941 time: 0.0068s\n",
      "Epoch: 0580 loss_train: 1.2749 acc_train: 0.6371 loss_val: 1.2780 acc_val: 0.5941 time: 0.0073s\n",
      "Epoch: 0581 loss_train: 1.2743 acc_train: 0.6413 loss_val: 1.2768 acc_val: 0.5941 time: 0.0071s\n",
      "Epoch: 0582 loss_train: 1.2835 acc_train: 0.6357 loss_val: 1.2755 acc_val: 0.5941 time: 0.0070s\n",
      "Epoch: 0583 loss_train: 1.2725 acc_train: 0.6454 loss_val: 1.2742 acc_val: 0.5941 time: 0.0071s\n",
      "Epoch: 0584 loss_train: 1.2758 acc_train: 0.6362 loss_val: 1.2730 acc_val: 0.5941 time: 0.0067s\n",
      "Epoch: 0585 loss_train: 1.2618 acc_train: 0.6473 loss_val: 1.2717 acc_val: 0.5978 time: 0.0065s\n",
      "Epoch: 0586 loss_train: 1.2816 acc_train: 0.6339 loss_val: 1.2704 acc_val: 0.5978 time: 0.0071s\n",
      "Epoch: 0587 loss_train: 1.2725 acc_train: 0.6413 loss_val: 1.2692 acc_val: 0.5978 time: 0.0079s\n",
      "Epoch: 0588 loss_train: 1.2670 acc_train: 0.6607 loss_val: 1.2679 acc_val: 0.5978 time: 0.0066s\n",
      "Epoch: 0589 loss_train: 1.2829 acc_train: 0.6454 loss_val: 1.2667 acc_val: 0.5978 time: 0.0068s\n",
      "Epoch: 0590 loss_train: 1.2723 acc_train: 0.6408 loss_val: 1.2655 acc_val: 0.6015 time: 0.0070s\n",
      "Epoch: 0591 loss_train: 1.2446 acc_train: 0.6524 loss_val: 1.2643 acc_val: 0.6015 time: 0.0069s\n",
      "Epoch: 0592 loss_train: 1.2498 acc_train: 0.6427 loss_val: 1.2631 acc_val: 0.6015 time: 0.0067s\n",
      "Epoch: 0593 loss_train: 1.2466 acc_train: 0.6588 loss_val: 1.2619 acc_val: 0.6015 time: 0.0067s\n",
      "Epoch: 0594 loss_train: 1.2495 acc_train: 0.6551 loss_val: 1.2606 acc_val: 0.6015 time: 0.0067s\n",
      "Epoch: 0595 loss_train: 1.2623 acc_train: 0.6459 loss_val: 1.2594 acc_val: 0.6052 time: 0.0072s\n",
      "Epoch: 0596 loss_train: 1.2688 acc_train: 0.6491 loss_val: 1.2582 acc_val: 0.6052 time: 0.0072s\n",
      "Epoch: 0597 loss_train: 1.2603 acc_train: 0.6639 loss_val: 1.2571 acc_val: 0.6052 time: 0.0068s\n",
      "Epoch: 0598 loss_train: 1.2506 acc_train: 0.6584 loss_val: 1.2559 acc_val: 0.6052 time: 0.0072s\n",
      "Epoch: 0599 loss_train: 1.2298 acc_train: 0.6620 loss_val: 1.2546 acc_val: 0.6052 time: 0.0073s\n",
      "Epoch: 0600 loss_train: 1.2333 acc_train: 0.6648 loss_val: 1.2534 acc_val: 0.6052 time: 0.0071s\n",
      "Epoch: 0601 loss_train: 1.2612 acc_train: 0.6408 loss_val: 1.2522 acc_val: 0.6052 time: 0.0068s\n",
      "Epoch: 0602 loss_train: 1.2379 acc_train: 0.6787 loss_val: 1.2510 acc_val: 0.6052 time: 0.0071s\n",
      "Epoch: 0603 loss_train: 1.2536 acc_train: 0.6487 loss_val: 1.2498 acc_val: 0.6052 time: 0.0069s\n",
      "Epoch: 0604 loss_train: 1.2571 acc_train: 0.6445 loss_val: 1.2486 acc_val: 0.6052 time: 0.0067s\n",
      "Epoch: 0605 loss_train: 1.2255 acc_train: 0.6574 loss_val: 1.2474 acc_val: 0.6089 time: 0.0067s\n",
      "Epoch: 0606 loss_train: 1.2555 acc_train: 0.6487 loss_val: 1.2462 acc_val: 0.6162 time: 0.0067s\n",
      "Epoch: 0607 loss_train: 1.2415 acc_train: 0.6514 loss_val: 1.2450 acc_val: 0.6162 time: 0.0071s\n",
      "Epoch: 0608 loss_train: 1.2375 acc_train: 0.6500 loss_val: 1.2437 acc_val: 0.6162 time: 0.0067s\n",
      "Epoch: 0609 loss_train: 1.2388 acc_train: 0.6602 loss_val: 1.2425 acc_val: 0.6162 time: 0.0065s\n",
      "Epoch: 0610 loss_train: 1.2418 acc_train: 0.6510 loss_val: 1.2412 acc_val: 0.6162 time: 0.0071s\n",
      "Epoch: 0611 loss_train: 1.2524 acc_train: 0.6704 loss_val: 1.2399 acc_val: 0.6162 time: 0.0071s\n",
      "Epoch: 0612 loss_train: 1.2420 acc_train: 0.6694 loss_val: 1.2387 acc_val: 0.6236 time: 0.0066s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0613 loss_train: 1.2364 acc_train: 0.6602 loss_val: 1.2374 acc_val: 0.6310 time: 0.0074s\n",
      "Epoch: 0614 loss_train: 1.2337 acc_train: 0.6690 loss_val: 1.2362 acc_val: 0.6310 time: 0.0068s\n",
      "Epoch: 0615 loss_train: 1.2260 acc_train: 0.6676 loss_val: 1.2349 acc_val: 0.6310 time: 0.0073s\n",
      "Epoch: 0616 loss_train: 1.2248 acc_train: 0.6620 loss_val: 1.2337 acc_val: 0.6310 time: 0.0070s\n",
      "Epoch: 0617 loss_train: 1.2366 acc_train: 0.6644 loss_val: 1.2324 acc_val: 0.6310 time: 0.0066s\n",
      "Epoch: 0618 loss_train: 1.2379 acc_train: 0.6620 loss_val: 1.2312 acc_val: 0.6347 time: 0.0068s\n",
      "Epoch: 0619 loss_train: 1.2406 acc_train: 0.6616 loss_val: 1.2300 acc_val: 0.6347 time: 0.0069s\n",
      "Epoch: 0620 loss_train: 1.2364 acc_train: 0.6648 loss_val: 1.2288 acc_val: 0.6347 time: 0.0065s\n",
      "Epoch: 0621 loss_train: 1.2277 acc_train: 0.6694 loss_val: 1.2276 acc_val: 0.6347 time: 0.0068s\n",
      "Epoch: 0622 loss_train: 1.2212 acc_train: 0.6630 loss_val: 1.2265 acc_val: 0.6347 time: 0.0071s\n",
      "Epoch: 0623 loss_train: 1.2386 acc_train: 0.6482 loss_val: 1.2253 acc_val: 0.6347 time: 0.0068s\n",
      "Epoch: 0624 loss_train: 1.2284 acc_train: 0.6681 loss_val: 1.2242 acc_val: 0.6347 time: 0.0067s\n",
      "Epoch: 0625 loss_train: 1.2193 acc_train: 0.6639 loss_val: 1.2231 acc_val: 0.6347 time: 0.0068s\n",
      "Epoch: 0626 loss_train: 1.2120 acc_train: 0.6833 loss_val: 1.2220 acc_val: 0.6310 time: 0.0067s\n",
      "Epoch: 0627 loss_train: 1.2036 acc_train: 0.6741 loss_val: 1.2209 acc_val: 0.6310 time: 0.0071s\n",
      "Epoch: 0628 loss_train: 1.2331 acc_train: 0.6750 loss_val: 1.2198 acc_val: 0.6310 time: 0.0068s\n",
      "Epoch: 0629 loss_train: 1.2161 acc_train: 0.6620 loss_val: 1.2187 acc_val: 0.6310 time: 0.0065s\n",
      "Epoch: 0630 loss_train: 1.2007 acc_train: 0.6699 loss_val: 1.2176 acc_val: 0.6310 time: 0.0069s\n",
      "Epoch: 0631 loss_train: 1.2108 acc_train: 0.6694 loss_val: 1.2165 acc_val: 0.6347 time: 0.0070s\n",
      "Epoch: 0632 loss_train: 1.1963 acc_train: 0.6791 loss_val: 1.2154 acc_val: 0.6347 time: 0.0065s\n",
      "Epoch: 0633 loss_train: 1.2069 acc_train: 0.6671 loss_val: 1.2142 acc_val: 0.6347 time: 0.0068s\n",
      "Epoch: 0634 loss_train: 1.2149 acc_train: 0.6713 loss_val: 1.2131 acc_val: 0.6347 time: 0.0071s\n",
      "Epoch: 0635 loss_train: 1.1993 acc_train: 0.6745 loss_val: 1.2119 acc_val: 0.6347 time: 0.0068s\n",
      "Epoch: 0636 loss_train: 1.2134 acc_train: 0.6699 loss_val: 1.2108 acc_val: 0.6347 time: 0.0069s\n",
      "Epoch: 0637 loss_train: 1.2058 acc_train: 0.6722 loss_val: 1.2096 acc_val: 0.6384 time: 0.0067s\n",
      "Epoch: 0638 loss_train: 1.2042 acc_train: 0.6754 loss_val: 1.2085 acc_val: 0.6384 time: 0.0067s\n",
      "Epoch: 0639 loss_train: 1.1910 acc_train: 0.6727 loss_val: 1.2073 acc_val: 0.6384 time: 0.0075s\n",
      "Epoch: 0640 loss_train: 1.2044 acc_train: 0.6801 loss_val: 1.2062 acc_val: 0.6384 time: 0.0070s\n",
      "Epoch: 0641 loss_train: 1.1924 acc_train: 0.6704 loss_val: 1.2052 acc_val: 0.6384 time: 0.0071s\n",
      "Epoch: 0642 loss_train: 1.1845 acc_train: 0.6847 loss_val: 1.2041 acc_val: 0.6384 time: 0.0071s\n",
      "Epoch: 0643 loss_train: 1.1995 acc_train: 0.6704 loss_val: 1.2030 acc_val: 0.6384 time: 0.0067s\n",
      "Epoch: 0644 loss_train: 1.1964 acc_train: 0.6805 loss_val: 1.2019 acc_val: 0.6421 time: 0.0066s\n",
      "Epoch: 0645 loss_train: 1.2066 acc_train: 0.6856 loss_val: 1.2008 acc_val: 0.6421 time: 0.0068s\n",
      "Epoch: 0646 loss_train: 1.1900 acc_train: 0.6911 loss_val: 1.1997 acc_val: 0.6421 time: 0.0069s\n",
      "Epoch: 0647 loss_train: 1.1789 acc_train: 0.6916 loss_val: 1.1986 acc_val: 0.6494 time: 0.0071s\n",
      "Epoch: 0648 loss_train: 1.1889 acc_train: 0.6833 loss_val: 1.1975 acc_val: 0.6494 time: 0.0066s\n",
      "Epoch: 0649 loss_train: 1.1944 acc_train: 0.6694 loss_val: 1.1964 acc_val: 0.6494 time: 0.0066s\n",
      "Epoch: 0650 loss_train: 1.1933 acc_train: 0.6690 loss_val: 1.1953 acc_val: 0.6531 time: 0.0069s\n",
      "Epoch: 0651 loss_train: 1.1966 acc_train: 0.6731 loss_val: 1.1942 acc_val: 0.6531 time: 0.0069s\n",
      "Epoch: 0652 loss_train: 1.1894 acc_train: 0.6777 loss_val: 1.1931 acc_val: 0.6568 time: 0.0067s\n",
      "Epoch: 0653 loss_train: 1.1996 acc_train: 0.6699 loss_val: 1.1921 acc_val: 0.6568 time: 0.0068s\n",
      "Epoch: 0654 loss_train: 1.1837 acc_train: 0.6791 loss_val: 1.1911 acc_val: 0.6531 time: 0.0071s\n",
      "Epoch: 0655 loss_train: 1.1977 acc_train: 0.6731 loss_val: 1.1901 acc_val: 0.6531 time: 0.0068s\n",
      "Epoch: 0656 loss_train: 1.1771 acc_train: 0.6893 loss_val: 1.1891 acc_val: 0.6531 time: 0.0067s\n",
      "Epoch: 0657 loss_train: 1.1986 acc_train: 0.6736 loss_val: 1.1881 acc_val: 0.6531 time: 0.0066s\n",
      "Epoch: 0658 loss_train: 1.1837 acc_train: 0.6791 loss_val: 1.1870 acc_val: 0.6531 time: 0.0064s\n",
      "Epoch: 0659 loss_train: 1.1858 acc_train: 0.6870 loss_val: 1.1859 acc_val: 0.6531 time: 0.0068s\n",
      "Epoch: 0660 loss_train: 1.1709 acc_train: 0.6902 loss_val: 1.1848 acc_val: 0.6531 time: 0.0067s\n",
      "Epoch: 0661 loss_train: 1.1845 acc_train: 0.6787 loss_val: 1.1837 acc_val: 0.6531 time: 0.0069s\n",
      "Epoch: 0662 loss_train: 1.1717 acc_train: 0.6842 loss_val: 1.1826 acc_val: 0.6568 time: 0.0071s\n",
      "Epoch: 0663 loss_train: 1.1794 acc_train: 0.6768 loss_val: 1.1814 acc_val: 0.6568 time: 0.0066s\n",
      "Epoch: 0664 loss_train: 1.1887 acc_train: 0.6847 loss_val: 1.1804 acc_val: 0.6605 time: 0.0067s\n",
      "Epoch: 0665 loss_train: 1.2002 acc_train: 0.6787 loss_val: 1.1793 acc_val: 0.6605 time: 0.0072s\n",
      "Epoch: 0666 loss_train: 1.1956 acc_train: 0.6791 loss_val: 1.1783 acc_val: 0.6605 time: 0.0072s\n",
      "Epoch: 0667 loss_train: 1.1899 acc_train: 0.6847 loss_val: 1.1773 acc_val: 0.6605 time: 0.0064s\n",
      "Epoch: 0668 loss_train: 1.1568 acc_train: 0.6837 loss_val: 1.1763 acc_val: 0.6605 time: 0.0067s\n",
      "Epoch: 0669 loss_train: 1.1737 acc_train: 0.6833 loss_val: 1.1752 acc_val: 0.6605 time: 0.0072s\n",
      "Epoch: 0670 loss_train: 1.1857 acc_train: 0.6713 loss_val: 1.1742 acc_val: 0.6605 time: 0.0073s\n",
      "Epoch: 0671 loss_train: 1.1804 acc_train: 0.6833 loss_val: 1.1732 acc_val: 0.6605 time: 0.0070s\n",
      "Epoch: 0672 loss_train: 1.1788 acc_train: 0.6791 loss_val: 1.1721 acc_val: 0.6642 time: 0.0071s\n",
      "Epoch: 0673 loss_train: 1.1704 acc_train: 0.6874 loss_val: 1.1711 acc_val: 0.6642 time: 0.0070s\n",
      "Epoch: 0674 loss_train: 1.1797 acc_train: 0.6787 loss_val: 1.1701 acc_val: 0.6679 time: 0.0068s\n",
      "Epoch: 0675 loss_train: 1.1679 acc_train: 0.6828 loss_val: 1.1690 acc_val: 0.6679 time: 0.0069s\n",
      "Epoch: 0676 loss_train: 1.1656 acc_train: 0.6861 loss_val: 1.1679 acc_val: 0.6679 time: 0.0068s\n",
      "Epoch: 0677 loss_train: 1.1581 acc_train: 0.6690 loss_val: 1.1668 acc_val: 0.6679 time: 0.0068s\n",
      "Epoch: 0678 loss_train: 1.1717 acc_train: 0.6851 loss_val: 1.1658 acc_val: 0.6716 time: 0.0073s\n",
      "Epoch: 0679 loss_train: 1.1577 acc_train: 0.6971 loss_val: 1.1647 acc_val: 0.6753 time: 0.0071s\n",
      "Epoch: 0680 loss_train: 1.1572 acc_train: 0.6837 loss_val: 1.1636 acc_val: 0.6790 time: 0.0066s\n",
      "Epoch: 0681 loss_train: 1.1706 acc_train: 0.6893 loss_val: 1.1626 acc_val: 0.6790 time: 0.0070s\n",
      "Epoch: 0682 loss_train: 1.1668 acc_train: 0.6824 loss_val: 1.1615 acc_val: 0.6790 time: 0.0072s\n",
      "Epoch: 0683 loss_train: 1.1657 acc_train: 0.6898 loss_val: 1.1605 acc_val: 0.6827 time: 0.0065s\n",
      "Epoch: 0684 loss_train: 1.1560 acc_train: 0.6911 loss_val: 1.1595 acc_val: 0.6827 time: 0.0069s\n",
      "Epoch: 0685 loss_train: 1.1721 acc_train: 0.6930 loss_val: 1.1585 acc_val: 0.6827 time: 0.0071s\n",
      "Epoch: 0686 loss_train: 1.1632 acc_train: 0.6842 loss_val: 1.1575 acc_val: 0.6827 time: 0.0068s\n",
      "Epoch: 0687 loss_train: 1.1478 acc_train: 0.6893 loss_val: 1.1565 acc_val: 0.6827 time: 0.0068s\n",
      "Epoch: 0688 loss_train: 1.1496 acc_train: 0.6925 loss_val: 1.1555 acc_val: 0.6827 time: 0.0068s\n",
      "Epoch: 0689 loss_train: 1.1479 acc_train: 0.6934 loss_val: 1.1545 acc_val: 0.6827 time: 0.0070s\n",
      "Epoch: 0690 loss_train: 1.1573 acc_train: 0.6824 loss_val: 1.1535 acc_val: 0.6827 time: 0.0071s\n",
      "Epoch: 0691 loss_train: 1.1549 acc_train: 0.6953 loss_val: 1.1525 acc_val: 0.6827 time: 0.0067s\n",
      "Epoch: 0692 loss_train: 1.1623 acc_train: 0.6717 loss_val: 1.1515 acc_val: 0.6863 time: 0.0065s\n",
      "Epoch: 0693 loss_train: 1.1641 acc_train: 0.6819 loss_val: 1.1505 acc_val: 0.6863 time: 0.0072s\n",
      "Epoch: 0694 loss_train: 1.1578 acc_train: 0.6865 loss_val: 1.1495 acc_val: 0.6863 time: 0.0072s\n",
      "Epoch: 0695 loss_train: 1.1373 acc_train: 0.6870 loss_val: 1.1486 acc_val: 0.6863 time: 0.0064s\n",
      "Epoch: 0696 loss_train: 1.1467 acc_train: 0.6999 loss_val: 1.1476 acc_val: 0.6863 time: 0.0067s\n",
      "Epoch: 0697 loss_train: 1.1220 acc_train: 0.7008 loss_val: 1.1466 acc_val: 0.6863 time: 0.0074s\n",
      "Epoch: 0698 loss_train: 1.1384 acc_train: 0.6958 loss_val: 1.1455 acc_val: 0.6863 time: 0.0069s\n",
      "Epoch: 0699 loss_train: 1.1413 acc_train: 0.6999 loss_val: 1.1445 acc_val: 0.6863 time: 0.0069s\n",
      "Epoch: 0700 loss_train: 1.1486 acc_train: 0.6934 loss_val: 1.1435 acc_val: 0.6900 time: 0.0070s\n",
      "Epoch: 0701 loss_train: 1.1362 acc_train: 0.6953 loss_val: 1.1424 acc_val: 0.6900 time: 0.0066s\n",
      "Epoch: 0702 loss_train: 1.1217 acc_train: 0.6990 loss_val: 1.1413 acc_val: 0.6937 time: 0.0070s\n",
      "Epoch: 0703 loss_train: 1.1220 acc_train: 0.6944 loss_val: 1.1403 acc_val: 0.6937 time: 0.0068s\n",
      "Epoch: 0704 loss_train: 1.1266 acc_train: 0.6934 loss_val: 1.1392 acc_val: 0.7011 time: 0.0064s\n",
      "Epoch: 0705 loss_train: 1.1382 acc_train: 0.6948 loss_val: 1.1381 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0706 loss_train: 1.1411 acc_train: 0.6967 loss_val: 1.1371 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0707 loss_train: 1.1562 acc_train: 0.6874 loss_val: 1.1361 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0708 loss_train: 1.1369 acc_train: 0.6925 loss_val: 1.1350 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0709 loss_train: 1.1443 acc_train: 0.7064 loss_val: 1.1340 acc_val: 0.7048 time: 0.0071s\n",
      "Epoch: 0710 loss_train: 1.1339 acc_train: 0.6967 loss_val: 1.1330 acc_val: 0.7048 time: 0.0064s\n",
      "Epoch: 0711 loss_train: 1.1237 acc_train: 0.6930 loss_val: 1.1321 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0712 loss_train: 1.1476 acc_train: 0.6782 loss_val: 1.1311 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0713 loss_train: 1.1320 acc_train: 0.7036 loss_val: 1.1301 acc_val: 0.7085 time: 0.0066s\n",
      "Epoch: 0714 loss_train: 1.1113 acc_train: 0.7013 loss_val: 1.1292 acc_val: 0.7085 time: 0.0068s\n",
      "Epoch: 0715 loss_train: 1.1399 acc_train: 0.6985 loss_val: 1.1283 acc_val: 0.7085 time: 0.0071s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0716 loss_train: 1.1359 acc_train: 0.6990 loss_val: 1.1274 acc_val: 0.7085 time: 0.0077s\n",
      "Epoch: 0717 loss_train: 1.1303 acc_train: 0.6865 loss_val: 1.1264 acc_val: 0.7085 time: 0.0066s\n",
      "Epoch: 0718 loss_train: 1.1036 acc_train: 0.7082 loss_val: 1.1254 acc_val: 0.7085 time: 0.0066s\n",
      "Epoch: 0719 loss_train: 1.1200 acc_train: 0.6948 loss_val: 1.1245 acc_val: 0.7085 time: 0.0066s\n",
      "Epoch: 0720 loss_train: 1.1117 acc_train: 0.6898 loss_val: 1.1235 acc_val: 0.7085 time: 0.0069s\n",
      "Epoch: 0721 loss_train: 1.1102 acc_train: 0.6911 loss_val: 1.1226 acc_val: 0.7048 time: 0.0066s\n",
      "Epoch: 0722 loss_train: 1.1169 acc_train: 0.7013 loss_val: 1.1216 acc_val: 0.7048 time: 0.0066s\n",
      "Epoch: 0723 loss_train: 1.1405 acc_train: 0.7027 loss_val: 1.1207 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0724 loss_train: 1.1180 acc_train: 0.6953 loss_val: 1.1198 acc_val: 0.7048 time: 0.0071s\n",
      "Epoch: 0725 loss_train: 1.1159 acc_train: 0.6999 loss_val: 1.1188 acc_val: 0.7048 time: 0.0065s\n",
      "Epoch: 0726 loss_train: 1.1050 acc_train: 0.7105 loss_val: 1.1179 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0727 loss_train: 1.1230 acc_train: 0.7004 loss_val: 1.1170 acc_val: 0.7085 time: 0.0072s\n",
      "Epoch: 0728 loss_train: 1.1100 acc_train: 0.7013 loss_val: 1.1160 acc_val: 0.7085 time: 0.0068s\n",
      "Epoch: 0729 loss_train: 1.1068 acc_train: 0.6907 loss_val: 1.1151 acc_val: 0.7085 time: 0.0067s\n",
      "Epoch: 0730 loss_train: 1.1119 acc_train: 0.6925 loss_val: 1.1142 acc_val: 0.7085 time: 0.0072s\n",
      "Epoch: 0731 loss_train: 1.1146 acc_train: 0.7008 loss_val: 1.1132 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0732 loss_train: 1.1251 acc_train: 0.7018 loss_val: 1.1123 acc_val: 0.7048 time: 0.0070s\n",
      "Epoch: 0733 loss_train: 1.0923 acc_train: 0.7133 loss_val: 1.1113 acc_val: 0.7085 time: 0.0069s\n",
      "Epoch: 0734 loss_train: 1.1087 acc_train: 0.6902 loss_val: 1.1104 acc_val: 0.7085 time: 0.0064s\n",
      "Epoch: 0735 loss_train: 1.1134 acc_train: 0.6851 loss_val: 1.1094 acc_val: 0.7085 time: 0.0070s\n",
      "Epoch: 0736 loss_train: 1.1137 acc_train: 0.6898 loss_val: 1.1085 acc_val: 0.7085 time: 0.0071s\n",
      "Epoch: 0737 loss_train: 1.1094 acc_train: 0.6981 loss_val: 1.1075 acc_val: 0.7085 time: 0.0070s\n",
      "Epoch: 0738 loss_train: 1.0994 acc_train: 0.7008 loss_val: 1.1066 acc_val: 0.7085 time: 0.0068s\n",
      "Epoch: 0739 loss_train: 1.1035 acc_train: 0.6967 loss_val: 1.1057 acc_val: 0.7085 time: 0.0074s\n",
      "Epoch: 0740 loss_train: 1.0802 acc_train: 0.7138 loss_val: 1.1047 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0741 loss_train: 1.0854 acc_train: 0.7087 loss_val: 1.1038 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0742 loss_train: 1.1143 acc_train: 0.6934 loss_val: 1.1029 acc_val: 0.7048 time: 0.0070s\n",
      "Epoch: 0743 loss_train: 1.0951 acc_train: 0.6953 loss_val: 1.1019 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0744 loss_train: 1.0801 acc_train: 0.7068 loss_val: 1.1010 acc_val: 0.7048 time: 0.0073s\n",
      "Epoch: 0745 loss_train: 1.1149 acc_train: 0.6939 loss_val: 1.1001 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0746 loss_train: 1.0965 acc_train: 0.7036 loss_val: 1.0992 acc_val: 0.7048 time: 0.0064s\n",
      "Epoch: 0747 loss_train: 1.0963 acc_train: 0.7142 loss_val: 1.0982 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0748 loss_train: 1.0732 acc_train: 0.7151 loss_val: 1.0973 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0749 loss_train: 1.0920 acc_train: 0.7105 loss_val: 1.0964 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0750 loss_train: 1.1005 acc_train: 0.6990 loss_val: 1.0955 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0751 loss_train: 1.0981 acc_train: 0.7013 loss_val: 1.0946 acc_val: 0.7048 time: 0.0073s\n",
      "Epoch: 0752 loss_train: 1.0879 acc_train: 0.7170 loss_val: 1.0937 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0753 loss_train: 1.0844 acc_train: 0.7073 loss_val: 1.0928 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0754 loss_train: 1.1058 acc_train: 0.6930 loss_val: 1.0919 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0755 loss_train: 1.0942 acc_train: 0.6939 loss_val: 1.0910 acc_val: 0.7048 time: 0.0065s\n",
      "Epoch: 0756 loss_train: 1.0947 acc_train: 0.7008 loss_val: 1.0902 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0757 loss_train: 1.0908 acc_train: 0.7008 loss_val: 1.0893 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0758 loss_train: 1.0854 acc_train: 0.7027 loss_val: 1.0885 acc_val: 0.7048 time: 0.0065s\n",
      "Epoch: 0759 loss_train: 1.0805 acc_train: 0.6958 loss_val: 1.0876 acc_val: 0.7048 time: 0.0070s\n",
      "Epoch: 0760 loss_train: 1.0680 acc_train: 0.7027 loss_val: 1.0867 acc_val: 0.7048 time: 0.0072s\n",
      "Epoch: 0761 loss_train: 1.0844 acc_train: 0.7124 loss_val: 1.0858 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0762 loss_train: 1.0660 acc_train: 0.7124 loss_val: 1.0848 acc_val: 0.7048 time: 0.0072s\n",
      "Epoch: 0763 loss_train: 1.0883 acc_train: 0.7101 loss_val: 1.0839 acc_val: 0.7048 time: 0.0075s\n",
      "Epoch: 0764 loss_train: 1.1020 acc_train: 0.6981 loss_val: 1.0829 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0765 loss_train: 1.0631 acc_train: 0.7147 loss_val: 1.0820 acc_val: 0.7048 time: 0.0068s\n",
      "Epoch: 0766 loss_train: 1.0876 acc_train: 0.7050 loss_val: 1.0811 acc_val: 0.7048 time: 0.0069s\n",
      "Epoch: 0767 loss_train: 1.0810 acc_train: 0.6967 loss_val: 1.0802 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0768 loss_train: 1.0773 acc_train: 0.6994 loss_val: 1.0793 acc_val: 0.7048 time: 0.0076s\n",
      "Epoch: 0769 loss_train: 1.0677 acc_train: 0.7202 loss_val: 1.0784 acc_val: 0.7048 time: 0.0067s\n",
      "Epoch: 0770 loss_train: 1.0646 acc_train: 0.7105 loss_val: 1.0774 acc_val: 0.7048 time: 0.0073s\n",
      "Epoch: 0771 loss_train: 1.0743 acc_train: 0.7018 loss_val: 1.0765 acc_val: 0.7085 time: 0.0072s\n",
      "Epoch: 0772 loss_train: 1.0736 acc_train: 0.7114 loss_val: 1.0756 acc_val: 0.7085 time: 0.0068s\n",
      "Epoch: 0773 loss_train: 1.0707 acc_train: 0.7031 loss_val: 1.0747 acc_val: 0.7085 time: 0.0066s\n",
      "Epoch: 0774 loss_train: 1.0828 acc_train: 0.7082 loss_val: 1.0738 acc_val: 0.7085 time: 0.0067s\n",
      "Epoch: 0775 loss_train: 1.0550 acc_train: 0.7091 loss_val: 1.0730 acc_val: 0.7122 time: 0.0065s\n",
      "Epoch: 0776 loss_train: 1.0689 acc_train: 0.7013 loss_val: 1.0721 acc_val: 0.7122 time: 0.0069s\n",
      "Epoch: 0777 loss_train: 1.0574 acc_train: 0.7175 loss_val: 1.0713 acc_val: 0.7122 time: 0.0067s\n",
      "Epoch: 0778 loss_train: 1.0848 acc_train: 0.7045 loss_val: 1.0705 acc_val: 0.7159 time: 0.0068s\n",
      "Epoch: 0779 loss_train: 1.0593 acc_train: 0.7087 loss_val: 1.0697 acc_val: 0.7159 time: 0.0069s\n",
      "Epoch: 0780 loss_train: 1.0642 acc_train: 0.7151 loss_val: 1.0689 acc_val: 0.7159 time: 0.0070s\n",
      "Epoch: 0781 loss_train: 1.0602 acc_train: 0.7161 loss_val: 1.0682 acc_val: 0.7159 time: 0.0065s\n",
      "Epoch: 0782 loss_train: 1.0709 acc_train: 0.7018 loss_val: 1.0674 acc_val: 0.7159 time: 0.0068s\n",
      "Epoch: 0783 loss_train: 1.0676 acc_train: 0.7031 loss_val: 1.0666 acc_val: 0.7159 time: 0.0073s\n",
      "Epoch: 0784 loss_train: 1.0495 acc_train: 0.7091 loss_val: 1.0658 acc_val: 0.7159 time: 0.0068s\n",
      "Epoch: 0785 loss_train: 1.0449 acc_train: 0.7161 loss_val: 1.0650 acc_val: 0.7159 time: 0.0068s\n",
      "Epoch: 0786 loss_train: 1.0956 acc_train: 0.6907 loss_val: 1.0642 acc_val: 0.7159 time: 0.0068s\n",
      "Epoch: 0787 loss_train: 1.0808 acc_train: 0.7027 loss_val: 1.0634 acc_val: 0.7159 time: 0.0073s\n",
      "Epoch: 0788 loss_train: 1.0710 acc_train: 0.6990 loss_val: 1.0626 acc_val: 0.7159 time: 0.0071s\n",
      "Epoch: 0789 loss_train: 1.0491 acc_train: 0.7059 loss_val: 1.0618 acc_val: 0.7159 time: 0.0071s\n",
      "Epoch: 0790 loss_train: 1.0573 acc_train: 0.7165 loss_val: 1.0609 acc_val: 0.7159 time: 0.0065s\n",
      "Epoch: 0791 loss_train: 1.0764 acc_train: 0.7054 loss_val: 1.0601 acc_val: 0.7159 time: 0.0070s\n",
      "Epoch: 0792 loss_train: 1.0589 acc_train: 0.7184 loss_val: 1.0592 acc_val: 0.7196 time: 0.0072s\n",
      "Epoch: 0793 loss_train: 1.0695 acc_train: 0.7091 loss_val: 1.0584 acc_val: 0.7196 time: 0.0065s\n",
      "Epoch: 0794 loss_train: 1.0536 acc_train: 0.7151 loss_val: 1.0576 acc_val: 0.7232 time: 0.0072s\n",
      "Epoch: 0795 loss_train: 1.0679 acc_train: 0.7050 loss_val: 1.0568 acc_val: 0.7232 time: 0.0072s\n",
      "Epoch: 0796 loss_train: 1.0526 acc_train: 0.7133 loss_val: 1.0560 acc_val: 0.7232 time: 0.0068s\n",
      "Epoch: 0797 loss_train: 1.0330 acc_train: 0.7193 loss_val: 1.0551 acc_val: 0.7196 time: 0.0068s\n",
      "Epoch: 0798 loss_train: 1.0507 acc_train: 0.7202 loss_val: 1.0542 acc_val: 0.7159 time: 0.0068s\n",
      "Epoch: 0799 loss_train: 1.0476 acc_train: 0.7096 loss_val: 1.0534 acc_val: 0.7159 time: 0.0066s\n",
      "Epoch: 0800 loss_train: 1.0327 acc_train: 0.7175 loss_val: 1.0525 acc_val: 0.7159 time: 0.0072s\n",
      "Epoch: 0801 loss_train: 1.0546 acc_train: 0.7165 loss_val: 1.0517 acc_val: 0.7159 time: 0.0066s\n",
      "Epoch: 0802 loss_train: 1.0603 acc_train: 0.7004 loss_val: 1.0509 acc_val: 0.7159 time: 0.0067s\n",
      "Epoch: 0803 loss_train: 1.0485 acc_train: 0.7207 loss_val: 1.0500 acc_val: 0.7159 time: 0.0071s\n",
      "Epoch: 0804 loss_train: 1.0388 acc_train: 0.7188 loss_val: 1.0492 acc_val: 0.7159 time: 0.0072s\n",
      "Epoch: 0805 loss_train: 1.0336 acc_train: 0.7207 loss_val: 1.0484 acc_val: 0.7159 time: 0.0063s\n",
      "Epoch: 0806 loss_train: 1.0323 acc_train: 0.7138 loss_val: 1.0475 acc_val: 0.7196 time: 0.0066s\n",
      "Epoch: 0807 loss_train: 1.0509 acc_train: 0.7119 loss_val: 1.0467 acc_val: 0.7232 time: 0.0068s\n",
      "Epoch: 0808 loss_train: 1.0496 acc_train: 0.7161 loss_val: 1.0460 acc_val: 0.7232 time: 0.0068s\n",
      "Epoch: 0809 loss_train: 1.0601 acc_train: 0.7059 loss_val: 1.0452 acc_val: 0.7269 time: 0.0067s\n",
      "Epoch: 0810 loss_train: 1.0484 acc_train: 0.7050 loss_val: 1.0444 acc_val: 0.7269 time: 0.0068s\n",
      "Epoch: 0811 loss_train: 1.0516 acc_train: 0.7128 loss_val: 1.0436 acc_val: 0.7269 time: 0.0067s\n",
      "Epoch: 0812 loss_train: 1.0241 acc_train: 0.7276 loss_val: 1.0429 acc_val: 0.7269 time: 0.0071s\n",
      "Epoch: 0813 loss_train: 1.0524 acc_train: 0.7064 loss_val: 1.0421 acc_val: 0.7269 time: 0.0071s\n",
      "Epoch: 0814 loss_train: 1.0236 acc_train: 0.7179 loss_val: 1.0413 acc_val: 0.7269 time: 0.0065s\n",
      "Epoch: 0815 loss_train: 1.0514 acc_train: 0.7216 loss_val: 1.0405 acc_val: 0.7269 time: 0.0071s\n",
      "Epoch: 0816 loss_train: 1.0634 acc_train: 0.7156 loss_val: 1.0397 acc_val: 0.7269 time: 0.0072s\n",
      "Epoch: 0817 loss_train: 1.0468 acc_train: 0.7170 loss_val: 1.0389 acc_val: 0.7269 time: 0.0067s\n",
      "Epoch: 0818 loss_train: 1.0581 acc_train: 0.7064 loss_val: 1.0382 acc_val: 0.7269 time: 0.0066s\n",
      "Epoch: 0819 loss_train: 1.0325 acc_train: 0.7235 loss_val: 1.0375 acc_val: 0.7269 time: 0.0069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0820 loss_train: 1.0508 acc_train: 0.7262 loss_val: 1.0368 acc_val: 0.7269 time: 0.0075s\n",
      "Epoch: 0821 loss_train: 1.0462 acc_train: 0.7184 loss_val: 1.0361 acc_val: 0.7232 time: 0.0067s\n",
      "Epoch: 0822 loss_train: 1.0327 acc_train: 0.7161 loss_val: 1.0353 acc_val: 0.7232 time: 0.0067s\n",
      "Epoch: 0823 loss_train: 1.0221 acc_train: 0.7091 loss_val: 1.0346 acc_val: 0.7269 time: 0.0066s\n",
      "Epoch: 0824 loss_train: 1.0568 acc_train: 0.7045 loss_val: 1.0339 acc_val: 0.7269 time: 0.0070s\n",
      "Epoch: 0825 loss_train: 1.0321 acc_train: 0.7207 loss_val: 1.0331 acc_val: 0.7269 time: 0.0066s\n",
      "Epoch: 0826 loss_train: 1.0387 acc_train: 0.7073 loss_val: 1.0324 acc_val: 0.7306 time: 0.0066s\n",
      "Epoch: 0827 loss_train: 1.0319 acc_train: 0.7202 loss_val: 1.0316 acc_val: 0.7306 time: 0.0070s\n",
      "Epoch: 0828 loss_train: 1.0334 acc_train: 0.7216 loss_val: 1.0308 acc_val: 0.7306 time: 0.0072s\n",
      "Epoch: 0829 loss_train: 1.0337 acc_train: 0.7105 loss_val: 1.0300 acc_val: 0.7306 time: 0.0064s\n",
      "Epoch: 0830 loss_train: 1.0263 acc_train: 0.7239 loss_val: 1.0292 acc_val: 0.7306 time: 0.0072s\n",
      "Epoch: 0831 loss_train: 1.0346 acc_train: 0.7244 loss_val: 1.0283 acc_val: 0.7306 time: 0.0070s\n",
      "Epoch: 0832 loss_train: 1.0261 acc_train: 0.7156 loss_val: 1.0275 acc_val: 0.7306 time: 0.0068s\n",
      "Epoch: 0833 loss_train: 1.0246 acc_train: 0.7230 loss_val: 1.0267 acc_val: 0.7306 time: 0.0067s\n",
      "Epoch: 0834 loss_train: 1.0277 acc_train: 0.7207 loss_val: 1.0258 acc_val: 0.7306 time: 0.0067s\n",
      "Epoch: 0835 loss_train: 1.0237 acc_train: 0.7221 loss_val: 1.0250 acc_val: 0.7306 time: 0.0066s\n",
      "Epoch: 0836 loss_train: 1.0199 acc_train: 0.7235 loss_val: 1.0241 acc_val: 0.7343 time: 0.0071s\n",
      "Epoch: 0837 loss_train: 1.0213 acc_train: 0.7258 loss_val: 1.0233 acc_val: 0.7343 time: 0.0066s\n",
      "Epoch: 0838 loss_train: 1.0140 acc_train: 0.7221 loss_val: 1.0225 acc_val: 0.7343 time: 0.0065s\n",
      "Epoch: 0839 loss_train: 1.0119 acc_train: 0.7207 loss_val: 1.0217 acc_val: 0.7343 time: 0.0071s\n",
      "Epoch: 0840 loss_train: 1.0261 acc_train: 0.7244 loss_val: 1.0209 acc_val: 0.7343 time: 0.0073s\n",
      "Epoch: 0841 loss_train: 1.0254 acc_train: 0.7225 loss_val: 1.0201 acc_val: 0.7343 time: 0.0064s\n",
      "Epoch: 0842 loss_train: 1.0085 acc_train: 0.7271 loss_val: 1.0192 acc_val: 0.7343 time: 0.0071s\n",
      "Epoch: 0843 loss_train: 1.0378 acc_train: 0.7156 loss_val: 1.0185 acc_val: 0.7343 time: 0.0069s\n",
      "Epoch: 0844 loss_train: 1.0318 acc_train: 0.7188 loss_val: 1.0177 acc_val: 0.7343 time: 0.0068s\n",
      "Epoch: 0845 loss_train: 1.0250 acc_train: 0.7248 loss_val: 1.0170 acc_val: 0.7343 time: 0.0068s\n",
      "Epoch: 0846 loss_train: 1.0260 acc_train: 0.7230 loss_val: 1.0162 acc_val: 0.7343 time: 0.0072s\n",
      "Epoch: 0847 loss_train: 1.0056 acc_train: 0.7175 loss_val: 1.0155 acc_val: 0.7343 time: 0.0071s\n",
      "Epoch: 0848 loss_train: 1.0212 acc_train: 0.7147 loss_val: 1.0149 acc_val: 0.7343 time: 0.0070s\n",
      "Epoch: 0849 loss_train: 1.0149 acc_train: 0.7124 loss_val: 1.0142 acc_val: 0.7343 time: 0.0068s\n",
      "Epoch: 0850 loss_train: 1.0226 acc_train: 0.7105 loss_val: 1.0136 acc_val: 0.7343 time: 0.0066s\n",
      "Epoch: 0851 loss_train: 1.0023 acc_train: 0.7239 loss_val: 1.0130 acc_val: 0.7343 time: 0.0073s\n",
      "Epoch: 0852 loss_train: 1.0176 acc_train: 0.7239 loss_val: 1.0124 acc_val: 0.7343 time: 0.0072s\n",
      "Epoch: 0853 loss_train: 1.0053 acc_train: 0.7281 loss_val: 1.0118 acc_val: 0.7343 time: 0.0065s\n",
      "Epoch: 0854 loss_train: 1.0065 acc_train: 0.7336 loss_val: 1.0112 acc_val: 0.7343 time: 0.0070s\n",
      "Epoch: 0855 loss_train: 1.0070 acc_train: 0.7304 loss_val: 1.0106 acc_val: 0.7343 time: 0.0071s\n",
      "Epoch: 0856 loss_train: 1.0045 acc_train: 0.7235 loss_val: 1.0100 acc_val: 0.7343 time: 0.0069s\n",
      "Epoch: 0857 loss_train: 1.0302 acc_train: 0.7225 loss_val: 1.0093 acc_val: 0.7343 time: 0.0067s\n",
      "Epoch: 0858 loss_train: 1.0181 acc_train: 0.7142 loss_val: 1.0087 acc_val: 0.7343 time: 0.0070s\n",
      "Epoch: 0859 loss_train: 1.0122 acc_train: 0.7198 loss_val: 1.0080 acc_val: 0.7343 time: 0.0071s\n",
      "Epoch: 0860 loss_train: 1.0104 acc_train: 0.7419 loss_val: 1.0073 acc_val: 0.7343 time: 0.0070s\n",
      "Epoch: 0861 loss_train: 0.9923 acc_train: 0.7239 loss_val: 1.0066 acc_val: 0.7343 time: 0.0068s\n",
      "Epoch: 0862 loss_train: 1.0032 acc_train: 0.7262 loss_val: 1.0059 acc_val: 0.7343 time: 0.0067s\n",
      "Epoch: 0863 loss_train: 1.0052 acc_train: 0.7331 loss_val: 1.0052 acc_val: 0.7343 time: 0.0070s\n",
      "Epoch: 0864 loss_train: 1.0039 acc_train: 0.7271 loss_val: 1.0044 acc_val: 0.7343 time: 0.0071s\n",
      "Epoch: 0865 loss_train: 1.0173 acc_train: 0.7313 loss_val: 1.0037 acc_val: 0.7380 time: 0.0069s\n",
      "Epoch: 0866 loss_train: 1.0031 acc_train: 0.7341 loss_val: 1.0029 acc_val: 0.7380 time: 0.0068s\n",
      "Epoch: 0867 loss_train: 1.0249 acc_train: 0.7142 loss_val: 1.0022 acc_val: 0.7380 time: 0.0072s\n",
      "Epoch: 0868 loss_train: 0.9873 acc_train: 0.7290 loss_val: 1.0015 acc_val: 0.7380 time: 0.0069s\n",
      "Epoch: 0869 loss_train: 1.0062 acc_train: 0.7235 loss_val: 1.0007 acc_val: 0.7380 time: 0.0071s\n",
      "Epoch: 0870 loss_train: 1.0071 acc_train: 0.7207 loss_val: 1.0000 acc_val: 0.7380 time: 0.0068s\n",
      "Epoch: 0871 loss_train: 1.0053 acc_train: 0.7262 loss_val: 0.9993 acc_val: 0.7380 time: 0.0071s\n",
      "Epoch: 0872 loss_train: 0.9938 acc_train: 0.7253 loss_val: 0.9986 acc_val: 0.7380 time: 0.0074s\n",
      "Epoch: 0873 loss_train: 0.9893 acc_train: 0.7392 loss_val: 0.9978 acc_val: 0.7417 time: 0.0066s\n",
      "Epoch: 0874 loss_train: 0.9990 acc_train: 0.7433 loss_val: 0.9971 acc_val: 0.7417 time: 0.0073s\n",
      "Epoch: 0875 loss_train: 0.9852 acc_train: 0.7548 loss_val: 0.9963 acc_val: 0.7417 time: 0.0070s\n",
      "Epoch: 0876 loss_train: 0.9881 acc_train: 0.7442 loss_val: 0.9956 acc_val: 0.7417 time: 0.0068s\n",
      "Epoch: 0877 loss_train: 0.9903 acc_train: 0.7336 loss_val: 0.9949 acc_val: 0.7417 time: 0.0066s\n",
      "Epoch: 0878 loss_train: 0.9905 acc_train: 0.7364 loss_val: 0.9941 acc_val: 0.7417 time: 0.0066s\n",
      "Epoch: 0879 loss_train: 1.0087 acc_train: 0.7248 loss_val: 0.9934 acc_val: 0.7417 time: 0.0068s\n",
      "Epoch: 0880 loss_train: 0.9897 acc_train: 0.7410 loss_val: 0.9927 acc_val: 0.7417 time: 0.0070s\n",
      "Epoch: 0881 loss_train: 0.9861 acc_train: 0.7350 loss_val: 0.9920 acc_val: 0.7417 time: 0.0066s\n",
      "Epoch: 0882 loss_train: 0.9991 acc_train: 0.7211 loss_val: 0.9913 acc_val: 0.7417 time: 0.0065s\n",
      "Epoch: 0883 loss_train: 0.9976 acc_train: 0.7290 loss_val: 0.9906 acc_val: 0.7417 time: 0.0069s\n",
      "Epoch: 0884 loss_train: 0.9802 acc_train: 0.7410 loss_val: 0.9899 acc_val: 0.7417 time: 0.0070s\n",
      "Epoch: 0885 loss_train: 0.9836 acc_train: 0.7378 loss_val: 0.9893 acc_val: 0.7417 time: 0.0090s\n",
      "Epoch: 0886 loss_train: 0.9831 acc_train: 0.7433 loss_val: 0.9885 acc_val: 0.7454 time: 0.0068s\n",
      "Epoch: 0887 loss_train: 1.0087 acc_train: 0.7244 loss_val: 0.9879 acc_val: 0.7454 time: 0.0069s\n",
      "Epoch: 0888 loss_train: 0.9838 acc_train: 0.7401 loss_val: 0.9872 acc_val: 0.7454 time: 0.0072s\n",
      "Epoch: 0889 loss_train: 0.9752 acc_train: 0.7267 loss_val: 0.9865 acc_val: 0.7454 time: 0.0068s\n",
      "Epoch: 0890 loss_train: 1.0042 acc_train: 0.7359 loss_val: 0.9858 acc_val: 0.7454 time: 0.0068s\n",
      "Epoch: 0891 loss_train: 0.9863 acc_train: 0.7507 loss_val: 0.9851 acc_val: 0.7454 time: 0.0069s\n",
      "Epoch: 0892 loss_train: 0.9681 acc_train: 0.7336 loss_val: 0.9844 acc_val: 0.7454 time: 0.0064s\n",
      "Epoch: 0893 loss_train: 0.9903 acc_train: 0.7392 loss_val: 0.9837 acc_val: 0.7454 time: 0.0068s\n",
      "Epoch: 0894 loss_train: 0.9816 acc_train: 0.7447 loss_val: 0.9831 acc_val: 0.7491 time: 0.0068s\n",
      "Epoch: 0895 loss_train: 0.9864 acc_train: 0.7438 loss_val: 0.9824 acc_val: 0.7491 time: 0.0069s\n",
      "Epoch: 0896 loss_train: 0.9708 acc_train: 0.7530 loss_val: 0.9818 acc_val: 0.7491 time: 0.0071s\n",
      "Epoch: 0897 loss_train: 0.9738 acc_train: 0.7461 loss_val: 0.9811 acc_val: 0.7491 time: 0.0070s\n",
      "Epoch: 0898 loss_train: 0.9882 acc_train: 0.7410 loss_val: 0.9805 acc_val: 0.7491 time: 0.0065s\n",
      "Epoch: 0899 loss_train: 0.9800 acc_train: 0.7322 loss_val: 0.9798 acc_val: 0.7491 time: 0.0071s\n",
      "Epoch: 0900 loss_train: 0.9939 acc_train: 0.7405 loss_val: 0.9792 acc_val: 0.7491 time: 0.0073s\n",
      "Epoch: 0901 loss_train: 0.9747 acc_train: 0.7318 loss_val: 0.9786 acc_val: 0.7491 time: 0.0066s\n",
      "Epoch: 0902 loss_train: 0.9878 acc_train: 0.7392 loss_val: 0.9780 acc_val: 0.7454 time: 0.0069s\n",
      "Epoch: 0903 loss_train: 0.9801 acc_train: 0.7401 loss_val: 0.9773 acc_val: 0.7454 time: 0.0070s\n",
      "Epoch: 0904 loss_train: 0.9727 acc_train: 0.7465 loss_val: 0.9767 acc_val: 0.7454 time: 0.0068s\n",
      "Epoch: 0905 loss_train: 0.9582 acc_train: 0.7567 loss_val: 0.9761 acc_val: 0.7454 time: 0.0070s\n",
      "Epoch: 0906 loss_train: 0.9681 acc_train: 0.7419 loss_val: 0.9755 acc_val: 0.7454 time: 0.0067s\n",
      "Epoch: 0907 loss_train: 1.0000 acc_train: 0.7405 loss_val: 0.9749 acc_val: 0.7491 time: 0.0068s\n",
      "Epoch: 0908 loss_train: 0.9915 acc_train: 0.7327 loss_val: 0.9743 acc_val: 0.7491 time: 0.0071s\n",
      "Epoch: 0909 loss_train: 0.9395 acc_train: 0.7502 loss_val: 0.9737 acc_val: 0.7528 time: 0.0068s\n",
      "Epoch: 0910 loss_train: 0.9966 acc_train: 0.7415 loss_val: 0.9731 acc_val: 0.7528 time: 0.0065s\n",
      "Epoch: 0911 loss_train: 0.9802 acc_train: 0.7235 loss_val: 0.9725 acc_val: 0.7528 time: 0.0070s\n",
      "Epoch: 0912 loss_train: 0.9536 acc_train: 0.7502 loss_val: 0.9719 acc_val: 0.7528 time: 0.0073s\n",
      "Epoch: 0913 loss_train: 0.9729 acc_train: 0.7581 loss_val: 0.9712 acc_val: 0.7528 time: 0.0065s\n",
      "Epoch: 0914 loss_train: 0.9831 acc_train: 0.7498 loss_val: 0.9706 acc_val: 0.7565 time: 0.0069s\n",
      "Epoch: 0915 loss_train: 0.9715 acc_train: 0.7553 loss_val: 0.9699 acc_val: 0.7565 time: 0.0072s\n",
      "Epoch: 0916 loss_train: 0.9705 acc_train: 0.7548 loss_val: 0.9693 acc_val: 0.7565 time: 0.0069s\n",
      "Epoch: 0917 loss_train: 0.9765 acc_train: 0.7341 loss_val: 0.9686 acc_val: 0.7565 time: 0.0067s\n",
      "Epoch: 0918 loss_train: 0.9657 acc_train: 0.7456 loss_val: 0.9679 acc_val: 0.7528 time: 0.0073s\n",
      "Epoch: 0919 loss_train: 0.9759 acc_train: 0.7401 loss_val: 0.9673 acc_val: 0.7528 time: 0.0070s\n",
      "Epoch: 0920 loss_train: 0.9738 acc_train: 0.7488 loss_val: 0.9666 acc_val: 0.7528 time: 0.0070s\n",
      "Epoch: 0921 loss_train: 0.9953 acc_train: 0.7553 loss_val: 0.9660 acc_val: 0.7528 time: 0.0068s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0922 loss_train: 0.9693 acc_train: 0.7470 loss_val: 0.9653 acc_val: 0.7528 time: 0.0071s\n",
      "Epoch: 0923 loss_train: 0.9817 acc_train: 0.7382 loss_val: 0.9647 acc_val: 0.7528 time: 0.0074s\n",
      "Epoch: 0924 loss_train: 0.9721 acc_train: 0.7438 loss_val: 0.9640 acc_val: 0.7528 time: 0.0070s\n",
      "Epoch: 0925 loss_train: 0.9608 acc_train: 0.7530 loss_val: 0.9633 acc_val: 0.7491 time: 0.0066s\n",
      "Epoch: 0926 loss_train: 0.9726 acc_train: 0.7415 loss_val: 0.9627 acc_val: 0.7491 time: 0.0068s\n",
      "Epoch: 0927 loss_train: 0.9817 acc_train: 0.7447 loss_val: 0.9620 acc_val: 0.7491 time: 0.0070s\n",
      "Epoch: 0928 loss_train: 0.9496 acc_train: 0.7548 loss_val: 0.9614 acc_val: 0.7528 time: 0.0068s\n",
      "Epoch: 0929 loss_train: 0.9379 acc_train: 0.7553 loss_val: 0.9607 acc_val: 0.7528 time: 0.0069s\n",
      "Epoch: 0930 loss_train: 0.9755 acc_train: 0.7452 loss_val: 0.9601 acc_val: 0.7528 time: 0.0068s\n",
      "Epoch: 0931 loss_train: 0.9734 acc_train: 0.7355 loss_val: 0.9595 acc_val: 0.7528 time: 0.0067s\n",
      "Epoch: 0932 loss_train: 0.9569 acc_train: 0.7475 loss_val: 0.9588 acc_val: 0.7528 time: 0.0072s\n",
      "Epoch: 0933 loss_train: 0.9704 acc_train: 0.7475 loss_val: 0.9582 acc_val: 0.7528 time: 0.0072s\n",
      "Epoch: 0934 loss_train: 0.9394 acc_train: 0.7530 loss_val: 0.9575 acc_val: 0.7565 time: 0.0063s\n",
      "Epoch: 0935 loss_train: 0.9645 acc_train: 0.7525 loss_val: 0.9568 acc_val: 0.7565 time: 0.0069s\n",
      "Epoch: 0936 loss_train: 0.9444 acc_train: 0.7608 loss_val: 0.9561 acc_val: 0.7565 time: 0.0069s\n",
      "Epoch: 0937 loss_train: 0.9562 acc_train: 0.7576 loss_val: 0.9554 acc_val: 0.7565 time: 0.0064s\n",
      "Epoch: 0938 loss_train: 0.9552 acc_train: 0.7608 loss_val: 0.9547 acc_val: 0.7565 time: 0.0068s\n",
      "Epoch: 0939 loss_train: 0.9627 acc_train: 0.7475 loss_val: 0.9541 acc_val: 0.7565 time: 0.0075s\n",
      "Epoch: 0940 loss_train: 0.9504 acc_train: 0.7488 loss_val: 0.9534 acc_val: 0.7638 time: 0.0069s\n",
      "Epoch: 0941 loss_train: 0.9473 acc_train: 0.7622 loss_val: 0.9527 acc_val: 0.7638 time: 0.0066s\n",
      "Epoch: 0942 loss_train: 0.9561 acc_train: 0.7608 loss_val: 0.9521 acc_val: 0.7638 time: 0.0066s\n",
      "Epoch: 0943 loss_train: 0.9633 acc_train: 0.7567 loss_val: 0.9514 acc_val: 0.7638 time: 0.0072s\n",
      "Epoch: 0944 loss_train: 0.9556 acc_train: 0.7521 loss_val: 0.9508 acc_val: 0.7638 time: 0.0071s\n",
      "Epoch: 0945 loss_train: 0.9468 acc_train: 0.7641 loss_val: 0.9502 acc_val: 0.7675 time: 0.0068s\n",
      "Epoch: 0946 loss_train: 0.9689 acc_train: 0.7507 loss_val: 0.9496 acc_val: 0.7675 time: 0.0065s\n",
      "Epoch: 0947 loss_train: 0.9321 acc_train: 0.7692 loss_val: 0.9490 acc_val: 0.7675 time: 0.0071s\n",
      "Epoch: 0948 loss_train: 0.9512 acc_train: 0.7516 loss_val: 0.9484 acc_val: 0.7675 time: 0.0081s\n",
      "Epoch: 0949 loss_train: 0.9548 acc_train: 0.7507 loss_val: 0.9478 acc_val: 0.7712 time: 0.0065s\n",
      "Epoch: 0950 loss_train: 0.9647 acc_train: 0.7424 loss_val: 0.9473 acc_val: 0.7712 time: 0.0072s\n",
      "Epoch: 0951 loss_train: 0.9442 acc_train: 0.7622 loss_val: 0.9468 acc_val: 0.7712 time: 0.0070s\n",
      "Epoch: 0952 loss_train: 0.9583 acc_train: 0.7498 loss_val: 0.9463 acc_val: 0.7712 time: 0.0068s\n",
      "Epoch: 0953 loss_train: 0.9548 acc_train: 0.7576 loss_val: 0.9458 acc_val: 0.7712 time: 0.0073s\n",
      "Epoch: 0954 loss_train: 0.9635 acc_train: 0.7576 loss_val: 0.9453 acc_val: 0.7638 time: 0.0072s\n",
      "Epoch: 0955 loss_train: 0.9366 acc_train: 0.7645 loss_val: 0.9448 acc_val: 0.7601 time: 0.0066s\n",
      "Epoch: 0956 loss_train: 0.9512 acc_train: 0.7442 loss_val: 0.9443 acc_val: 0.7565 time: 0.0072s\n",
      "Epoch: 0957 loss_train: 0.9585 acc_train: 0.7553 loss_val: 0.9439 acc_val: 0.7565 time: 0.0069s\n",
      "Epoch: 0958 loss_train: 0.9602 acc_train: 0.7475 loss_val: 0.9434 acc_val: 0.7565 time: 0.0067s\n",
      "Epoch: 0959 loss_train: 0.9414 acc_train: 0.7669 loss_val: 0.9429 acc_val: 0.7565 time: 0.0071s\n",
      "Epoch: 0960 loss_train: 0.9433 acc_train: 0.7585 loss_val: 0.9424 acc_val: 0.7565 time: 0.0070s\n",
      "Epoch: 0961 loss_train: 0.9510 acc_train: 0.7548 loss_val: 0.9418 acc_val: 0.7565 time: 0.0065s\n",
      "Epoch: 0962 loss_train: 0.9360 acc_train: 0.7636 loss_val: 0.9413 acc_val: 0.7565 time: 0.0069s\n",
      "Epoch: 0963 loss_train: 0.9533 acc_train: 0.7595 loss_val: 0.9408 acc_val: 0.7565 time: 0.0071s\n",
      "Epoch: 0964 loss_train: 0.9461 acc_train: 0.7553 loss_val: 0.9402 acc_val: 0.7565 time: 0.0068s\n",
      "Epoch: 0965 loss_train: 0.9483 acc_train: 0.7581 loss_val: 0.9396 acc_val: 0.7565 time: 0.0068s\n",
      "Epoch: 0966 loss_train: 0.9427 acc_train: 0.7562 loss_val: 0.9391 acc_val: 0.7565 time: 0.0068s\n",
      "Epoch: 0967 loss_train: 0.9252 acc_train: 0.7604 loss_val: 0.9385 acc_val: 0.7565 time: 0.0067s\n",
      "Epoch: 0968 loss_train: 0.9386 acc_train: 0.7673 loss_val: 0.9379 acc_val: 0.7565 time: 0.0072s\n",
      "Epoch: 0969 loss_train: 0.9441 acc_train: 0.7655 loss_val: 0.9372 acc_val: 0.7565 time: 0.0069s\n",
      "Epoch: 0970 loss_train: 0.9461 acc_train: 0.7673 loss_val: 0.9366 acc_val: 0.7565 time: 0.0064s\n",
      "Epoch: 0971 loss_train: 0.9349 acc_train: 0.7687 loss_val: 0.9359 acc_val: 0.7601 time: 0.0070s\n",
      "Epoch: 0972 loss_train: 0.9626 acc_train: 0.7562 loss_val: 0.9352 acc_val: 0.7601 time: 0.0076s\n",
      "Epoch: 0973 loss_train: 0.9526 acc_train: 0.7590 loss_val: 0.9346 acc_val: 0.7601 time: 0.0066s\n",
      "Epoch: 0974 loss_train: 0.9455 acc_train: 0.7576 loss_val: 0.9340 acc_val: 0.7601 time: 0.0069s\n",
      "Epoch: 0975 loss_train: 0.9365 acc_train: 0.7636 loss_val: 0.9334 acc_val: 0.7601 time: 0.0071s\n",
      "Epoch: 0976 loss_train: 0.9342 acc_train: 0.7678 loss_val: 0.9327 acc_val: 0.7601 time: 0.0068s\n",
      "Epoch: 0977 loss_train: 0.9549 acc_train: 0.7562 loss_val: 0.9321 acc_val: 0.7601 time: 0.0067s\n",
      "Epoch: 0978 loss_train: 0.9305 acc_train: 0.7655 loss_val: 0.9314 acc_val: 0.7601 time: 0.0067s\n",
      "Epoch: 0979 loss_train: 0.9435 acc_train: 0.7664 loss_val: 0.9307 acc_val: 0.7675 time: 0.0076s\n",
      "Epoch: 0980 loss_train: 0.9321 acc_train: 0.7604 loss_val: 0.9301 acc_val: 0.7675 time: 0.0072s\n",
      "Epoch: 0981 loss_train: 0.9287 acc_train: 0.7618 loss_val: 0.9295 acc_val: 0.7712 time: 0.0065s\n",
      "Epoch: 0982 loss_train: 0.9319 acc_train: 0.7678 loss_val: 0.9289 acc_val: 0.7749 time: 0.0069s\n",
      "Epoch: 0983 loss_train: 0.9358 acc_train: 0.7655 loss_val: 0.9283 acc_val: 0.7749 time: 0.0071s\n",
      "Epoch: 0984 loss_train: 0.9362 acc_train: 0.7692 loss_val: 0.9277 acc_val: 0.7749 time: 0.0069s\n",
      "Epoch: 0985 loss_train: 0.9228 acc_train: 0.7512 loss_val: 0.9271 acc_val: 0.7749 time: 0.0067s\n",
      "Epoch: 0986 loss_train: 0.9330 acc_train: 0.7641 loss_val: 0.9265 acc_val: 0.7749 time: 0.0067s\n",
      "Epoch: 0987 loss_train: 0.9285 acc_train: 0.7645 loss_val: 0.9259 acc_val: 0.7749 time: 0.0068s\n",
      "Epoch: 0988 loss_train: 0.9157 acc_train: 0.7742 loss_val: 0.9253 acc_val: 0.7749 time: 0.0071s\n",
      "Epoch: 0989 loss_train: 0.9281 acc_train: 0.7595 loss_val: 0.9248 acc_val: 0.7749 time: 0.0068s\n",
      "Epoch: 0990 loss_train: 0.9283 acc_train: 0.7692 loss_val: 0.9242 acc_val: 0.7749 time: 0.0065s\n",
      "Epoch: 0991 loss_train: 0.9255 acc_train: 0.7710 loss_val: 0.9236 acc_val: 0.7749 time: 0.0068s\n",
      "Epoch: 0992 loss_train: 0.9455 acc_train: 0.7636 loss_val: 0.9231 acc_val: 0.7786 time: 0.0071s\n",
      "Epoch: 0993 loss_train: 0.9437 acc_train: 0.7530 loss_val: 0.9225 acc_val: 0.7786 time: 0.0066s\n",
      "Epoch: 0994 loss_train: 0.9130 acc_train: 0.7692 loss_val: 0.9220 acc_val: 0.7786 time: 0.0067s\n",
      "Epoch: 0995 loss_train: 0.9385 acc_train: 0.7576 loss_val: 0.9214 acc_val: 0.7786 time: 0.0071s\n",
      "Epoch: 0996 loss_train: 0.9222 acc_train: 0.7752 loss_val: 0.9209 acc_val: 0.7749 time: 0.0070s\n",
      "Epoch: 0997 loss_train: 0.9260 acc_train: 0.7655 loss_val: 0.9203 acc_val: 0.7749 time: 0.0069s\n",
      "Epoch: 0998 loss_train: 0.9238 acc_train: 0.7738 loss_val: 0.9197 acc_val: 0.7749 time: 0.0076s\n",
      "Epoch: 0999 loss_train: 0.9001 acc_train: 0.7682 loss_val: 0.9191 acc_val: 0.7749 time: 0.0068s\n",
      "Epoch: 1000 loss_train: 0.9203 acc_train: 0.7678 loss_val: 0.9185 acc_val: 0.7786 time: 0.0072s\n",
      "Epoch: 1001 loss_train: 0.9172 acc_train: 0.7650 loss_val: 0.9179 acc_val: 0.7786 time: 0.0068s\n",
      "Epoch: 1002 loss_train: 0.9171 acc_train: 0.7779 loss_val: 0.9173 acc_val: 0.7786 time: 0.0064s\n",
      "Epoch: 1003 loss_train: 0.9088 acc_train: 0.7798 loss_val: 0.9166 acc_val: 0.7786 time: 0.0069s\n",
      "Epoch: 1004 loss_train: 0.9167 acc_train: 0.7627 loss_val: 0.9160 acc_val: 0.7786 time: 0.0071s\n",
      "Epoch: 1005 loss_train: 0.9281 acc_train: 0.7627 loss_val: 0.9154 acc_val: 0.7786 time: 0.0065s\n",
      "Epoch: 1006 loss_train: 0.8947 acc_train: 0.7752 loss_val: 0.9149 acc_val: 0.7786 time: 0.0071s\n",
      "Epoch: 1007 loss_train: 0.9143 acc_train: 0.7715 loss_val: 0.9143 acc_val: 0.7786 time: 0.0071s\n",
      "Epoch: 1008 loss_train: 0.8938 acc_train: 0.7692 loss_val: 0.9138 acc_val: 0.7786 time: 0.0068s\n",
      "Epoch: 1009 loss_train: 0.9127 acc_train: 0.7775 loss_val: 0.9133 acc_val: 0.7786 time: 0.0066s\n",
      "Epoch: 1010 loss_train: 0.9128 acc_train: 0.7669 loss_val: 0.9127 acc_val: 0.7786 time: 0.0070s\n",
      "Epoch: 1011 loss_train: 0.9271 acc_train: 0.7581 loss_val: 0.9122 acc_val: 0.7786 time: 0.0068s\n",
      "Epoch: 1012 loss_train: 0.9258 acc_train: 0.7599 loss_val: 0.9117 acc_val: 0.7786 time: 0.0070s\n",
      "Epoch: 1013 loss_train: 0.9054 acc_train: 0.7747 loss_val: 0.9111 acc_val: 0.7860 time: 0.0070s\n",
      "Epoch: 1014 loss_train: 0.9132 acc_train: 0.7733 loss_val: 0.9106 acc_val: 0.7860 time: 0.0067s\n",
      "Epoch: 1015 loss_train: 0.9049 acc_train: 0.7779 loss_val: 0.9100 acc_val: 0.7860 time: 0.0069s\n",
      "Epoch: 1016 loss_train: 0.9111 acc_train: 0.7678 loss_val: 0.9094 acc_val: 0.7934 time: 0.0071s\n",
      "Epoch: 1017 loss_train: 0.9003 acc_train: 0.7830 loss_val: 0.9088 acc_val: 0.7970 time: 0.0065s\n",
      "Epoch: 1018 loss_train: 0.9121 acc_train: 0.7669 loss_val: 0.9082 acc_val: 0.7970 time: 0.0069s\n",
      "Epoch: 1019 loss_train: 0.8889 acc_train: 0.7830 loss_val: 0.9076 acc_val: 0.7970 time: 0.0074s\n",
      "Epoch: 1020 loss_train: 0.9000 acc_train: 0.7812 loss_val: 0.9070 acc_val: 0.7897 time: 0.0067s\n",
      "Epoch: 1021 loss_train: 0.9294 acc_train: 0.7553 loss_val: 0.9064 acc_val: 0.7897 time: 0.0068s\n",
      "Epoch: 1022 loss_train: 0.9198 acc_train: 0.7678 loss_val: 0.9058 acc_val: 0.7897 time: 0.0069s\n",
      "Epoch: 1023 loss_train: 0.8997 acc_train: 0.7784 loss_val: 0.9053 acc_val: 0.7897 time: 0.0066s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1024 loss_train: 0.9126 acc_train: 0.7530 loss_val: 0.9047 acc_val: 0.7897 time: 0.0076s\n",
      "Epoch: 1025 loss_train: 0.9128 acc_train: 0.7779 loss_val: 0.9042 acc_val: 0.7897 time: 0.0066s\n",
      "Epoch: 1026 loss_train: 0.8888 acc_train: 0.7752 loss_val: 0.9036 acc_val: 0.7897 time: 0.0074s\n",
      "Epoch: 1027 loss_train: 0.9029 acc_train: 0.7650 loss_val: 0.9030 acc_val: 0.7897 time: 0.0071s\n",
      "Epoch: 1028 loss_train: 0.9164 acc_train: 0.7724 loss_val: 0.9025 acc_val: 0.7934 time: 0.0069s\n",
      "Epoch: 1029 loss_train: 0.9101 acc_train: 0.7701 loss_val: 0.9020 acc_val: 0.7934 time: 0.0070s\n",
      "Epoch: 1030 loss_train: 0.9153 acc_train: 0.7715 loss_val: 0.9015 acc_val: 0.7934 time: 0.0070s\n",
      "Epoch: 1031 loss_train: 0.9091 acc_train: 0.7761 loss_val: 0.9010 acc_val: 0.7934 time: 0.0067s\n",
      "Epoch: 1032 loss_train: 0.9065 acc_train: 0.7747 loss_val: 0.9005 acc_val: 0.7934 time: 0.0070s\n",
      "Epoch: 1033 loss_train: 0.9065 acc_train: 0.7682 loss_val: 0.9000 acc_val: 0.7934 time: 0.0068s\n",
      "Epoch: 1034 loss_train: 0.9185 acc_train: 0.7608 loss_val: 0.8995 acc_val: 0.7934 time: 0.0071s\n",
      "Epoch: 1035 loss_train: 0.9208 acc_train: 0.7595 loss_val: 0.8991 acc_val: 0.7934 time: 0.0070s\n",
      "Epoch: 1036 loss_train: 0.9184 acc_train: 0.7705 loss_val: 0.8988 acc_val: 0.7934 time: 0.0071s\n",
      "Epoch: 1037 loss_train: 0.9135 acc_train: 0.7747 loss_val: 0.8984 acc_val: 0.7934 time: 0.0067s\n",
      "Epoch: 1038 loss_train: 0.8914 acc_train: 0.7793 loss_val: 0.8980 acc_val: 0.7934 time: 0.0068s\n",
      "Epoch: 1039 loss_train: 0.9220 acc_train: 0.7692 loss_val: 0.8977 acc_val: 0.7970 time: 0.0070s\n",
      "Epoch: 1040 loss_train: 0.8901 acc_train: 0.7844 loss_val: 0.8973 acc_val: 0.7934 time: 0.0068s\n",
      "Epoch: 1041 loss_train: 0.9180 acc_train: 0.7701 loss_val: 0.8969 acc_val: 0.7934 time: 0.0066s\n",
      "Epoch: 1042 loss_train: 0.8872 acc_train: 0.7798 loss_val: 0.8965 acc_val: 0.7934 time: 0.0067s\n",
      "Epoch: 1043 loss_train: 0.8843 acc_train: 0.7941 loss_val: 0.8959 acc_val: 0.7934 time: 0.0071s\n",
      "Epoch: 1044 loss_train: 0.8967 acc_train: 0.7881 loss_val: 0.8954 acc_val: 0.7934 time: 0.0070s\n",
      "Epoch: 1045 loss_train: 0.8968 acc_train: 0.7724 loss_val: 0.8949 acc_val: 0.7934 time: 0.0066s\n",
      "Epoch: 1046 loss_train: 0.8924 acc_train: 0.7821 loss_val: 0.8943 acc_val: 0.7970 time: 0.0065s\n",
      "Epoch: 1047 loss_train: 0.9011 acc_train: 0.7747 loss_val: 0.8937 acc_val: 0.7970 time: 0.0071s\n",
      "Epoch: 1048 loss_train: 0.9078 acc_train: 0.7752 loss_val: 0.8932 acc_val: 0.7970 time: 0.0072s\n",
      "Epoch: 1049 loss_train: 0.9035 acc_train: 0.7872 loss_val: 0.8926 acc_val: 0.8007 time: 0.0066s\n",
      "Epoch: 1050 loss_train: 0.8869 acc_train: 0.7825 loss_val: 0.8920 acc_val: 0.8007 time: 0.0076s\n",
      "Epoch: 1051 loss_train: 0.9072 acc_train: 0.7761 loss_val: 0.8914 acc_val: 0.8007 time: 0.0071s\n",
      "Epoch: 1052 loss_train: 0.9086 acc_train: 0.7890 loss_val: 0.8908 acc_val: 0.8007 time: 0.0069s\n",
      "Epoch: 1053 loss_train: 0.8869 acc_train: 0.7793 loss_val: 0.8902 acc_val: 0.8081 time: 0.0067s\n",
      "Epoch: 1054 loss_train: 0.9008 acc_train: 0.7784 loss_val: 0.8896 acc_val: 0.8081 time: 0.0067s\n",
      "Epoch: 1055 loss_train: 0.9039 acc_train: 0.7761 loss_val: 0.8891 acc_val: 0.8081 time: 0.0065s\n",
      "Epoch: 1056 loss_train: 0.8998 acc_train: 0.7733 loss_val: 0.8885 acc_val: 0.8081 time: 0.0071s\n",
      "Epoch: 1057 loss_train: 0.8984 acc_train: 0.7886 loss_val: 0.8880 acc_val: 0.8044 time: 0.0066s\n",
      "Epoch: 1058 loss_train: 0.8920 acc_train: 0.7789 loss_val: 0.8874 acc_val: 0.8044 time: 0.0066s\n",
      "Epoch: 1059 loss_train: 0.8817 acc_train: 0.7761 loss_val: 0.8869 acc_val: 0.8044 time: 0.0070s\n",
      "Epoch: 1060 loss_train: 0.8794 acc_train: 0.7844 loss_val: 0.8862 acc_val: 0.8044 time: 0.0071s\n",
      "Epoch: 1061 loss_train: 0.8757 acc_train: 0.7909 loss_val: 0.8856 acc_val: 0.8044 time: 0.0065s\n",
      "Epoch: 1062 loss_train: 0.8996 acc_train: 0.7705 loss_val: 0.8851 acc_val: 0.8044 time: 0.0071s\n",
      "Epoch: 1063 loss_train: 0.9029 acc_train: 0.7798 loss_val: 0.8846 acc_val: 0.8081 time: 0.0070s\n",
      "Epoch: 1064 loss_train: 0.8821 acc_train: 0.7789 loss_val: 0.8841 acc_val: 0.8081 time: 0.0069s\n",
      "Epoch: 1065 loss_train: 0.8841 acc_train: 0.7802 loss_val: 0.8836 acc_val: 0.8081 time: 0.0066s\n",
      "Epoch: 1066 loss_train: 0.8862 acc_train: 0.7775 loss_val: 0.8831 acc_val: 0.8081 time: 0.0070s\n",
      "Epoch: 1067 loss_train: 0.8862 acc_train: 0.7913 loss_val: 0.8827 acc_val: 0.8081 time: 0.0065s\n",
      "Epoch: 1068 loss_train: 0.8724 acc_train: 0.7839 loss_val: 0.8822 acc_val: 0.8081 time: 0.0069s\n",
      "Epoch: 1069 loss_train: 0.8841 acc_train: 0.7849 loss_val: 0.8818 acc_val: 0.8081 time: 0.0066s\n",
      "Epoch: 1070 loss_train: 0.8789 acc_train: 0.7982 loss_val: 0.8813 acc_val: 0.8081 time: 0.0068s\n",
      "Epoch: 1071 loss_train: 0.8850 acc_train: 0.7812 loss_val: 0.8808 acc_val: 0.8044 time: 0.0069s\n",
      "Epoch: 1072 loss_train: 0.8767 acc_train: 0.7992 loss_val: 0.8804 acc_val: 0.8044 time: 0.0070s\n",
      "Epoch: 1073 loss_train: 0.9034 acc_train: 0.7770 loss_val: 0.8799 acc_val: 0.8044 time: 0.0064s\n",
      "Epoch: 1074 loss_train: 0.8646 acc_train: 0.7825 loss_val: 0.8794 acc_val: 0.8044 time: 0.0069s\n",
      "Epoch: 1075 loss_train: 0.8844 acc_train: 0.7867 loss_val: 0.8789 acc_val: 0.8044 time: 0.0074s\n",
      "Epoch: 1076 loss_train: 0.8780 acc_train: 0.7872 loss_val: 0.8784 acc_val: 0.8081 time: 0.0074s\n",
      "Epoch: 1077 loss_train: 0.8887 acc_train: 0.7853 loss_val: 0.8780 acc_val: 0.8118 time: 0.0071s\n",
      "Epoch: 1078 loss_train: 0.8845 acc_train: 0.7835 loss_val: 0.8775 acc_val: 0.8118 time: 0.0071s\n",
      "Epoch: 1079 loss_train: 0.8939 acc_train: 0.7835 loss_val: 0.8770 acc_val: 0.8118 time: 0.0067s\n",
      "Epoch: 1080 loss_train: 0.8702 acc_train: 0.7867 loss_val: 0.8766 acc_val: 0.8118 time: 0.0067s\n",
      "Epoch: 1081 loss_train: 0.8919 acc_train: 0.7742 loss_val: 0.8761 acc_val: 0.8118 time: 0.0069s\n",
      "Epoch: 1082 loss_train: 0.8790 acc_train: 0.7775 loss_val: 0.8757 acc_val: 0.8118 time: 0.0070s\n",
      "Epoch: 1083 loss_train: 0.8848 acc_train: 0.7738 loss_val: 0.8752 acc_val: 0.8118 time: 0.0073s\n",
      "Epoch: 1084 loss_train: 0.8897 acc_train: 0.7816 loss_val: 0.8749 acc_val: 0.8118 time: 0.0067s\n",
      "Epoch: 1085 loss_train: 0.8974 acc_train: 0.7770 loss_val: 0.8745 acc_val: 0.8118 time: 0.0067s\n",
      "Epoch: 1086 loss_train: 0.8803 acc_train: 0.7858 loss_val: 0.8742 acc_val: 0.8118 time: 0.0066s\n",
      "Epoch: 1087 loss_train: 0.8913 acc_train: 0.7784 loss_val: 0.8738 acc_val: 0.8118 time: 0.0066s\n",
      "Epoch: 1088 loss_train: 0.8678 acc_train: 0.7816 loss_val: 0.8734 acc_val: 0.8155 time: 0.0067s\n",
      "Epoch: 1089 loss_train: 0.8728 acc_train: 0.7756 loss_val: 0.8730 acc_val: 0.8155 time: 0.0067s\n",
      "Epoch: 1090 loss_train: 0.8566 acc_train: 0.7839 loss_val: 0.8726 acc_val: 0.8155 time: 0.0072s\n",
      "Epoch: 1091 loss_train: 0.8624 acc_train: 0.7839 loss_val: 0.8722 acc_val: 0.8155 time: 0.0072s\n",
      "Epoch: 1092 loss_train: 0.8735 acc_train: 0.7909 loss_val: 0.8717 acc_val: 0.8155 time: 0.0068s\n",
      "Epoch: 1093 loss_train: 0.8824 acc_train: 0.7784 loss_val: 0.8712 acc_val: 0.8155 time: 0.0067s\n",
      "Epoch: 1094 loss_train: 0.8741 acc_train: 0.7867 loss_val: 0.8708 acc_val: 0.8155 time: 0.0066s\n",
      "Epoch: 1095 loss_train: 0.8800 acc_train: 0.7812 loss_val: 0.8703 acc_val: 0.8155 time: 0.0071s\n",
      "Epoch: 1096 loss_train: 0.8919 acc_train: 0.7881 loss_val: 0.8698 acc_val: 0.8118 time: 0.0072s\n",
      "Epoch: 1097 loss_train: 0.8711 acc_train: 0.7853 loss_val: 0.8693 acc_val: 0.8118 time: 0.0068s\n",
      "Epoch: 1098 loss_train: 0.8808 acc_train: 0.7733 loss_val: 0.8688 acc_val: 0.8118 time: 0.0064s\n",
      "Epoch: 1099 loss_train: 0.8857 acc_train: 0.7895 loss_val: 0.8683 acc_val: 0.8118 time: 0.0070s\n",
      "Epoch: 1100 loss_train: 0.8705 acc_train: 0.7849 loss_val: 0.8678 acc_val: 0.8081 time: 0.0070s\n",
      "Epoch: 1101 loss_train: 0.8773 acc_train: 0.7825 loss_val: 0.8674 acc_val: 0.8081 time: 0.0065s\n",
      "Epoch: 1102 loss_train: 0.8991 acc_train: 0.7881 loss_val: 0.8669 acc_val: 0.8044 time: 0.0073s\n",
      "Epoch: 1103 loss_train: 0.8719 acc_train: 0.7853 loss_val: 0.8664 acc_val: 0.8044 time: 0.0075s\n",
      "Epoch: 1104 loss_train: 0.8644 acc_train: 0.7830 loss_val: 0.8660 acc_val: 0.8044 time: 0.0071s\n",
      "Epoch: 1105 loss_train: 0.8775 acc_train: 0.7895 loss_val: 0.8655 acc_val: 0.8044 time: 0.0069s\n",
      "Epoch: 1106 loss_train: 0.8732 acc_train: 0.7775 loss_val: 0.8651 acc_val: 0.8044 time: 0.0068s\n",
      "Epoch: 1107 loss_train: 0.8672 acc_train: 0.7802 loss_val: 0.8647 acc_val: 0.8044 time: 0.0067s\n",
      "Epoch: 1108 loss_train: 0.8669 acc_train: 0.7969 loss_val: 0.8642 acc_val: 0.8044 time: 0.0070s\n",
      "Epoch: 1109 loss_train: 0.8666 acc_train: 0.8001 loss_val: 0.8637 acc_val: 0.8044 time: 0.0066s\n",
      "Epoch: 1110 loss_train: 0.8651 acc_train: 0.7858 loss_val: 0.8632 acc_val: 0.8081 time: 0.0069s\n",
      "Epoch: 1111 loss_train: 0.8657 acc_train: 0.7913 loss_val: 0.8627 acc_val: 0.8081 time: 0.0070s\n",
      "Epoch: 1112 loss_train: 0.8487 acc_train: 0.7862 loss_val: 0.8622 acc_val: 0.8081 time: 0.0067s\n",
      "Epoch: 1113 loss_train: 0.8671 acc_train: 0.7807 loss_val: 0.8616 acc_val: 0.8081 time: 0.0073s\n",
      "Epoch: 1114 loss_train: 0.8857 acc_train: 0.7747 loss_val: 0.8611 acc_val: 0.8081 time: 0.0069s\n",
      "Epoch: 1115 loss_train: 0.8581 acc_train: 0.7913 loss_val: 0.8605 acc_val: 0.8118 time: 0.0065s\n",
      "Epoch: 1116 loss_train: 0.8605 acc_train: 0.7839 loss_val: 0.8600 acc_val: 0.8118 time: 0.0067s\n",
      "Epoch: 1117 loss_train: 0.8888 acc_train: 0.7770 loss_val: 0.8595 acc_val: 0.8118 time: 0.0071s\n",
      "Epoch: 1118 loss_train: 0.8636 acc_train: 0.7927 loss_val: 0.8590 acc_val: 0.8155 time: 0.0069s\n",
      "Epoch: 1119 loss_train: 0.8465 acc_train: 0.7932 loss_val: 0.8586 acc_val: 0.8192 time: 0.0068s\n",
      "Epoch: 1120 loss_train: 0.8959 acc_train: 0.7936 loss_val: 0.8581 acc_val: 0.8192 time: 0.0068s\n",
      "Epoch: 1121 loss_train: 0.8681 acc_train: 0.7807 loss_val: 0.8576 acc_val: 0.8192 time: 0.0066s\n",
      "Epoch: 1122 loss_train: 0.8712 acc_train: 0.7849 loss_val: 0.8571 acc_val: 0.8192 time: 0.0069s\n",
      "Epoch: 1123 loss_train: 0.8731 acc_train: 0.7839 loss_val: 0.8566 acc_val: 0.8192 time: 0.0066s\n",
      "Epoch: 1124 loss_train: 0.8447 acc_train: 0.8056 loss_val: 0.8561 acc_val: 0.8192 time: 0.0065s\n",
      "Epoch: 1125 loss_train: 0.8891 acc_train: 0.7752 loss_val: 0.8555 acc_val: 0.8192 time: 0.0077s\n",
      "Epoch: 1126 loss_train: 0.8609 acc_train: 0.8006 loss_val: 0.8550 acc_val: 0.8192 time: 0.0072s\n",
      "Epoch: 1127 loss_train: 0.8429 acc_train: 0.7982 loss_val: 0.8545 acc_val: 0.8192 time: 0.0064s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1128 loss_train: 0.8597 acc_train: 0.7964 loss_val: 0.8540 acc_val: 0.8192 time: 0.0072s\n",
      "Epoch: 1129 loss_train: 0.8659 acc_train: 0.7922 loss_val: 0.8535 acc_val: 0.8192 time: 0.0070s\n",
      "Epoch: 1130 loss_train: 0.8710 acc_train: 0.7959 loss_val: 0.8530 acc_val: 0.8192 time: 0.0068s\n",
      "Epoch: 1131 loss_train: 0.8537 acc_train: 0.7978 loss_val: 0.8525 acc_val: 0.8192 time: 0.0067s\n",
      "Epoch: 1132 loss_train: 0.8763 acc_train: 0.7853 loss_val: 0.8520 acc_val: 0.8192 time: 0.0067s\n",
      "Epoch: 1133 loss_train: 0.8537 acc_train: 0.8024 loss_val: 0.8516 acc_val: 0.8192 time: 0.0071s\n",
      "Epoch: 1134 loss_train: 0.8441 acc_train: 0.7936 loss_val: 0.8511 acc_val: 0.8192 time: 0.0071s\n",
      "Epoch: 1135 loss_train: 0.8575 acc_train: 0.7978 loss_val: 0.8506 acc_val: 0.8192 time: 0.0067s\n",
      "Epoch: 1136 loss_train: 0.8718 acc_train: 0.7844 loss_val: 0.8502 acc_val: 0.8192 time: 0.0064s\n",
      "Epoch: 1137 loss_train: 0.8548 acc_train: 0.7853 loss_val: 0.8498 acc_val: 0.8192 time: 0.0073s\n",
      "Epoch: 1138 loss_train: 0.8631 acc_train: 0.7955 loss_val: 0.8494 acc_val: 0.8192 time: 0.0071s\n",
      "Epoch: 1139 loss_train: 0.8570 acc_train: 0.7936 loss_val: 0.8489 acc_val: 0.8192 time: 0.0065s\n",
      "Epoch: 1140 loss_train: 0.8643 acc_train: 0.7825 loss_val: 0.8485 acc_val: 0.8229 time: 0.0068s\n",
      "Epoch: 1141 loss_train: 0.8738 acc_train: 0.7941 loss_val: 0.8481 acc_val: 0.8229 time: 0.0071s\n",
      "Epoch: 1142 loss_train: 0.8613 acc_train: 0.7909 loss_val: 0.8476 acc_val: 0.8229 time: 0.0068s\n",
      "Epoch: 1143 loss_train: 0.8632 acc_train: 0.7969 loss_val: 0.8472 acc_val: 0.8229 time: 0.0066s\n",
      "Epoch: 1144 loss_train: 0.8552 acc_train: 0.7932 loss_val: 0.8467 acc_val: 0.8229 time: 0.0067s\n",
      "Epoch: 1145 loss_train: 0.8852 acc_train: 0.7738 loss_val: 0.8463 acc_val: 0.8266 time: 0.0068s\n",
      "Epoch: 1146 loss_train: 0.8376 acc_train: 0.7936 loss_val: 0.8459 acc_val: 0.8266 time: 0.0071s\n",
      "Epoch: 1147 loss_train: 0.8486 acc_train: 0.7835 loss_val: 0.8454 acc_val: 0.8266 time: 0.0067s\n",
      "Epoch: 1148 loss_train: 0.8688 acc_train: 0.7830 loss_val: 0.8450 acc_val: 0.8303 time: 0.0067s\n",
      "Epoch: 1149 loss_train: 0.8495 acc_train: 0.7959 loss_val: 0.8445 acc_val: 0.8303 time: 0.0072s\n",
      "Epoch: 1150 loss_train: 0.8811 acc_train: 0.7784 loss_val: 0.8442 acc_val: 0.8303 time: 0.0072s\n",
      "Epoch: 1151 loss_train: 0.8510 acc_train: 0.7987 loss_val: 0.8438 acc_val: 0.8303 time: 0.0064s\n",
      "Epoch: 1152 loss_train: 0.8591 acc_train: 0.7932 loss_val: 0.8434 acc_val: 0.8303 time: 0.0068s\n",
      "Epoch: 1153 loss_train: 0.8581 acc_train: 0.7982 loss_val: 0.8431 acc_val: 0.8303 time: 0.0074s\n",
      "Epoch: 1154 loss_train: 0.8367 acc_train: 0.8024 loss_val: 0.8427 acc_val: 0.8339 time: 0.0075s\n",
      "Epoch: 1155 loss_train: 0.8294 acc_train: 0.8102 loss_val: 0.8422 acc_val: 0.8339 time: 0.0065s\n",
      "Epoch: 1156 loss_train: 0.8587 acc_train: 0.7812 loss_val: 0.8418 acc_val: 0.8339 time: 0.0067s\n",
      "Epoch: 1157 loss_train: 0.8494 acc_train: 0.7909 loss_val: 0.8413 acc_val: 0.8339 time: 0.0066s\n",
      "Epoch: 1158 loss_train: 0.8492 acc_train: 0.8047 loss_val: 0.8408 acc_val: 0.8339 time: 0.0068s\n",
      "Epoch: 1159 loss_train: 0.8435 acc_train: 0.7955 loss_val: 0.8403 acc_val: 0.8303 time: 0.0071s\n",
      "Epoch: 1160 loss_train: 0.8342 acc_train: 0.7987 loss_val: 0.8398 acc_val: 0.8303 time: 0.0067s\n",
      "Epoch: 1161 loss_train: 0.8466 acc_train: 0.7992 loss_val: 0.8393 acc_val: 0.8266 time: 0.0071s\n",
      "Epoch: 1162 loss_train: 0.8635 acc_train: 0.7881 loss_val: 0.8388 acc_val: 0.8266 time: 0.0067s\n",
      "Epoch: 1163 loss_train: 0.8581 acc_train: 0.7932 loss_val: 0.8383 acc_val: 0.8266 time: 0.0065s\n",
      "Epoch: 1164 loss_train: 0.8307 acc_train: 0.8001 loss_val: 0.8379 acc_val: 0.8266 time: 0.0069s\n",
      "Epoch: 1165 loss_train: 0.8521 acc_train: 0.8052 loss_val: 0.8375 acc_val: 0.8266 time: 0.0069s\n",
      "Epoch: 1166 loss_train: 0.8375 acc_train: 0.7987 loss_val: 0.8371 acc_val: 0.8266 time: 0.0067s\n",
      "Epoch: 1167 loss_train: 0.8239 acc_train: 0.8015 loss_val: 0.8367 acc_val: 0.8266 time: 0.0071s\n",
      "Epoch: 1168 loss_train: 0.8381 acc_train: 0.8015 loss_val: 0.8362 acc_val: 0.8266 time: 0.0070s\n",
      "Epoch: 1169 loss_train: 0.8402 acc_train: 0.7973 loss_val: 0.8357 acc_val: 0.8266 time: 0.0069s\n",
      "Epoch: 1170 loss_train: 0.8335 acc_train: 0.7969 loss_val: 0.8352 acc_val: 0.8266 time: 0.0067s\n",
      "Epoch: 1171 loss_train: 0.8503 acc_train: 0.7918 loss_val: 0.8348 acc_val: 0.8303 time: 0.0069s\n",
      "Epoch: 1172 loss_train: 0.8456 acc_train: 0.8038 loss_val: 0.8344 acc_val: 0.8303 time: 0.0068s\n",
      "Epoch: 1173 loss_train: 0.8498 acc_train: 0.7941 loss_val: 0.8340 acc_val: 0.8303 time: 0.0071s\n",
      "Epoch: 1174 loss_train: 0.8286 acc_train: 0.8029 loss_val: 0.8337 acc_val: 0.8303 time: 0.0067s\n",
      "Epoch: 1175 loss_train: 0.8557 acc_train: 0.7867 loss_val: 0.8333 acc_val: 0.8339 time: 0.0065s\n",
      "Epoch: 1176 loss_train: 0.8472 acc_train: 0.7969 loss_val: 0.8329 acc_val: 0.8339 time: 0.0071s\n",
      "Epoch: 1177 loss_train: 0.8399 acc_train: 0.8029 loss_val: 0.8326 acc_val: 0.8339 time: 0.0072s\n",
      "Epoch: 1178 loss_train: 0.8539 acc_train: 0.8056 loss_val: 0.8322 acc_val: 0.8339 time: 0.0064s\n",
      "Epoch: 1179 loss_train: 0.8397 acc_train: 0.7982 loss_val: 0.8317 acc_val: 0.8339 time: 0.0069s\n",
      "Epoch: 1180 loss_train: 0.8422 acc_train: 0.8015 loss_val: 0.8313 acc_val: 0.8339 time: 0.0071s\n",
      "Epoch: 1181 loss_train: 0.8606 acc_train: 0.7973 loss_val: 0.8308 acc_val: 0.8339 time: 0.0069s\n",
      "Epoch: 1182 loss_train: 0.8296 acc_train: 0.7982 loss_val: 0.8303 acc_val: 0.8339 time: 0.0068s\n",
      "Epoch: 1183 loss_train: 0.8473 acc_train: 0.7987 loss_val: 0.8298 acc_val: 0.8339 time: 0.0069s\n",
      "Epoch: 1184 loss_train: 0.8281 acc_train: 0.7969 loss_val: 0.8292 acc_val: 0.8339 time: 0.0069s\n",
      "Epoch: 1185 loss_train: 0.8154 acc_train: 0.8190 loss_val: 0.8287 acc_val: 0.8339 time: 0.0069s\n",
      "Epoch: 1186 loss_train: 0.8571 acc_train: 0.7927 loss_val: 0.8282 acc_val: 0.8339 time: 0.0072s\n",
      "Epoch: 1187 loss_train: 0.8522 acc_train: 0.7950 loss_val: 0.8277 acc_val: 0.8339 time: 0.0064s\n",
      "Epoch: 1188 loss_train: 0.8357 acc_train: 0.7913 loss_val: 0.8272 acc_val: 0.8339 time: 0.0065s\n",
      "Epoch: 1189 loss_train: 0.8585 acc_train: 0.8015 loss_val: 0.8268 acc_val: 0.8376 time: 0.0069s\n",
      "Epoch: 1190 loss_train: 0.8314 acc_train: 0.8047 loss_val: 0.8263 acc_val: 0.8376 time: 0.0073s\n",
      "Epoch: 1191 loss_train: 0.8275 acc_train: 0.8006 loss_val: 0.8259 acc_val: 0.8339 time: 0.0073s\n",
      "Epoch: 1192 loss_train: 0.8614 acc_train: 0.7941 loss_val: 0.8255 acc_val: 0.8339 time: 0.0065s\n",
      "Epoch: 1193 loss_train: 0.8303 acc_train: 0.8084 loss_val: 0.8250 acc_val: 0.8339 time: 0.0071s\n",
      "Epoch: 1194 loss_train: 0.8389 acc_train: 0.7881 loss_val: 0.8246 acc_val: 0.8339 time: 0.0067s\n",
      "Epoch: 1195 loss_train: 0.8247 acc_train: 0.8015 loss_val: 0.8241 acc_val: 0.8339 time: 0.0067s\n",
      "Epoch: 1196 loss_train: 0.8380 acc_train: 0.8075 loss_val: 0.8236 acc_val: 0.8339 time: 0.0070s\n",
      "Epoch: 1197 loss_train: 0.8466 acc_train: 0.8038 loss_val: 0.8231 acc_val: 0.8376 time: 0.0073s\n",
      "Epoch: 1198 loss_train: 0.8201 acc_train: 0.8112 loss_val: 0.8225 acc_val: 0.8376 time: 0.0064s\n",
      "Epoch: 1199 loss_train: 0.8434 acc_train: 0.7950 loss_val: 0.8219 acc_val: 0.8376 time: 0.0070s\n",
      "Epoch: 1200 loss_train: 0.8251 acc_train: 0.7969 loss_val: 0.8213 acc_val: 0.8376 time: 0.0069s\n",
      "Epoch: 1201 loss_train: 0.8351 acc_train: 0.8079 loss_val: 0.8207 acc_val: 0.8376 time: 0.0068s\n",
      "Epoch: 1202 loss_train: 0.8334 acc_train: 0.7927 loss_val: 0.8201 acc_val: 0.8376 time: 0.0066s\n",
      "Epoch: 1203 loss_train: 0.8142 acc_train: 0.8061 loss_val: 0.8196 acc_val: 0.8376 time: 0.0069s\n",
      "Epoch: 1204 loss_train: 0.8514 acc_train: 0.7881 loss_val: 0.8190 acc_val: 0.8376 time: 0.0067s\n",
      "Epoch: 1205 loss_train: 0.8383 acc_train: 0.7941 loss_val: 0.8185 acc_val: 0.8376 time: 0.0070s\n",
      "Epoch: 1206 loss_train: 0.8237 acc_train: 0.8061 loss_val: 0.8180 acc_val: 0.8376 time: 0.0073s\n",
      "Epoch: 1207 loss_train: 0.8306 acc_train: 0.7973 loss_val: 0.8174 acc_val: 0.8376 time: 0.0069s\n",
      "Epoch: 1208 loss_train: 0.8270 acc_train: 0.7987 loss_val: 0.8169 acc_val: 0.8376 time: 0.0070s\n",
      "Epoch: 1209 loss_train: 0.8125 acc_train: 0.8176 loss_val: 0.8164 acc_val: 0.8376 time: 0.0071s\n",
      "Epoch: 1210 loss_train: 0.8320 acc_train: 0.8066 loss_val: 0.8158 acc_val: 0.8376 time: 0.0064s\n",
      "Epoch: 1211 loss_train: 0.8325 acc_train: 0.8001 loss_val: 0.8153 acc_val: 0.8376 time: 0.0069s\n",
      "Epoch: 1212 loss_train: 0.8309 acc_train: 0.8010 loss_val: 0.8148 acc_val: 0.8376 time: 0.0070s\n",
      "Epoch: 1213 loss_train: 0.8203 acc_train: 0.8061 loss_val: 0.8143 acc_val: 0.8413 time: 0.0069s\n",
      "Epoch: 1214 loss_train: 0.8087 acc_train: 0.8135 loss_val: 0.8138 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1215 loss_train: 0.8172 acc_train: 0.7978 loss_val: 0.8133 acc_val: 0.8450 time: 0.0066s\n",
      "Epoch: 1216 loss_train: 0.8189 acc_train: 0.8061 loss_val: 0.8129 acc_val: 0.8450 time: 0.0066s\n",
      "Epoch: 1217 loss_train: 0.8409 acc_train: 0.7927 loss_val: 0.8124 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1218 loss_train: 0.8029 acc_train: 0.8084 loss_val: 0.8120 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1219 loss_train: 0.7987 acc_train: 0.8172 loss_val: 0.8117 acc_val: 0.8450 time: 0.0064s\n",
      "Epoch: 1220 loss_train: 0.8313 acc_train: 0.8130 loss_val: 0.8113 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1221 loss_train: 0.8196 acc_train: 0.8019 loss_val: 0.8110 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1222 loss_train: 0.7948 acc_train: 0.8204 loss_val: 0.8106 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1223 loss_train: 0.8207 acc_train: 0.8112 loss_val: 0.8102 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1224 loss_train: 0.8256 acc_train: 0.7978 loss_val: 0.8097 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1225 loss_train: 0.8303 acc_train: 0.8052 loss_val: 0.8092 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1226 loss_train: 0.8167 acc_train: 0.8052 loss_val: 0.8086 acc_val: 0.8450 time: 0.0064s\n",
      "Epoch: 1227 loss_train: 0.8164 acc_train: 0.8066 loss_val: 0.8081 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1228 loss_train: 0.8037 acc_train: 0.8149 loss_val: 0.8075 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1229 loss_train: 0.8282 acc_train: 0.8006 loss_val: 0.8069 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1230 loss_train: 0.8004 acc_train: 0.8070 loss_val: 0.8063 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1231 loss_train: 0.8063 acc_train: 0.8089 loss_val: 0.8057 acc_val: 0.8450 time: 0.0069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1232 loss_train: 0.8119 acc_train: 0.8126 loss_val: 0.8052 acc_val: 0.8450 time: 0.0076s\n",
      "Epoch: 1233 loss_train: 0.8245 acc_train: 0.7996 loss_val: 0.8047 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1234 loss_train: 0.8260 acc_train: 0.8070 loss_val: 0.8042 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1235 loss_train: 0.8019 acc_train: 0.8033 loss_val: 0.8037 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1236 loss_train: 0.8040 acc_train: 0.8121 loss_val: 0.8033 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1237 loss_train: 0.8367 acc_train: 0.7946 loss_val: 0.8028 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1238 loss_train: 0.8074 acc_train: 0.7964 loss_val: 0.8023 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1239 loss_train: 0.8131 acc_train: 0.7964 loss_val: 0.8018 acc_val: 0.8450 time: 0.0066s\n",
      "Epoch: 1240 loss_train: 0.8030 acc_train: 0.7959 loss_val: 0.8013 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1241 loss_train: 0.8178 acc_train: 0.8107 loss_val: 0.8008 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1242 loss_train: 0.8332 acc_train: 0.8024 loss_val: 0.8003 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1243 loss_train: 0.8462 acc_train: 0.7825 loss_val: 0.7998 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1244 loss_train: 0.8154 acc_train: 0.8079 loss_val: 0.7993 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1245 loss_train: 0.8044 acc_train: 0.8144 loss_val: 0.7989 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1246 loss_train: 0.8085 acc_train: 0.8038 loss_val: 0.7985 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1247 loss_train: 0.8227 acc_train: 0.8075 loss_val: 0.7981 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1248 loss_train: 0.8029 acc_train: 0.8029 loss_val: 0.7977 acc_val: 0.8450 time: 0.0066s\n",
      "Epoch: 1249 loss_train: 0.8160 acc_train: 0.8010 loss_val: 0.7971 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1250 loss_train: 0.7983 acc_train: 0.7964 loss_val: 0.7967 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1251 loss_train: 0.8075 acc_train: 0.7996 loss_val: 0.7962 acc_val: 0.8450 time: 0.0064s\n",
      "Epoch: 1252 loss_train: 0.8176 acc_train: 0.7946 loss_val: 0.7957 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1253 loss_train: 0.7948 acc_train: 0.8135 loss_val: 0.7953 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1254 loss_train: 0.8146 acc_train: 0.8019 loss_val: 0.7948 acc_val: 0.8450 time: 0.0065s\n",
      "Epoch: 1255 loss_train: 0.8071 acc_train: 0.8070 loss_val: 0.7943 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1256 loss_train: 0.8022 acc_train: 0.8186 loss_val: 0.7938 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1257 loss_train: 0.7918 acc_train: 0.8015 loss_val: 0.7933 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1258 loss_train: 0.8173 acc_train: 0.8033 loss_val: 0.7928 acc_val: 0.8450 time: 0.0076s\n",
      "Epoch: 1259 loss_train: 0.8023 acc_train: 0.8006 loss_val: 0.7923 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1260 loss_train: 0.7863 acc_train: 0.8126 loss_val: 0.7918 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1261 loss_train: 0.8035 acc_train: 0.7959 loss_val: 0.7913 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1262 loss_train: 0.8030 acc_train: 0.8047 loss_val: 0.7908 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1263 loss_train: 0.7986 acc_train: 0.8033 loss_val: 0.7903 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1264 loss_train: 0.8258 acc_train: 0.8015 loss_val: 0.7898 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1265 loss_train: 0.8038 acc_train: 0.8149 loss_val: 0.7892 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1266 loss_train: 0.7888 acc_train: 0.8102 loss_val: 0.7886 acc_val: 0.8450 time: 0.0065s\n",
      "Epoch: 1267 loss_train: 0.8050 acc_train: 0.8102 loss_val: 0.7880 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1268 loss_train: 0.8060 acc_train: 0.8070 loss_val: 0.7873 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1269 loss_train: 0.8018 acc_train: 0.8195 loss_val: 0.7866 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1270 loss_train: 0.8268 acc_train: 0.7973 loss_val: 0.7859 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1271 loss_train: 0.7943 acc_train: 0.8084 loss_val: 0.7852 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1272 loss_train: 0.8139 acc_train: 0.8042 loss_val: 0.7845 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1273 loss_train: 0.8130 acc_train: 0.8089 loss_val: 0.7839 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1274 loss_train: 0.8076 acc_train: 0.8098 loss_val: 0.7834 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1275 loss_train: 0.7860 acc_train: 0.8112 loss_val: 0.7830 acc_val: 0.8450 time: 0.0066s\n",
      "Epoch: 1276 loss_train: 0.7910 acc_train: 0.8093 loss_val: 0.7826 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1277 loss_train: 0.7853 acc_train: 0.8176 loss_val: 0.7823 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1278 loss_train: 0.7814 acc_train: 0.8056 loss_val: 0.7820 acc_val: 0.8450 time: 0.0066s\n",
      "Epoch: 1279 loss_train: 0.7829 acc_train: 0.8204 loss_val: 0.7818 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1280 loss_train: 0.7866 acc_train: 0.8070 loss_val: 0.7815 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1281 loss_train: 0.7948 acc_train: 0.8135 loss_val: 0.7813 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1282 loss_train: 0.8032 acc_train: 0.8033 loss_val: 0.7810 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1283 loss_train: 0.7928 acc_train: 0.8033 loss_val: 0.7807 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1284 loss_train: 0.7917 acc_train: 0.8126 loss_val: 0.7803 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1285 loss_train: 0.7764 acc_train: 0.8130 loss_val: 0.7798 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1286 loss_train: 0.7720 acc_train: 0.8195 loss_val: 0.7794 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1287 loss_train: 0.8040 acc_train: 0.8024 loss_val: 0.7790 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1288 loss_train: 0.8114 acc_train: 0.8107 loss_val: 0.7785 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1289 loss_train: 0.8055 acc_train: 0.7987 loss_val: 0.7779 acc_val: 0.8450 time: 0.0071s\n",
      "Epoch: 1290 loss_train: 0.7828 acc_train: 0.8158 loss_val: 0.7774 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1291 loss_train: 0.7855 acc_train: 0.8139 loss_val: 0.7768 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1292 loss_train: 0.7982 acc_train: 0.8052 loss_val: 0.7762 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1293 loss_train: 0.7738 acc_train: 0.8186 loss_val: 0.7756 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1294 loss_train: 0.8002 acc_train: 0.8139 loss_val: 0.7750 acc_val: 0.8450 time: 0.0167s\n",
      "Epoch: 1295 loss_train: 0.7843 acc_train: 0.8112 loss_val: 0.7745 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1296 loss_train: 0.7861 acc_train: 0.8107 loss_val: 0.7740 acc_val: 0.8450 time: 0.0065s\n",
      "Epoch: 1297 loss_train: 0.7904 acc_train: 0.8153 loss_val: 0.7734 acc_val: 0.8450 time: 0.0066s\n",
      "Epoch: 1298 loss_train: 0.8133 acc_train: 0.8089 loss_val: 0.7728 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1299 loss_train: 0.7989 acc_train: 0.7992 loss_val: 0.7722 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1300 loss_train: 0.7639 acc_train: 0.8098 loss_val: 0.7716 acc_val: 0.8450 time: 0.0077s\n",
      "Epoch: 1301 loss_train: 0.7829 acc_train: 0.8153 loss_val: 0.7712 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1302 loss_train: 0.7893 acc_train: 0.8181 loss_val: 0.7707 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1303 loss_train: 0.7945 acc_train: 0.8075 loss_val: 0.7702 acc_val: 0.8450 time: 0.0072s\n",
      "Epoch: 1304 loss_train: 0.7982 acc_train: 0.7969 loss_val: 0.7697 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1305 loss_train: 0.7723 acc_train: 0.8232 loss_val: 0.7692 acc_val: 0.8450 time: 0.0069s\n",
      "Epoch: 1306 loss_train: 0.7917 acc_train: 0.8144 loss_val: 0.7686 acc_val: 0.8450 time: 0.0070s\n",
      "Epoch: 1307 loss_train: 0.7862 acc_train: 0.8038 loss_val: 0.7680 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1308 loss_train: 0.7515 acc_train: 0.8135 loss_val: 0.7675 acc_val: 0.8450 time: 0.0073s\n",
      "Epoch: 1309 loss_train: 0.7700 acc_train: 0.8236 loss_val: 0.7670 acc_val: 0.8450 time: 0.0068s\n",
      "Epoch: 1310 loss_train: 0.7664 acc_train: 0.8241 loss_val: 0.7665 acc_val: 0.8450 time: 0.0067s\n",
      "Epoch: 1311 loss_train: 0.7848 acc_train: 0.8079 loss_val: 0.7660 acc_val: 0.8487 time: 0.0070s\n",
      "Epoch: 1312 loss_train: 0.7804 acc_train: 0.8075 loss_val: 0.7654 acc_val: 0.8487 time: 0.0073s\n",
      "Epoch: 1313 loss_train: 0.7774 acc_train: 0.8121 loss_val: 0.7649 acc_val: 0.8487 time: 0.0066s\n",
      "Epoch: 1314 loss_train: 0.8012 acc_train: 0.8181 loss_val: 0.7643 acc_val: 0.8487 time: 0.0069s\n",
      "Epoch: 1315 loss_train: 0.7796 acc_train: 0.8172 loss_val: 0.7636 acc_val: 0.8487 time: 0.0074s\n",
      "Epoch: 1316 loss_train: 0.7795 acc_train: 0.8139 loss_val: 0.7631 acc_val: 0.8487 time: 0.0070s\n",
      "Epoch: 1317 loss_train: 0.7580 acc_train: 0.8278 loss_val: 0.7624 acc_val: 0.8487 time: 0.0068s\n",
      "Epoch: 1318 loss_train: 0.7737 acc_train: 0.8047 loss_val: 0.7618 acc_val: 0.8487 time: 0.0070s\n",
      "Epoch: 1319 loss_train: 0.8021 acc_train: 0.8098 loss_val: 0.7611 acc_val: 0.8487 time: 0.0068s\n",
      "Epoch: 1320 loss_train: 0.7806 acc_train: 0.8135 loss_val: 0.7603 acc_val: 0.8487 time: 0.0075s\n",
      "Epoch: 1321 loss_train: 0.7721 acc_train: 0.8121 loss_val: 0.7596 acc_val: 0.8487 time: 0.0070s\n",
      "Epoch: 1322 loss_train: 0.7866 acc_train: 0.8121 loss_val: 0.7590 acc_val: 0.8487 time: 0.0066s\n",
      "Epoch: 1323 loss_train: 0.7786 acc_train: 0.8084 loss_val: 0.7583 acc_val: 0.8487 time: 0.0069s\n",
      "Epoch: 1324 loss_train: 0.7705 acc_train: 0.8209 loss_val: 0.7578 acc_val: 0.8487 time: 0.0072s\n",
      "Epoch: 1325 loss_train: 0.7629 acc_train: 0.8213 loss_val: 0.7573 acc_val: 0.8487 time: 0.0069s\n",
      "Epoch: 1326 loss_train: 0.7675 acc_train: 0.8255 loss_val: 0.7568 acc_val: 0.8487 time: 0.0069s\n",
      "Epoch: 1327 loss_train: 0.7538 acc_train: 0.8172 loss_val: 0.7564 acc_val: 0.8487 time: 0.0074s\n",
      "Epoch: 1328 loss_train: 0.7614 acc_train: 0.8176 loss_val: 0.7560 acc_val: 0.8487 time: 0.0069s\n",
      "Epoch: 1329 loss_train: 0.7706 acc_train: 0.8176 loss_val: 0.7557 acc_val: 0.8487 time: 0.0069s\n",
      "Epoch: 1330 loss_train: 0.7723 acc_train: 0.8126 loss_val: 0.7554 acc_val: 0.8524 time: 0.0069s\n",
      "Epoch: 1331 loss_train: 0.7690 acc_train: 0.8213 loss_val: 0.7552 acc_val: 0.8524 time: 0.0069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1332 loss_train: 0.7788 acc_train: 0.8135 loss_val: 0.7549 acc_val: 0.8524 time: 0.0074s\n",
      "Epoch: 1333 loss_train: 0.7606 acc_train: 0.8213 loss_val: 0.7546 acc_val: 0.8524 time: 0.0068s\n",
      "Epoch: 1334 loss_train: 0.7627 acc_train: 0.8199 loss_val: 0.7543 acc_val: 0.8524 time: 0.0066s\n",
      "Epoch: 1335 loss_train: 0.7643 acc_train: 0.8163 loss_val: 0.7539 acc_val: 0.8524 time: 0.0072s\n",
      "Epoch: 1336 loss_train: 0.7595 acc_train: 0.8204 loss_val: 0.7536 acc_val: 0.8524 time: 0.0073s\n",
      "Epoch: 1337 loss_train: 0.7766 acc_train: 0.8186 loss_val: 0.7532 acc_val: 0.8524 time: 0.0067s\n",
      "Epoch: 1338 loss_train: 0.7602 acc_train: 0.8158 loss_val: 0.7528 acc_val: 0.8561 time: 0.0071s\n",
      "Epoch: 1339 loss_train: 0.7445 acc_train: 0.8269 loss_val: 0.7524 acc_val: 0.8561 time: 0.0072s\n",
      "Epoch: 1340 loss_train: 0.7736 acc_train: 0.8172 loss_val: 0.7519 acc_val: 0.8561 time: 0.0070s\n",
      "Epoch: 1341 loss_train: 0.7538 acc_train: 0.8153 loss_val: 0.7515 acc_val: 0.8561 time: 0.0070s\n",
      "Epoch: 1342 loss_train: 0.7600 acc_train: 0.8066 loss_val: 0.7510 acc_val: 0.8561 time: 0.0070s\n",
      "Epoch: 1343 loss_train: 0.7634 acc_train: 0.8190 loss_val: 0.7506 acc_val: 0.8561 time: 0.0068s\n",
      "Epoch: 1344 loss_train: 0.7436 acc_train: 0.8296 loss_val: 0.7501 acc_val: 0.8561 time: 0.0073s\n",
      "Epoch: 1345 loss_train: 0.7596 acc_train: 0.8204 loss_val: 0.7496 acc_val: 0.8524 time: 0.0068s\n",
      "Epoch: 1346 loss_train: 0.7551 acc_train: 0.8176 loss_val: 0.7491 acc_val: 0.8524 time: 0.0066s\n",
      "Epoch: 1347 loss_train: 0.7579 acc_train: 0.8158 loss_val: 0.7486 acc_val: 0.8524 time: 0.0071s\n",
      "Epoch: 1348 loss_train: 0.7684 acc_train: 0.8227 loss_val: 0.7480 acc_val: 0.8524 time: 0.0072s\n",
      "Epoch: 1349 loss_train: 0.7578 acc_train: 0.8172 loss_val: 0.7475 acc_val: 0.8524 time: 0.0067s\n",
      "Epoch: 1350 loss_train: 0.7542 acc_train: 0.8259 loss_val: 0.7471 acc_val: 0.8524 time: 0.0071s\n",
      "Epoch: 1351 loss_train: 0.7726 acc_train: 0.8066 loss_val: 0.7465 acc_val: 0.8524 time: 0.0072s\n",
      "Epoch: 1352 loss_train: 0.7706 acc_train: 0.8121 loss_val: 0.7460 acc_val: 0.8524 time: 0.0070s\n",
      "Epoch: 1353 loss_train: 0.7651 acc_train: 0.8075 loss_val: 0.7456 acc_val: 0.8524 time: 0.0069s\n",
      "Epoch: 1354 loss_train: 0.7532 acc_train: 0.8227 loss_val: 0.7451 acc_val: 0.8524 time: 0.0070s\n",
      "Epoch: 1355 loss_train: 0.7674 acc_train: 0.8236 loss_val: 0.7445 acc_val: 0.8524 time: 0.0068s\n",
      "Epoch: 1356 loss_train: 0.7577 acc_train: 0.8186 loss_val: 0.7440 acc_val: 0.8524 time: 0.0075s\n",
      "Epoch: 1357 loss_train: 0.7601 acc_train: 0.8269 loss_val: 0.7434 acc_val: 0.8524 time: 0.0073s\n",
      "Epoch: 1358 loss_train: 0.7594 acc_train: 0.8163 loss_val: 0.7428 acc_val: 0.8524 time: 0.0070s\n",
      "Epoch: 1359 loss_train: 0.7826 acc_train: 0.8218 loss_val: 0.7422 acc_val: 0.8524 time: 0.0080s\n",
      "Epoch: 1360 loss_train: 0.7437 acc_train: 0.8209 loss_val: 0.7417 acc_val: 0.8524 time: 0.0076s\n",
      "Epoch: 1361 loss_train: 0.7482 acc_train: 0.8227 loss_val: 0.7412 acc_val: 0.8524 time: 0.0066s\n",
      "Epoch: 1362 loss_train: 0.7499 acc_train: 0.8172 loss_val: 0.7407 acc_val: 0.8524 time: 0.0070s\n",
      "Epoch: 1363 loss_train: 0.7500 acc_train: 0.8158 loss_val: 0.7402 acc_val: 0.8524 time: 0.0071s\n",
      "Epoch: 1364 loss_train: 0.7569 acc_train: 0.8213 loss_val: 0.7397 acc_val: 0.8524 time: 0.0070s\n",
      "Epoch: 1365 loss_train: 0.7529 acc_train: 0.8199 loss_val: 0.7392 acc_val: 0.8524 time: 0.0068s\n",
      "Epoch: 1366 loss_train: 0.7582 acc_train: 0.8223 loss_val: 0.7386 acc_val: 0.8524 time: 0.0068s\n",
      "Epoch: 1367 loss_train: 0.7397 acc_train: 0.8366 loss_val: 0.7380 acc_val: 0.8524 time: 0.0070s\n",
      "Epoch: 1368 loss_train: 0.7483 acc_train: 0.8213 loss_val: 0.7375 acc_val: 0.8524 time: 0.0073s\n",
      "Epoch: 1369 loss_train: 0.7507 acc_train: 0.8112 loss_val: 0.7371 acc_val: 0.8524 time: 0.0069s\n",
      "Epoch: 1370 loss_train: 0.7518 acc_train: 0.8264 loss_val: 0.7367 acc_val: 0.8524 time: 0.0068s\n",
      "Epoch: 1371 loss_train: 0.7413 acc_train: 0.8250 loss_val: 0.7362 acc_val: 0.8524 time: 0.0071s\n",
      "Epoch: 1372 loss_train: 0.7532 acc_train: 0.8213 loss_val: 0.7358 acc_val: 0.8524 time: 0.0071s\n",
      "Epoch: 1373 loss_train: 0.7585 acc_train: 0.8172 loss_val: 0.7353 acc_val: 0.8524 time: 0.0067s\n",
      "Epoch: 1374 loss_train: 0.7555 acc_train: 0.8102 loss_val: 0.7349 acc_val: 0.8524 time: 0.0070s\n",
      "Epoch: 1375 loss_train: 0.7508 acc_train: 0.8089 loss_val: 0.7346 acc_val: 0.8524 time: 0.0073s\n",
      "Epoch: 1376 loss_train: 0.7554 acc_train: 0.8190 loss_val: 0.7343 acc_val: 0.8524 time: 0.0067s\n",
      "Epoch: 1377 loss_train: 0.7465 acc_train: 0.8264 loss_val: 0.7341 acc_val: 0.8524 time: 0.0071s\n",
      "Epoch: 1378 loss_train: 0.7244 acc_train: 0.8319 loss_val: 0.7340 acc_val: 0.8561 time: 0.0073s\n",
      "Epoch: 1379 loss_train: 0.7460 acc_train: 0.8172 loss_val: 0.7338 acc_val: 0.8561 time: 0.0070s\n",
      "Epoch: 1380 loss_train: 0.7481 acc_train: 0.8250 loss_val: 0.7336 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1381 loss_train: 0.7606 acc_train: 0.8199 loss_val: 0.7334 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1382 loss_train: 0.7428 acc_train: 0.8223 loss_val: 0.7330 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1383 loss_train: 0.7498 acc_train: 0.8301 loss_val: 0.7326 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1384 loss_train: 0.7381 acc_train: 0.8315 loss_val: 0.7322 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1385 loss_train: 0.7451 acc_train: 0.8264 loss_val: 0.7317 acc_val: 0.8598 time: 0.0067s\n",
      "Epoch: 1386 loss_train: 0.7256 acc_train: 0.8250 loss_val: 0.7311 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1387 loss_train: 0.7495 acc_train: 0.8163 loss_val: 0.7305 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1388 loss_train: 0.7460 acc_train: 0.8278 loss_val: 0.7298 acc_val: 0.8598 time: 0.0067s\n",
      "Epoch: 1389 loss_train: 0.7295 acc_train: 0.8278 loss_val: 0.7292 acc_val: 0.8598 time: 0.0071s\n",
      "Epoch: 1390 loss_train: 0.7422 acc_train: 0.8283 loss_val: 0.7285 acc_val: 0.8598 time: 0.0076s\n",
      "Epoch: 1391 loss_train: 0.7177 acc_train: 0.8333 loss_val: 0.7279 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1392 loss_train: 0.7349 acc_train: 0.8186 loss_val: 0.7272 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1393 loss_train: 0.7536 acc_train: 0.8190 loss_val: 0.7266 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1394 loss_train: 0.7759 acc_train: 0.8126 loss_val: 0.7259 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1395 loss_train: 0.7383 acc_train: 0.8278 loss_val: 0.7254 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1396 loss_train: 0.7381 acc_train: 0.8319 loss_val: 0.7247 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1397 loss_train: 0.7516 acc_train: 0.8176 loss_val: 0.7240 acc_val: 0.8598 time: 0.0066s\n",
      "Epoch: 1398 loss_train: 0.7453 acc_train: 0.8116 loss_val: 0.7233 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1399 loss_train: 0.7393 acc_train: 0.8241 loss_val: 0.7227 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1400 loss_train: 0.7223 acc_train: 0.8259 loss_val: 0.7222 acc_val: 0.8598 time: 0.0067s\n",
      "Epoch: 1401 loss_train: 0.7378 acc_train: 0.8250 loss_val: 0.7217 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1402 loss_train: 0.7317 acc_train: 0.8181 loss_val: 0.7213 acc_val: 0.8598 time: 0.0071s\n",
      "Epoch: 1403 loss_train: 0.7345 acc_train: 0.8269 loss_val: 0.7208 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1404 loss_train: 0.7221 acc_train: 0.8195 loss_val: 0.7205 acc_val: 0.8598 time: 0.0071s\n",
      "Epoch: 1405 loss_train: 0.7209 acc_train: 0.8370 loss_val: 0.7201 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1406 loss_train: 0.7401 acc_train: 0.8250 loss_val: 0.7198 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1407 loss_train: 0.7295 acc_train: 0.8250 loss_val: 0.7194 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1408 loss_train: 0.7240 acc_train: 0.8324 loss_val: 0.7190 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1409 loss_train: 0.7109 acc_train: 0.8278 loss_val: 0.7186 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1410 loss_train: 0.7462 acc_train: 0.8181 loss_val: 0.7183 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1411 loss_train: 0.7326 acc_train: 0.8273 loss_val: 0.7179 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1412 loss_train: 0.7268 acc_train: 0.8356 loss_val: 0.7175 acc_val: 0.8598 time: 0.0066s\n",
      "Epoch: 1413 loss_train: 0.7505 acc_train: 0.8273 loss_val: 0.7171 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1414 loss_train: 0.7375 acc_train: 0.8306 loss_val: 0.7167 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1415 loss_train: 0.7121 acc_train: 0.8250 loss_val: 0.7164 acc_val: 0.8598 time: 0.0071s\n",
      "Epoch: 1416 loss_train: 0.7229 acc_train: 0.8176 loss_val: 0.7159 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1417 loss_train: 0.7108 acc_train: 0.8407 loss_val: 0.7155 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1418 loss_train: 0.7353 acc_train: 0.8259 loss_val: 0.7149 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1419 loss_train: 0.7378 acc_train: 0.8287 loss_val: 0.7143 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1420 loss_train: 0.7487 acc_train: 0.8241 loss_val: 0.7138 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1421 loss_train: 0.7327 acc_train: 0.8278 loss_val: 0.7133 acc_val: 0.8598 time: 0.0067s\n",
      "Epoch: 1422 loss_train: 0.7261 acc_train: 0.8218 loss_val: 0.7128 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1423 loss_train: 0.7401 acc_train: 0.8366 loss_val: 0.7123 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1424 loss_train: 0.7279 acc_train: 0.8250 loss_val: 0.7117 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1425 loss_train: 0.7211 acc_train: 0.8227 loss_val: 0.7110 acc_val: 0.8598 time: 0.0071s\n",
      "Epoch: 1426 loss_train: 0.7208 acc_train: 0.8278 loss_val: 0.7103 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1427 loss_train: 0.7483 acc_train: 0.8223 loss_val: 0.7096 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1428 loss_train: 0.7205 acc_train: 0.8283 loss_val: 0.7091 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1429 loss_train: 0.7315 acc_train: 0.8287 loss_val: 0.7086 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1430 loss_train: 0.7417 acc_train: 0.8190 loss_val: 0.7083 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1431 loss_train: 0.7161 acc_train: 0.8255 loss_val: 0.7080 acc_val: 0.8598 time: 0.0073s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1432 loss_train: 0.7441 acc_train: 0.8273 loss_val: 0.7076 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1433 loss_train: 0.7245 acc_train: 0.8236 loss_val: 0.7072 acc_val: 0.8561 time: 0.0068s\n",
      "Epoch: 1434 loss_train: 0.7225 acc_train: 0.8213 loss_val: 0.7068 acc_val: 0.8561 time: 0.0072s\n",
      "Epoch: 1435 loss_train: 0.7133 acc_train: 0.8333 loss_val: 0.7063 acc_val: 0.8561 time: 0.0073s\n",
      "Epoch: 1436 loss_train: 0.7088 acc_train: 0.8440 loss_val: 0.7058 acc_val: 0.8561 time: 0.0067s\n",
      "Epoch: 1437 loss_train: 0.7047 acc_train: 0.8449 loss_val: 0.7052 acc_val: 0.8561 time: 0.0069s\n",
      "Epoch: 1438 loss_train: 0.7275 acc_train: 0.8232 loss_val: 0.7047 acc_val: 0.8561 time: 0.0071s\n",
      "Epoch: 1439 loss_train: 0.7362 acc_train: 0.8223 loss_val: 0.7042 acc_val: 0.8561 time: 0.0071s\n",
      "Epoch: 1440 loss_train: 0.7147 acc_train: 0.8338 loss_val: 0.7037 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1441 loss_train: 0.7183 acc_train: 0.8319 loss_val: 0.7032 acc_val: 0.8635 time: 0.0070s\n",
      "Epoch: 1442 loss_train: 0.7153 acc_train: 0.8315 loss_val: 0.7028 acc_val: 0.8635 time: 0.0070s\n",
      "Epoch: 1443 loss_train: 0.7095 acc_train: 0.8301 loss_val: 0.7025 acc_val: 0.8635 time: 0.0072s\n",
      "Epoch: 1444 loss_train: 0.7197 acc_train: 0.8259 loss_val: 0.7023 acc_val: 0.8635 time: 0.0069s\n",
      "Epoch: 1445 loss_train: 0.7170 acc_train: 0.8292 loss_val: 0.7019 acc_val: 0.8635 time: 0.0068s\n",
      "Epoch: 1446 loss_train: 0.7162 acc_train: 0.8296 loss_val: 0.7015 acc_val: 0.8635 time: 0.0070s\n",
      "Epoch: 1447 loss_train: 0.7559 acc_train: 0.8199 loss_val: 0.7011 acc_val: 0.8635 time: 0.0074s\n",
      "Epoch: 1448 loss_train: 0.7160 acc_train: 0.8329 loss_val: 0.7007 acc_val: 0.8635 time: 0.0067s\n",
      "Epoch: 1449 loss_train: 0.7205 acc_train: 0.8306 loss_val: 0.7003 acc_val: 0.8635 time: 0.0068s\n",
      "Epoch: 1450 loss_train: 0.7151 acc_train: 0.8306 loss_val: 0.6999 acc_val: 0.8561 time: 0.0072s\n",
      "Epoch: 1451 loss_train: 0.7400 acc_train: 0.8190 loss_val: 0.6995 acc_val: 0.8561 time: 0.0070s\n",
      "Epoch: 1452 loss_train: 0.7067 acc_train: 0.8310 loss_val: 0.6991 acc_val: 0.8561 time: 0.0068s\n",
      "Epoch: 1453 loss_train: 0.7184 acc_train: 0.8356 loss_val: 0.6987 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1454 loss_train: 0.7029 acc_train: 0.8241 loss_val: 0.6983 acc_val: 0.8598 time: 0.0068s\n",
      "Epoch: 1455 loss_train: 0.7179 acc_train: 0.8273 loss_val: 0.6979 acc_val: 0.8598 time: 0.0071s\n",
      "Epoch: 1456 loss_train: 0.6986 acc_train: 0.8301 loss_val: 0.6976 acc_val: 0.8598 time: 0.0069s\n",
      "Epoch: 1457 loss_train: 0.7093 acc_train: 0.8310 loss_val: 0.6972 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1458 loss_train: 0.6986 acc_train: 0.8421 loss_val: 0.6968 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1459 loss_train: 0.6999 acc_train: 0.8412 loss_val: 0.6964 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1460 loss_train: 0.7216 acc_train: 0.8255 loss_val: 0.6961 acc_val: 0.8598 time: 0.0067s\n",
      "Epoch: 1461 loss_train: 0.7045 acc_train: 0.8370 loss_val: 0.6957 acc_val: 0.8598 time: 0.0070s\n",
      "Epoch: 1462 loss_train: 0.7179 acc_train: 0.8361 loss_val: 0.6954 acc_val: 0.8635 time: 0.0073s\n",
      "Epoch: 1463 loss_train: 0.7148 acc_train: 0.8347 loss_val: 0.6952 acc_val: 0.8672 time: 0.0070s\n",
      "Epoch: 1464 loss_train: 0.6991 acc_train: 0.8412 loss_val: 0.6949 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1465 loss_train: 0.7131 acc_train: 0.8232 loss_val: 0.6947 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1466 loss_train: 0.7004 acc_train: 0.8292 loss_val: 0.6943 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1467 loss_train: 0.7069 acc_train: 0.8324 loss_val: 0.6940 acc_val: 0.8708 time: 0.0072s\n",
      "Epoch: 1468 loss_train: 0.7069 acc_train: 0.8370 loss_val: 0.6936 acc_val: 0.8672 time: 0.0068s\n",
      "Epoch: 1469 loss_train: 0.7142 acc_train: 0.8310 loss_val: 0.6932 acc_val: 0.8672 time: 0.0066s\n",
      "Epoch: 1470 loss_train: 0.7000 acc_train: 0.8370 loss_val: 0.6927 acc_val: 0.8672 time: 0.0071s\n",
      "Epoch: 1471 loss_train: 0.7052 acc_train: 0.8236 loss_val: 0.6922 acc_val: 0.8672 time: 0.0072s\n",
      "Epoch: 1472 loss_train: 0.6954 acc_train: 0.8347 loss_val: 0.6916 acc_val: 0.8672 time: 0.0067s\n",
      "Epoch: 1473 loss_train: 0.7021 acc_train: 0.8393 loss_val: 0.6911 acc_val: 0.8672 time: 0.0071s\n",
      "Epoch: 1474 loss_train: 0.6968 acc_train: 0.8343 loss_val: 0.6906 acc_val: 0.8635 time: 0.0072s\n",
      "Epoch: 1475 loss_train: 0.6930 acc_train: 0.8398 loss_val: 0.6901 acc_val: 0.8672 time: 0.0070s\n",
      "Epoch: 1476 loss_train: 0.7154 acc_train: 0.8338 loss_val: 0.6897 acc_val: 0.8672 time: 0.0068s\n",
      "Epoch: 1477 loss_train: 0.6985 acc_train: 0.8356 loss_val: 0.6892 acc_val: 0.8672 time: 0.0068s\n",
      "Epoch: 1478 loss_train: 0.7158 acc_train: 0.8283 loss_val: 0.6888 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1479 loss_train: 0.7196 acc_train: 0.8296 loss_val: 0.6884 acc_val: 0.8672 time: 0.0074s\n",
      "Epoch: 1480 loss_train: 0.6745 acc_train: 0.8426 loss_val: 0.6880 acc_val: 0.8635 time: 0.0070s\n",
      "Epoch: 1481 loss_train: 0.6942 acc_train: 0.8412 loss_val: 0.6877 acc_val: 0.8635 time: 0.0067s\n",
      "Epoch: 1482 loss_train: 0.7151 acc_train: 0.8232 loss_val: 0.6874 acc_val: 0.8635 time: 0.0071s\n",
      "Epoch: 1483 loss_train: 0.6992 acc_train: 0.8444 loss_val: 0.6872 acc_val: 0.8672 time: 0.0072s\n",
      "Epoch: 1484 loss_train: 0.7167 acc_train: 0.8306 loss_val: 0.6870 acc_val: 0.8672 time: 0.0066s\n",
      "Epoch: 1485 loss_train: 0.7001 acc_train: 0.8343 loss_val: 0.6867 acc_val: 0.8672 time: 0.0070s\n",
      "Epoch: 1486 loss_train: 0.7221 acc_train: 0.8287 loss_val: 0.6864 acc_val: 0.8672 time: 0.0073s\n",
      "Epoch: 1487 loss_train: 0.7086 acc_train: 0.8167 loss_val: 0.6860 acc_val: 0.8635 time: 0.0069s\n",
      "Epoch: 1488 loss_train: 0.7035 acc_train: 0.8310 loss_val: 0.6855 acc_val: 0.8635 time: 0.0070s\n",
      "Epoch: 1489 loss_train: 0.7021 acc_train: 0.8343 loss_val: 0.6851 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1490 loss_train: 0.6861 acc_train: 0.8352 loss_val: 0.6847 acc_val: 0.8672 time: 0.0067s\n",
      "Epoch: 1491 loss_train: 0.6922 acc_train: 0.8393 loss_val: 0.6844 acc_val: 0.8672 time: 0.0071s\n",
      "Epoch: 1492 loss_train: 0.6997 acc_train: 0.8389 loss_val: 0.6841 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1493 loss_train: 0.6956 acc_train: 0.8287 loss_val: 0.6837 acc_val: 0.8672 time: 0.0066s\n",
      "Epoch: 1494 loss_train: 0.7041 acc_train: 0.8444 loss_val: 0.6832 acc_val: 0.8672 time: 0.0070s\n",
      "Epoch: 1495 loss_train: 0.7027 acc_train: 0.8380 loss_val: 0.6827 acc_val: 0.8672 time: 0.0071s\n",
      "Epoch: 1496 loss_train: 0.7303 acc_train: 0.8223 loss_val: 0.6821 acc_val: 0.8672 time: 0.0066s\n",
      "Epoch: 1497 loss_train: 0.6915 acc_train: 0.8195 loss_val: 0.6816 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1498 loss_train: 0.6744 acc_train: 0.8440 loss_val: 0.6811 acc_val: 0.8672 time: 0.0072s\n",
      "Epoch: 1499 loss_train: 0.6859 acc_train: 0.8426 loss_val: 0.6806 acc_val: 0.8672 time: 0.0070s\n",
      "Epoch: 1500 loss_train: 0.6853 acc_train: 0.8361 loss_val: 0.6801 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1501 loss_train: 0.6853 acc_train: 0.8407 loss_val: 0.6797 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1502 loss_train: 0.6976 acc_train: 0.8306 loss_val: 0.6792 acc_val: 0.8672 time: 0.0069s\n",
      "Epoch: 1503 loss_train: 0.6982 acc_train: 0.8315 loss_val: 0.6788 acc_val: 0.8672 time: 0.0073s\n",
      "Epoch: 1504 loss_train: 0.7010 acc_train: 0.8278 loss_val: 0.6784 acc_val: 0.8672 time: 0.0070s\n",
      "Epoch: 1505 loss_train: 0.6993 acc_train: 0.8375 loss_val: 0.6780 acc_val: 0.8672 time: 0.0066s\n",
      "Epoch: 1506 loss_train: 0.6947 acc_train: 0.8352 loss_val: 0.6777 acc_val: 0.8672 time: 0.0071s\n",
      "Epoch: 1507 loss_train: 0.6961 acc_train: 0.8384 loss_val: 0.6775 acc_val: 0.8672 time: 0.0073s\n",
      "Epoch: 1508 loss_train: 0.6931 acc_train: 0.8393 loss_val: 0.6772 acc_val: 0.8672 time: 0.0067s\n",
      "Epoch: 1509 loss_train: 0.6977 acc_train: 0.8356 loss_val: 0.6769 acc_val: 0.8672 time: 0.0070s\n",
      "Epoch: 1510 loss_train: 0.7047 acc_train: 0.8273 loss_val: 0.6766 acc_val: 0.8672 time: 0.0072s\n",
      "Epoch: 1511 loss_train: 0.6838 acc_train: 0.8398 loss_val: 0.6763 acc_val: 0.8708 time: 0.0070s\n",
      "Epoch: 1512 loss_train: 0.6862 acc_train: 0.8560 loss_val: 0.6760 acc_val: 0.8745 time: 0.0069s\n",
      "Epoch: 1513 loss_train: 0.6998 acc_train: 0.8426 loss_val: 0.6758 acc_val: 0.8745 time: 0.0069s\n",
      "Epoch: 1514 loss_train: 0.6920 acc_train: 0.8476 loss_val: 0.6755 acc_val: 0.8745 time: 0.0069s\n",
      "Epoch: 1515 loss_train: 0.6889 acc_train: 0.8407 loss_val: 0.6753 acc_val: 0.8745 time: 0.0073s\n",
      "Epoch: 1516 loss_train: 0.6847 acc_train: 0.8416 loss_val: 0.6751 acc_val: 0.8745 time: 0.0068s\n",
      "Epoch: 1517 loss_train: 0.7024 acc_train: 0.8370 loss_val: 0.6748 acc_val: 0.8745 time: 0.0068s\n",
      "Epoch: 1518 loss_train: 0.7066 acc_train: 0.8287 loss_val: 0.6745 acc_val: 0.8745 time: 0.0072s\n",
      "Epoch: 1519 loss_train: 0.6864 acc_train: 0.8366 loss_val: 0.6743 acc_val: 0.8745 time: 0.0075s\n",
      "Epoch: 1520 loss_train: 0.6887 acc_train: 0.8356 loss_val: 0.6739 acc_val: 0.8745 time: 0.0069s\n",
      "Epoch: 1521 loss_train: 0.6891 acc_train: 0.8412 loss_val: 0.6735 acc_val: 0.8745 time: 0.0069s\n",
      "Epoch: 1522 loss_train: 0.6909 acc_train: 0.8361 loss_val: 0.6730 acc_val: 0.8745 time: 0.0073s\n",
      "Epoch: 1523 loss_train: 0.6978 acc_train: 0.8380 loss_val: 0.6724 acc_val: 0.8745 time: 0.0070s\n",
      "Epoch: 1524 loss_train: 0.6730 acc_train: 0.8324 loss_val: 0.6719 acc_val: 0.8782 time: 0.0070s\n",
      "Epoch: 1525 loss_train: 0.6810 acc_train: 0.8324 loss_val: 0.6713 acc_val: 0.8782 time: 0.0069s\n",
      "Epoch: 1526 loss_train: 0.6629 acc_train: 0.8476 loss_val: 0.6707 acc_val: 0.8782 time: 0.0070s\n",
      "Epoch: 1527 loss_train: 0.7075 acc_train: 0.8347 loss_val: 0.6701 acc_val: 0.8782 time: 0.0073s\n",
      "Epoch: 1528 loss_train: 0.6904 acc_train: 0.8343 loss_val: 0.6696 acc_val: 0.8782 time: 0.0071s\n",
      "Epoch: 1529 loss_train: 0.6772 acc_train: 0.8430 loss_val: 0.6691 acc_val: 0.8782 time: 0.0068s\n",
      "Epoch: 1530 loss_train: 0.6812 acc_train: 0.8356 loss_val: 0.6687 acc_val: 0.8782 time: 0.0070s\n",
      "Epoch: 1531 loss_train: 0.6905 acc_train: 0.8430 loss_val: 0.6684 acc_val: 0.8782 time: 0.0071s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1532 loss_train: 0.6809 acc_train: 0.8393 loss_val: 0.6680 acc_val: 0.8782 time: 0.0066s\n",
      "Epoch: 1533 loss_train: 0.6711 acc_train: 0.8421 loss_val: 0.6677 acc_val: 0.8782 time: 0.0069s\n",
      "Epoch: 1534 loss_train: 0.6809 acc_train: 0.8370 loss_val: 0.6674 acc_val: 0.8782 time: 0.0070s\n",
      "Epoch: 1535 loss_train: 0.6761 acc_train: 0.8426 loss_val: 0.6671 acc_val: 0.8782 time: 0.0069s\n",
      "Epoch: 1536 loss_train: 0.6787 acc_train: 0.8449 loss_val: 0.6667 acc_val: 0.8782 time: 0.0068s\n",
      "Epoch: 1537 loss_train: 0.6806 acc_train: 0.8273 loss_val: 0.6664 acc_val: 0.8782 time: 0.0070s\n",
      "Epoch: 1538 loss_train: 0.6777 acc_train: 0.8389 loss_val: 0.6661 acc_val: 0.8782 time: 0.0068s\n",
      "Epoch: 1539 loss_train: 0.6815 acc_train: 0.8393 loss_val: 0.6657 acc_val: 0.8782 time: 0.0074s\n",
      "Epoch: 1540 loss_train: 0.6783 acc_train: 0.8453 loss_val: 0.6655 acc_val: 0.8819 time: 0.0068s\n",
      "Epoch: 1541 loss_train: 0.6836 acc_train: 0.8407 loss_val: 0.6652 acc_val: 0.8819 time: 0.0067s\n",
      "Epoch: 1542 loss_train: 0.6800 acc_train: 0.8403 loss_val: 0.6649 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1543 loss_train: 0.6929 acc_train: 0.8347 loss_val: 0.6647 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1544 loss_train: 0.6737 acc_train: 0.8430 loss_val: 0.6645 acc_val: 0.8819 time: 0.0067s\n",
      "Epoch: 1545 loss_train: 0.6694 acc_train: 0.8546 loss_val: 0.6642 acc_val: 0.8819 time: 0.0070s\n",
      "Epoch: 1546 loss_train: 0.6861 acc_train: 0.8370 loss_val: 0.6639 acc_val: 0.8819 time: 0.0073s\n",
      "Epoch: 1547 loss_train: 0.6601 acc_train: 0.8416 loss_val: 0.6636 acc_val: 0.8819 time: 0.0071s\n",
      "Epoch: 1548 loss_train: 0.6629 acc_train: 0.8449 loss_val: 0.6632 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1549 loss_train: 0.6918 acc_train: 0.8412 loss_val: 0.6629 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1550 loss_train: 0.6892 acc_train: 0.8370 loss_val: 0.6624 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1551 loss_train: 0.6812 acc_train: 0.8329 loss_val: 0.6620 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1552 loss_train: 0.6801 acc_train: 0.8458 loss_val: 0.6616 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1553 loss_train: 0.6655 acc_train: 0.8338 loss_val: 0.6612 acc_val: 0.8819 time: 0.0066s\n",
      "Epoch: 1554 loss_train: 0.6637 acc_train: 0.8495 loss_val: 0.6609 acc_val: 0.8819 time: 0.0070s\n",
      "Epoch: 1555 loss_train: 0.6720 acc_train: 0.8453 loss_val: 0.6604 acc_val: 0.8819 time: 0.0071s\n",
      "Epoch: 1556 loss_train: 0.6774 acc_train: 0.8472 loss_val: 0.6600 acc_val: 0.8819 time: 0.0066s\n",
      "Epoch: 1557 loss_train: 0.6582 acc_train: 0.8504 loss_val: 0.6595 acc_val: 0.8819 time: 0.0071s\n",
      "Epoch: 1558 loss_train: 0.6757 acc_train: 0.8310 loss_val: 0.6591 acc_val: 0.8819 time: 0.0071s\n",
      "Epoch: 1559 loss_train: 0.6636 acc_train: 0.8435 loss_val: 0.6589 acc_val: 0.8819 time: 0.0070s\n",
      "Epoch: 1560 loss_train: 0.6663 acc_train: 0.8370 loss_val: 0.6585 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1561 loss_train: 0.6779 acc_train: 0.8449 loss_val: 0.6582 acc_val: 0.8819 time: 0.0071s\n",
      "Epoch: 1562 loss_train: 0.6898 acc_train: 0.8352 loss_val: 0.6579 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1563 loss_train: 0.6763 acc_train: 0.8426 loss_val: 0.6576 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1564 loss_train: 0.6601 acc_train: 0.8412 loss_val: 0.6572 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1565 loss_train: 0.6670 acc_train: 0.8384 loss_val: 0.6567 acc_val: 0.8819 time: 0.0067s\n",
      "Epoch: 1566 loss_train: 0.6798 acc_train: 0.8283 loss_val: 0.6564 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1567 loss_train: 0.6624 acc_train: 0.8476 loss_val: 0.6560 acc_val: 0.8856 time: 0.0074s\n",
      "Epoch: 1568 loss_train: 0.6561 acc_train: 0.8560 loss_val: 0.6555 acc_val: 0.8856 time: 0.0070s\n",
      "Epoch: 1569 loss_train: 0.6857 acc_train: 0.8333 loss_val: 0.6551 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1570 loss_train: 0.6561 acc_train: 0.8560 loss_val: 0.6547 acc_val: 0.8856 time: 0.0072s\n",
      "Epoch: 1571 loss_train: 0.6491 acc_train: 0.8532 loss_val: 0.6544 acc_val: 0.8856 time: 0.0069s\n",
      "Epoch: 1572 loss_train: 0.6666 acc_train: 0.8513 loss_val: 0.6540 acc_val: 0.8856 time: 0.0069s\n",
      "Epoch: 1573 loss_train: 0.6960 acc_train: 0.8306 loss_val: 0.6538 acc_val: 0.8856 time: 0.0070s\n",
      "Epoch: 1574 loss_train: 0.6439 acc_train: 0.8527 loss_val: 0.6535 acc_val: 0.8856 time: 0.0067s\n",
      "Epoch: 1575 loss_train: 0.6654 acc_train: 0.8352 loss_val: 0.6533 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1576 loss_train: 0.6681 acc_train: 0.8523 loss_val: 0.6530 acc_val: 0.8856 time: 0.0068s\n",
      "Epoch: 1577 loss_train: 0.6645 acc_train: 0.8426 loss_val: 0.6525 acc_val: 0.8856 time: 0.0066s\n",
      "Epoch: 1578 loss_train: 0.6679 acc_train: 0.8412 loss_val: 0.6522 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1579 loss_train: 0.6590 acc_train: 0.8472 loss_val: 0.6519 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1580 loss_train: 0.6629 acc_train: 0.8472 loss_val: 0.6517 acc_val: 0.8856 time: 0.0070s\n",
      "Epoch: 1581 loss_train: 0.6760 acc_train: 0.8338 loss_val: 0.6515 acc_val: 0.8856 time: 0.0070s\n",
      "Epoch: 1582 loss_train: 0.6750 acc_train: 0.8440 loss_val: 0.6513 acc_val: 0.8856 time: 0.0072s\n",
      "Epoch: 1583 loss_train: 0.6694 acc_train: 0.8467 loss_val: 0.6511 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1584 loss_train: 0.6878 acc_train: 0.8389 loss_val: 0.6509 acc_val: 0.8819 time: 0.0070s\n",
      "Epoch: 1585 loss_train: 0.6783 acc_train: 0.8407 loss_val: 0.6508 acc_val: 0.8819 time: 0.0070s\n",
      "Epoch: 1586 loss_train: 0.6776 acc_train: 0.8380 loss_val: 0.6506 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1587 loss_train: 0.6899 acc_train: 0.8398 loss_val: 0.6504 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1588 loss_train: 0.6570 acc_train: 0.8495 loss_val: 0.6502 acc_val: 0.8819 time: 0.0069s\n",
      "Epoch: 1589 loss_train: 0.6625 acc_train: 0.8356 loss_val: 0.6500 acc_val: 0.8819 time: 0.0066s\n",
      "Epoch: 1590 loss_train: 0.6704 acc_train: 0.8412 loss_val: 0.6496 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1591 loss_train: 0.6653 acc_train: 0.8500 loss_val: 0.6493 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1592 loss_train: 0.6524 acc_train: 0.8426 loss_val: 0.6490 acc_val: 0.8856 time: 0.0067s\n",
      "Epoch: 1593 loss_train: 0.6691 acc_train: 0.8440 loss_val: 0.6486 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1594 loss_train: 0.6513 acc_train: 0.8458 loss_val: 0.6482 acc_val: 0.8856 time: 0.0072s\n",
      "Epoch: 1595 loss_train: 0.6835 acc_train: 0.8416 loss_val: 0.6478 acc_val: 0.8856 time: 0.0070s\n",
      "Epoch: 1596 loss_train: 0.6652 acc_train: 0.8380 loss_val: 0.6474 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1597 loss_train: 0.6671 acc_train: 0.8384 loss_val: 0.6471 acc_val: 0.8856 time: 0.0068s\n",
      "Epoch: 1598 loss_train: 0.6553 acc_train: 0.8527 loss_val: 0.6467 acc_val: 0.8856 time: 0.0068s\n",
      "Epoch: 1599 loss_train: 0.6522 acc_train: 0.8467 loss_val: 0.6463 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1600 loss_train: 0.6679 acc_train: 0.8389 loss_val: 0.6458 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1601 loss_train: 0.6759 acc_train: 0.8407 loss_val: 0.6453 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1602 loss_train: 0.6706 acc_train: 0.8472 loss_val: 0.6448 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1603 loss_train: 0.6646 acc_train: 0.8398 loss_val: 0.6444 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 1604 loss_train: 0.6691 acc_train: 0.8421 loss_val: 0.6441 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1605 loss_train: 0.6795 acc_train: 0.8407 loss_val: 0.6438 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1606 loss_train: 0.6644 acc_train: 0.8490 loss_val: 0.6435 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1607 loss_train: 0.6598 acc_train: 0.8384 loss_val: 0.6434 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1608 loss_train: 0.6576 acc_train: 0.8541 loss_val: 0.6433 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1609 loss_train: 0.6588 acc_train: 0.8463 loss_val: 0.6433 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1610 loss_train: 0.6634 acc_train: 0.8435 loss_val: 0.6432 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1611 loss_train: 0.6506 acc_train: 0.8486 loss_val: 0.6432 acc_val: 0.8856 time: 0.0072s\n",
      "Epoch: 1612 loss_train: 0.6445 acc_train: 0.8463 loss_val: 0.6432 acc_val: 0.8856 time: 0.0068s\n",
      "Epoch: 1613 loss_train: 0.6631 acc_train: 0.8486 loss_val: 0.6431 acc_val: 0.8856 time: 0.0067s\n",
      "Epoch: 1614 loss_train: 0.6388 acc_train: 0.8421 loss_val: 0.6430 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1615 loss_train: 0.6635 acc_train: 0.8407 loss_val: 0.6429 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1616 loss_train: 0.6682 acc_train: 0.8440 loss_val: 0.6426 acc_val: 0.8819 time: 0.0067s\n",
      "Epoch: 1617 loss_train: 0.6669 acc_train: 0.8412 loss_val: 0.6423 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1618 loss_train: 0.6621 acc_train: 0.8523 loss_val: 0.6418 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1619 loss_train: 0.6600 acc_train: 0.8518 loss_val: 0.6413 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1620 loss_train: 0.6558 acc_train: 0.8393 loss_val: 0.6408 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1621 loss_train: 0.6471 acc_train: 0.8500 loss_val: 0.6402 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1622 loss_train: 0.6497 acc_train: 0.8500 loss_val: 0.6397 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1623 loss_train: 0.6373 acc_train: 0.8550 loss_val: 0.6393 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1624 loss_train: 0.6539 acc_train: 0.8407 loss_val: 0.6388 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1625 loss_train: 0.6712 acc_train: 0.8430 loss_val: 0.6383 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1626 loss_train: 0.6506 acc_train: 0.8416 loss_val: 0.6378 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1627 loss_train: 0.6622 acc_train: 0.8467 loss_val: 0.6374 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1628 loss_train: 0.6660 acc_train: 0.8490 loss_val: 0.6370 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1629 loss_train: 0.6696 acc_train: 0.8449 loss_val: 0.6367 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1630 loss_train: 0.6623 acc_train: 0.8532 loss_val: 0.6366 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 1631 loss_train: 0.6567 acc_train: 0.8518 loss_val: 0.6365 acc_val: 0.8893 time: 0.0070s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1632 loss_train: 0.6368 acc_train: 0.8490 loss_val: 0.6365 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1633 loss_train: 0.6501 acc_train: 0.8495 loss_val: 0.6365 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1634 loss_train: 0.6481 acc_train: 0.8513 loss_val: 0.6366 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1635 loss_train: 0.6599 acc_train: 0.8393 loss_val: 0.6366 acc_val: 0.8856 time: 0.0074s\n",
      "Epoch: 1636 loss_train: 0.6394 acc_train: 0.8527 loss_val: 0.6366 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1637 loss_train: 0.6411 acc_train: 0.8546 loss_val: 0.6366 acc_val: 0.8856 time: 0.0068s\n",
      "Epoch: 1638 loss_train: 0.6594 acc_train: 0.8375 loss_val: 0.6366 acc_val: 0.8856 time: 0.0072s\n",
      "Epoch: 1639 loss_train: 0.6772 acc_train: 0.8343 loss_val: 0.6364 acc_val: 0.8856 time: 0.0074s\n",
      "Epoch: 1640 loss_train: 0.6448 acc_train: 0.8458 loss_val: 0.6361 acc_val: 0.8856 time: 0.0067s\n",
      "Epoch: 1641 loss_train: 0.6487 acc_train: 0.8430 loss_val: 0.6357 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1642 loss_train: 0.6332 acc_train: 0.8564 loss_val: 0.6353 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1643 loss_train: 0.6500 acc_train: 0.8500 loss_val: 0.6349 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1644 loss_train: 0.6477 acc_train: 0.8486 loss_val: 0.6344 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1645 loss_train: 0.6603 acc_train: 0.8416 loss_val: 0.6339 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1646 loss_train: 0.6539 acc_train: 0.8467 loss_val: 0.6334 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1647 loss_train: 0.6591 acc_train: 0.8476 loss_val: 0.6330 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1648 loss_train: 0.6521 acc_train: 0.8444 loss_val: 0.6326 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1649 loss_train: 0.6628 acc_train: 0.8380 loss_val: 0.6323 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1650 loss_train: 0.6441 acc_train: 0.8657 loss_val: 0.6319 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1651 loss_train: 0.6512 acc_train: 0.8500 loss_val: 0.6315 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 1652 loss_train: 0.6571 acc_train: 0.8444 loss_val: 0.6313 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1653 loss_train: 0.6449 acc_train: 0.8453 loss_val: 0.6311 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1654 loss_train: 0.6412 acc_train: 0.8550 loss_val: 0.6310 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1655 loss_train: 0.6618 acc_train: 0.8527 loss_val: 0.6308 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1656 loss_train: 0.6665 acc_train: 0.8384 loss_val: 0.6307 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1657 loss_train: 0.6399 acc_train: 0.8476 loss_val: 0.6305 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1658 loss_train: 0.6555 acc_train: 0.8518 loss_val: 0.6302 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1659 loss_train: 0.6470 acc_train: 0.8523 loss_val: 0.6299 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1660 loss_train: 0.6550 acc_train: 0.8449 loss_val: 0.6297 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1661 loss_train: 0.6578 acc_train: 0.8412 loss_val: 0.6294 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1662 loss_train: 0.6354 acc_train: 0.8518 loss_val: 0.6291 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1663 loss_train: 0.6328 acc_train: 0.8560 loss_val: 0.6289 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1664 loss_train: 0.6427 acc_train: 0.8481 loss_val: 0.6288 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1665 loss_train: 0.6469 acc_train: 0.8578 loss_val: 0.6286 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1666 loss_train: 0.6454 acc_train: 0.8564 loss_val: 0.6283 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1667 loss_train: 0.6330 acc_train: 0.8601 loss_val: 0.6281 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1668 loss_train: 0.6174 acc_train: 0.8596 loss_val: 0.6280 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1669 loss_train: 0.6621 acc_train: 0.8463 loss_val: 0.6278 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1670 loss_train: 0.6276 acc_train: 0.8666 loss_val: 0.6277 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1671 loss_train: 0.6529 acc_train: 0.8449 loss_val: 0.6277 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 1672 loss_train: 0.6407 acc_train: 0.8495 loss_val: 0.6276 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1673 loss_train: 0.6508 acc_train: 0.8467 loss_val: 0.6275 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1674 loss_train: 0.6350 acc_train: 0.8518 loss_val: 0.6273 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1675 loss_train: 0.6549 acc_train: 0.8412 loss_val: 0.6270 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1676 loss_train: 0.6485 acc_train: 0.8449 loss_val: 0.6267 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1677 loss_train: 0.6319 acc_train: 0.8500 loss_val: 0.6263 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1678 loss_train: 0.6518 acc_train: 0.8463 loss_val: 0.6259 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1679 loss_train: 0.6350 acc_train: 0.8578 loss_val: 0.6253 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1680 loss_train: 0.6414 acc_train: 0.8550 loss_val: 0.6248 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1681 loss_train: 0.6535 acc_train: 0.8403 loss_val: 0.6243 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1682 loss_train: 0.6571 acc_train: 0.8440 loss_val: 0.6240 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1683 loss_train: 0.6442 acc_train: 0.8444 loss_val: 0.6237 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1684 loss_train: 0.6371 acc_train: 0.8500 loss_val: 0.6234 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1685 loss_train: 0.6475 acc_train: 0.8518 loss_val: 0.6231 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1686 loss_train: 0.6533 acc_train: 0.8403 loss_val: 0.6229 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1687 loss_train: 0.6533 acc_train: 0.8458 loss_val: 0.6227 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1688 loss_train: 0.6223 acc_train: 0.8596 loss_val: 0.6225 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 1689 loss_train: 0.6323 acc_train: 0.8518 loss_val: 0.6224 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1690 loss_train: 0.6538 acc_train: 0.8463 loss_val: 0.6222 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1691 loss_train: 0.6504 acc_train: 0.8444 loss_val: 0.6222 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1692 loss_train: 0.6291 acc_train: 0.8536 loss_val: 0.6221 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1693 loss_train: 0.6586 acc_train: 0.8389 loss_val: 0.6220 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1694 loss_train: 0.6665 acc_train: 0.8384 loss_val: 0.6220 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1695 loss_train: 0.6447 acc_train: 0.8518 loss_val: 0.6220 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1696 loss_train: 0.6284 acc_train: 0.8476 loss_val: 0.6220 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1697 loss_train: 0.6461 acc_train: 0.8486 loss_val: 0.6218 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1698 loss_train: 0.6360 acc_train: 0.8583 loss_val: 0.6216 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1699 loss_train: 0.6483 acc_train: 0.8444 loss_val: 0.6214 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1700 loss_train: 0.6460 acc_train: 0.8347 loss_val: 0.6212 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1701 loss_train: 0.6403 acc_train: 0.8541 loss_val: 0.6210 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1702 loss_train: 0.6449 acc_train: 0.8523 loss_val: 0.6208 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1703 loss_train: 0.6382 acc_train: 0.8546 loss_val: 0.6206 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1704 loss_train: 0.6492 acc_train: 0.8587 loss_val: 0.6202 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1705 loss_train: 0.6205 acc_train: 0.8555 loss_val: 0.6199 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1706 loss_train: 0.6365 acc_train: 0.8518 loss_val: 0.6196 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1707 loss_train: 0.6277 acc_train: 0.8578 loss_val: 0.6192 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1708 loss_train: 0.6367 acc_train: 0.8536 loss_val: 0.6189 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1709 loss_train: 0.6554 acc_train: 0.8500 loss_val: 0.6187 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1710 loss_train: 0.6438 acc_train: 0.8546 loss_val: 0.6184 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1711 loss_train: 0.6692 acc_train: 0.8426 loss_val: 0.6181 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1712 loss_train: 0.6338 acc_train: 0.8463 loss_val: 0.6179 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1713 loss_train: 0.6312 acc_train: 0.8536 loss_val: 0.6176 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1714 loss_train: 0.6523 acc_train: 0.8476 loss_val: 0.6174 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1715 loss_train: 0.6422 acc_train: 0.8430 loss_val: 0.6171 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1716 loss_train: 0.6346 acc_train: 0.8527 loss_val: 0.6167 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1717 loss_train: 0.6499 acc_train: 0.8509 loss_val: 0.6163 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1718 loss_train: 0.6528 acc_train: 0.8440 loss_val: 0.6160 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1719 loss_train: 0.6454 acc_train: 0.8583 loss_val: 0.6157 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1720 loss_train: 0.6395 acc_train: 0.8500 loss_val: 0.6153 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1721 loss_train: 0.6409 acc_train: 0.8523 loss_val: 0.6148 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1722 loss_train: 0.6206 acc_train: 0.8513 loss_val: 0.6144 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1723 loss_train: 0.6497 acc_train: 0.8453 loss_val: 0.6141 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1724 loss_train: 0.6213 acc_train: 0.8555 loss_val: 0.6138 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1725 loss_train: 0.6460 acc_train: 0.8509 loss_val: 0.6135 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1726 loss_train: 0.6066 acc_train: 0.8573 loss_val: 0.6133 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1727 loss_train: 0.6348 acc_train: 0.8578 loss_val: 0.6130 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1728 loss_train: 0.6243 acc_train: 0.8560 loss_val: 0.6127 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1729 loss_train: 0.6416 acc_train: 0.8513 loss_val: 0.6126 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1730 loss_train: 0.6470 acc_train: 0.8481 loss_val: 0.6124 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1731 loss_train: 0.6359 acc_train: 0.8490 loss_val: 0.6122 acc_val: 0.8930 time: 0.0073s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1732 loss_train: 0.6232 acc_train: 0.8583 loss_val: 0.6119 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1733 loss_train: 0.6297 acc_train: 0.8495 loss_val: 0.6116 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1734 loss_train: 0.6344 acc_train: 0.8564 loss_val: 0.6114 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1735 loss_train: 0.6298 acc_train: 0.8509 loss_val: 0.6113 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1736 loss_train: 0.6076 acc_train: 0.8573 loss_val: 0.6111 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1737 loss_train: 0.6203 acc_train: 0.8601 loss_val: 0.6110 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1738 loss_train: 0.6163 acc_train: 0.8583 loss_val: 0.6108 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1739 loss_train: 0.6258 acc_train: 0.8500 loss_val: 0.6107 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1740 loss_train: 0.6310 acc_train: 0.8573 loss_val: 0.6105 acc_val: 0.8930 time: 0.0117s\n",
      "Epoch: 1741 loss_train: 0.6174 acc_train: 0.8592 loss_val: 0.6103 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1742 loss_train: 0.6262 acc_train: 0.8546 loss_val: 0.6102 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1743 loss_train: 0.6291 acc_train: 0.8513 loss_val: 0.6101 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1744 loss_train: 0.6197 acc_train: 0.8587 loss_val: 0.6099 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1745 loss_train: 0.6366 acc_train: 0.8513 loss_val: 0.6097 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1746 loss_train: 0.6225 acc_train: 0.8578 loss_val: 0.6095 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1747 loss_train: 0.6404 acc_train: 0.8509 loss_val: 0.6093 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1748 loss_train: 0.6294 acc_train: 0.8532 loss_val: 0.6090 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1749 loss_train: 0.6226 acc_train: 0.8587 loss_val: 0.6087 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1750 loss_train: 0.6254 acc_train: 0.8481 loss_val: 0.6085 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1751 loss_train: 0.6237 acc_train: 0.8486 loss_val: 0.6082 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1752 loss_train: 0.6145 acc_train: 0.8652 loss_val: 0.6080 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1753 loss_train: 0.6289 acc_train: 0.8532 loss_val: 0.6077 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1754 loss_train: 0.6162 acc_train: 0.8606 loss_val: 0.6073 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1755 loss_train: 0.6165 acc_train: 0.8463 loss_val: 0.6070 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1756 loss_train: 0.6289 acc_train: 0.8467 loss_val: 0.6067 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1757 loss_train: 0.6312 acc_train: 0.8578 loss_val: 0.6063 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1758 loss_train: 0.6336 acc_train: 0.8638 loss_val: 0.6058 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1759 loss_train: 0.6016 acc_train: 0.8587 loss_val: 0.6055 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1760 loss_train: 0.6112 acc_train: 0.8643 loss_val: 0.6053 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1761 loss_train: 0.6168 acc_train: 0.8573 loss_val: 0.6051 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1762 loss_train: 0.6358 acc_train: 0.8440 loss_val: 0.6049 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1763 loss_train: 0.6368 acc_train: 0.8412 loss_val: 0.6046 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1764 loss_train: 0.6076 acc_train: 0.8661 loss_val: 0.6045 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1765 loss_train: 0.6244 acc_train: 0.8560 loss_val: 0.6044 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1766 loss_train: 0.6216 acc_train: 0.8509 loss_val: 0.6043 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1767 loss_train: 0.6295 acc_train: 0.8467 loss_val: 0.6042 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1768 loss_train: 0.6204 acc_train: 0.8523 loss_val: 0.6042 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1769 loss_train: 0.6165 acc_train: 0.8601 loss_val: 0.6042 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1770 loss_train: 0.6313 acc_train: 0.8463 loss_val: 0.6042 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1771 loss_train: 0.6020 acc_train: 0.8624 loss_val: 0.6041 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1772 loss_train: 0.6240 acc_train: 0.8458 loss_val: 0.6041 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1773 loss_train: 0.6250 acc_train: 0.8550 loss_val: 0.6040 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1774 loss_train: 0.6231 acc_train: 0.8546 loss_val: 0.6039 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1775 loss_train: 0.6204 acc_train: 0.8527 loss_val: 0.6039 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1776 loss_train: 0.6234 acc_train: 0.8550 loss_val: 0.6038 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1777 loss_train: 0.6237 acc_train: 0.8587 loss_val: 0.6036 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1778 loss_train: 0.6158 acc_train: 0.8546 loss_val: 0.6034 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1779 loss_train: 0.6228 acc_train: 0.8536 loss_val: 0.6032 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1780 loss_train: 0.6232 acc_train: 0.8495 loss_val: 0.6029 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1781 loss_train: 0.6138 acc_train: 0.8550 loss_val: 0.6026 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1782 loss_train: 0.6070 acc_train: 0.8541 loss_val: 0.6023 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1783 loss_train: 0.6092 acc_train: 0.8643 loss_val: 0.6020 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1784 loss_train: 0.6319 acc_train: 0.8509 loss_val: 0.6016 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1785 loss_train: 0.6058 acc_train: 0.8546 loss_val: 0.6013 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1786 loss_train: 0.6121 acc_train: 0.8509 loss_val: 0.6012 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1787 loss_train: 0.6181 acc_train: 0.8587 loss_val: 0.6012 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1788 loss_train: 0.6161 acc_train: 0.8624 loss_val: 0.6011 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1789 loss_train: 0.6197 acc_train: 0.8587 loss_val: 0.6010 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1790 loss_train: 0.6044 acc_train: 0.8560 loss_val: 0.6009 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1791 loss_train: 0.6106 acc_train: 0.8550 loss_val: 0.6007 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1792 loss_train: 0.6121 acc_train: 0.8513 loss_val: 0.6004 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1793 loss_train: 0.6125 acc_train: 0.8546 loss_val: 0.6001 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1794 loss_train: 0.6226 acc_train: 0.8560 loss_val: 0.5998 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1795 loss_train: 0.6294 acc_train: 0.8495 loss_val: 0.5996 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1796 loss_train: 0.6053 acc_train: 0.8638 loss_val: 0.5993 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1797 loss_train: 0.6074 acc_train: 0.8657 loss_val: 0.5990 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1798 loss_train: 0.6211 acc_train: 0.8449 loss_val: 0.5987 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1799 loss_train: 0.6028 acc_train: 0.8675 loss_val: 0.5984 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1800 loss_train: 0.5901 acc_train: 0.8643 loss_val: 0.5981 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1801 loss_train: 0.6209 acc_train: 0.8606 loss_val: 0.5978 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1802 loss_train: 0.6156 acc_train: 0.8490 loss_val: 0.5974 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1803 loss_train: 0.6068 acc_train: 0.8606 loss_val: 0.5971 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1804 loss_train: 0.6150 acc_train: 0.8657 loss_val: 0.5967 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1805 loss_train: 0.6128 acc_train: 0.8569 loss_val: 0.5963 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1806 loss_train: 0.5968 acc_train: 0.8610 loss_val: 0.5960 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1807 loss_train: 0.6111 acc_train: 0.8546 loss_val: 0.5958 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1808 loss_train: 0.6111 acc_train: 0.8550 loss_val: 0.5955 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1809 loss_train: 0.6205 acc_train: 0.8504 loss_val: 0.5954 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1810 loss_train: 0.6139 acc_train: 0.8573 loss_val: 0.5951 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1811 loss_train: 0.6054 acc_train: 0.8490 loss_val: 0.5949 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1812 loss_train: 0.6064 acc_train: 0.8578 loss_val: 0.5947 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1813 loss_train: 0.6252 acc_train: 0.8578 loss_val: 0.5947 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1814 loss_train: 0.6196 acc_train: 0.8596 loss_val: 0.5948 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1815 loss_train: 0.6202 acc_train: 0.8550 loss_val: 0.5949 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1816 loss_train: 0.6144 acc_train: 0.8578 loss_val: 0.5950 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1817 loss_train: 0.6234 acc_train: 0.8546 loss_val: 0.5952 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1818 loss_train: 0.6049 acc_train: 0.8550 loss_val: 0.5954 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1819 loss_train: 0.6191 acc_train: 0.8500 loss_val: 0.5954 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1820 loss_train: 0.6058 acc_train: 0.8583 loss_val: 0.5954 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1821 loss_train: 0.6175 acc_train: 0.8536 loss_val: 0.5952 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1822 loss_train: 0.6240 acc_train: 0.8472 loss_val: 0.5949 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1823 loss_train: 0.6002 acc_train: 0.8601 loss_val: 0.5945 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1824 loss_train: 0.6062 acc_train: 0.8578 loss_val: 0.5940 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1825 loss_train: 0.6035 acc_train: 0.8550 loss_val: 0.5935 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1826 loss_train: 0.5999 acc_train: 0.8564 loss_val: 0.5929 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1827 loss_train: 0.6123 acc_train: 0.8536 loss_val: 0.5923 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1828 loss_train: 0.5945 acc_train: 0.8620 loss_val: 0.5917 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1829 loss_train: 0.6117 acc_train: 0.8472 loss_val: 0.5913 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1830 loss_train: 0.6104 acc_train: 0.8513 loss_val: 0.5909 acc_val: 0.8930 time: 0.0066s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1831 loss_train: 0.6183 acc_train: 0.8564 loss_val: 0.5906 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1832 loss_train: 0.5855 acc_train: 0.8624 loss_val: 0.5902 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1833 loss_train: 0.6177 acc_train: 0.8596 loss_val: 0.5899 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1834 loss_train: 0.6212 acc_train: 0.8513 loss_val: 0.5897 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1835 loss_train: 0.6194 acc_train: 0.8620 loss_val: 0.5894 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1836 loss_train: 0.6091 acc_train: 0.8546 loss_val: 0.5892 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1837 loss_train: 0.6109 acc_train: 0.8583 loss_val: 0.5891 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1838 loss_train: 0.6164 acc_train: 0.8583 loss_val: 0.5889 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1839 loss_train: 0.6084 acc_train: 0.8564 loss_val: 0.5887 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1840 loss_train: 0.6000 acc_train: 0.8573 loss_val: 0.5885 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1841 loss_train: 0.6187 acc_train: 0.8523 loss_val: 0.5883 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1842 loss_train: 0.6038 acc_train: 0.8615 loss_val: 0.5881 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1843 loss_train: 0.6149 acc_train: 0.8546 loss_val: 0.5880 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1844 loss_train: 0.6003 acc_train: 0.8573 loss_val: 0.5878 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1845 loss_train: 0.6033 acc_train: 0.8652 loss_val: 0.5875 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1846 loss_train: 0.5963 acc_train: 0.8624 loss_val: 0.5873 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1847 loss_train: 0.5985 acc_train: 0.8518 loss_val: 0.5872 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1848 loss_train: 0.6068 acc_train: 0.8564 loss_val: 0.5871 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1849 loss_train: 0.5850 acc_train: 0.8596 loss_val: 0.5870 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1850 loss_train: 0.6094 acc_train: 0.8560 loss_val: 0.5867 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1851 loss_train: 0.5928 acc_train: 0.8633 loss_val: 0.5866 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1852 loss_train: 0.6017 acc_train: 0.8689 loss_val: 0.5865 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1853 loss_train: 0.5999 acc_train: 0.8555 loss_val: 0.5862 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1854 loss_train: 0.5974 acc_train: 0.8643 loss_val: 0.5860 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 1855 loss_train: 0.6031 acc_train: 0.8647 loss_val: 0.5857 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1856 loss_train: 0.5898 acc_train: 0.8573 loss_val: 0.5855 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1857 loss_train: 0.6133 acc_train: 0.8550 loss_val: 0.5852 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1858 loss_train: 0.5760 acc_train: 0.8680 loss_val: 0.5849 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1859 loss_train: 0.5923 acc_train: 0.8633 loss_val: 0.5848 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1860 loss_train: 0.6074 acc_train: 0.8573 loss_val: 0.5846 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1861 loss_train: 0.5934 acc_train: 0.8638 loss_val: 0.5845 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1862 loss_train: 0.5901 acc_train: 0.8657 loss_val: 0.5844 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1863 loss_train: 0.6006 acc_train: 0.8513 loss_val: 0.5843 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1864 loss_train: 0.6046 acc_train: 0.8564 loss_val: 0.5841 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1865 loss_train: 0.5891 acc_train: 0.8583 loss_val: 0.5840 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1866 loss_train: 0.5968 acc_train: 0.8629 loss_val: 0.5838 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1867 loss_train: 0.6043 acc_train: 0.8601 loss_val: 0.5835 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1868 loss_train: 0.5956 acc_train: 0.8638 loss_val: 0.5832 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1869 loss_train: 0.6062 acc_train: 0.8578 loss_val: 0.5829 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1870 loss_train: 0.5923 acc_train: 0.8643 loss_val: 0.5827 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1871 loss_train: 0.5805 acc_train: 0.8753 loss_val: 0.5825 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1872 loss_train: 0.6081 acc_train: 0.8523 loss_val: 0.5823 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1873 loss_train: 0.5940 acc_train: 0.8541 loss_val: 0.5821 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1874 loss_train: 0.5847 acc_train: 0.8606 loss_val: 0.5819 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1875 loss_train: 0.6125 acc_train: 0.8606 loss_val: 0.5817 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1876 loss_train: 0.6054 acc_train: 0.8518 loss_val: 0.5814 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1877 loss_train: 0.5917 acc_train: 0.8592 loss_val: 0.5811 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1878 loss_train: 0.6069 acc_train: 0.8610 loss_val: 0.5808 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1879 loss_train: 0.5893 acc_train: 0.8564 loss_val: 0.5805 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1880 loss_train: 0.6001 acc_train: 0.8652 loss_val: 0.5803 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1881 loss_train: 0.5688 acc_train: 0.8721 loss_val: 0.5800 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1882 loss_train: 0.5920 acc_train: 0.8550 loss_val: 0.5799 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1883 loss_train: 0.5841 acc_train: 0.8615 loss_val: 0.5798 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1884 loss_train: 0.6285 acc_train: 0.8560 loss_val: 0.5795 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1885 loss_train: 0.5824 acc_train: 0.8643 loss_val: 0.5792 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1886 loss_train: 0.6050 acc_train: 0.8550 loss_val: 0.5789 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1887 loss_train: 0.6108 acc_train: 0.8610 loss_val: 0.5786 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1888 loss_train: 0.6001 acc_train: 0.8583 loss_val: 0.5783 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1889 loss_train: 0.5890 acc_train: 0.8633 loss_val: 0.5779 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1890 loss_train: 0.6044 acc_train: 0.8652 loss_val: 0.5776 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1891 loss_train: 0.5680 acc_train: 0.8643 loss_val: 0.5773 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1892 loss_train: 0.5900 acc_train: 0.8610 loss_val: 0.5770 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1893 loss_train: 0.5850 acc_train: 0.8666 loss_val: 0.5768 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 1894 loss_train: 0.5787 acc_train: 0.8749 loss_val: 0.5766 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1895 loss_train: 0.5933 acc_train: 0.8666 loss_val: 0.5765 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1896 loss_train: 0.5936 acc_train: 0.8550 loss_val: 0.5765 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1897 loss_train: 0.5812 acc_train: 0.8707 loss_val: 0.5764 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1898 loss_train: 0.5865 acc_train: 0.8587 loss_val: 0.5764 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1899 loss_train: 0.5749 acc_train: 0.8601 loss_val: 0.5764 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 1900 loss_train: 0.5816 acc_train: 0.8587 loss_val: 0.5763 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 1901 loss_train: 0.5886 acc_train: 0.8629 loss_val: 0.5763 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1902 loss_train: 0.5835 acc_train: 0.8661 loss_val: 0.5763 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 1903 loss_train: 0.5854 acc_train: 0.8684 loss_val: 0.5762 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1904 loss_train: 0.5806 acc_train: 0.8657 loss_val: 0.5760 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1905 loss_train: 0.5883 acc_train: 0.8638 loss_val: 0.5758 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 1906 loss_train: 0.5763 acc_train: 0.8657 loss_val: 0.5757 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1907 loss_train: 0.6016 acc_train: 0.8592 loss_val: 0.5755 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1908 loss_train: 0.5924 acc_train: 0.8647 loss_val: 0.5753 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1909 loss_train: 0.5848 acc_train: 0.8610 loss_val: 0.5749 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1910 loss_train: 0.5963 acc_train: 0.8601 loss_val: 0.5746 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1911 loss_train: 0.5908 acc_train: 0.8578 loss_val: 0.5742 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1912 loss_train: 0.5932 acc_train: 0.8596 loss_val: 0.5739 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1913 loss_train: 0.6079 acc_train: 0.8546 loss_val: 0.5736 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1914 loss_train: 0.5854 acc_train: 0.8578 loss_val: 0.5734 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1915 loss_train: 0.5701 acc_train: 0.8712 loss_val: 0.5733 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1916 loss_train: 0.5701 acc_train: 0.8726 loss_val: 0.5732 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1917 loss_train: 0.5926 acc_train: 0.8657 loss_val: 0.5731 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1918 loss_train: 0.5873 acc_train: 0.8740 loss_val: 0.5730 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1919 loss_train: 0.5807 acc_train: 0.8661 loss_val: 0.5729 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1920 loss_train: 0.5868 acc_train: 0.8680 loss_val: 0.5728 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1921 loss_train: 0.5941 acc_train: 0.8615 loss_val: 0.5727 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1922 loss_train: 0.5859 acc_train: 0.8684 loss_val: 0.5727 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1923 loss_train: 0.5703 acc_train: 0.8670 loss_val: 0.5726 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 1924 loss_train: 0.5974 acc_train: 0.8592 loss_val: 0.5726 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1925 loss_train: 0.6191 acc_train: 0.8592 loss_val: 0.5726 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 1926 loss_train: 0.6085 acc_train: 0.8555 loss_val: 0.5725 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1927 loss_train: 0.5687 acc_train: 0.8800 loss_val: 0.5724 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 1928 loss_train: 0.5954 acc_train: 0.8578 loss_val: 0.5723 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1929 loss_train: 0.5885 acc_train: 0.8596 loss_val: 0.5721 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1930 loss_train: 0.5912 acc_train: 0.8532 loss_val: 0.5719 acc_val: 0.8930 time: 0.0069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1931 loss_train: 0.5837 acc_train: 0.8661 loss_val: 0.5717 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 1932 loss_train: 0.5808 acc_train: 0.8624 loss_val: 0.5716 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 1933 loss_train: 0.5851 acc_train: 0.8615 loss_val: 0.5713 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1934 loss_train: 0.5612 acc_train: 0.8730 loss_val: 0.5711 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1935 loss_train: 0.6076 acc_train: 0.8624 loss_val: 0.5709 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 1936 loss_train: 0.5973 acc_train: 0.8601 loss_val: 0.5707 acc_val: 0.8967 time: 0.0075s\n",
      "Epoch: 1937 loss_train: 0.5582 acc_train: 0.8740 loss_val: 0.5705 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 1938 loss_train: 0.5819 acc_train: 0.8684 loss_val: 0.5702 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 1939 loss_train: 0.5976 acc_train: 0.8587 loss_val: 0.5699 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 1940 loss_train: 0.5866 acc_train: 0.8633 loss_val: 0.5697 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 1941 loss_train: 0.5747 acc_train: 0.8661 loss_val: 0.5693 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 1942 loss_train: 0.5857 acc_train: 0.8638 loss_val: 0.5691 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 1943 loss_train: 0.5893 acc_train: 0.8610 loss_val: 0.5688 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 1944 loss_train: 0.6000 acc_train: 0.8513 loss_val: 0.5685 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 1945 loss_train: 0.6029 acc_train: 0.8587 loss_val: 0.5682 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 1946 loss_train: 0.5732 acc_train: 0.8601 loss_val: 0.5680 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 1947 loss_train: 0.5864 acc_train: 0.8657 loss_val: 0.5678 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 1948 loss_train: 0.5766 acc_train: 0.8638 loss_val: 0.5676 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 1949 loss_train: 0.5806 acc_train: 0.8615 loss_val: 0.5674 acc_val: 0.8967 time: 0.0078s\n",
      "Epoch: 1950 loss_train: 0.5669 acc_train: 0.8763 loss_val: 0.5670 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1951 loss_train: 0.5722 acc_train: 0.8657 loss_val: 0.5667 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 1952 loss_train: 0.5716 acc_train: 0.8643 loss_val: 0.5664 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1953 loss_train: 0.5714 acc_train: 0.8735 loss_val: 0.5662 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1954 loss_train: 0.5837 acc_train: 0.8670 loss_val: 0.5660 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1955 loss_train: 0.5819 acc_train: 0.8629 loss_val: 0.5657 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 1956 loss_train: 0.5749 acc_train: 0.8661 loss_val: 0.5656 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1957 loss_train: 0.5744 acc_train: 0.8573 loss_val: 0.5656 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1958 loss_train: 0.5847 acc_train: 0.8633 loss_val: 0.5657 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1959 loss_train: 0.5924 acc_train: 0.8583 loss_val: 0.5656 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1960 loss_train: 0.5624 acc_train: 0.8610 loss_val: 0.5655 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 1961 loss_train: 0.5739 acc_train: 0.8647 loss_val: 0.5654 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 1962 loss_train: 0.5904 acc_train: 0.8536 loss_val: 0.5653 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1963 loss_train: 0.5840 acc_train: 0.8610 loss_val: 0.5652 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 1964 loss_train: 0.5756 acc_train: 0.8564 loss_val: 0.5651 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 1965 loss_train: 0.5737 acc_train: 0.8578 loss_val: 0.5650 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 1966 loss_train: 0.5809 acc_train: 0.8661 loss_val: 0.5647 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1967 loss_train: 0.5728 acc_train: 0.8675 loss_val: 0.5645 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 1968 loss_train: 0.5949 acc_train: 0.8638 loss_val: 0.5643 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 1969 loss_train: 0.5930 acc_train: 0.8633 loss_val: 0.5642 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 1970 loss_train: 0.5687 acc_train: 0.8693 loss_val: 0.5640 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 1971 loss_train: 0.5768 acc_train: 0.8592 loss_val: 0.5638 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1972 loss_train: 0.5532 acc_train: 0.8698 loss_val: 0.5636 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 1973 loss_train: 0.5648 acc_train: 0.8758 loss_val: 0.5634 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 1974 loss_train: 0.5924 acc_train: 0.8583 loss_val: 0.5633 acc_val: 0.8967 time: 0.0066s\n",
      "Epoch: 1975 loss_train: 0.5673 acc_train: 0.8661 loss_val: 0.5631 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1976 loss_train: 0.5752 acc_train: 0.8758 loss_val: 0.5630 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1977 loss_train: 0.5621 acc_train: 0.8721 loss_val: 0.5629 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 1978 loss_train: 0.5765 acc_train: 0.8680 loss_val: 0.5627 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1979 loss_train: 0.5731 acc_train: 0.8610 loss_val: 0.5625 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 1980 loss_train: 0.5869 acc_train: 0.8620 loss_val: 0.5623 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1981 loss_train: 0.5788 acc_train: 0.8629 loss_val: 0.5619 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 1982 loss_train: 0.5512 acc_train: 0.8717 loss_val: 0.5616 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 1983 loss_train: 0.5723 acc_train: 0.8643 loss_val: 0.5613 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 1984 loss_train: 0.5731 acc_train: 0.8684 loss_val: 0.5610 acc_val: 0.8967 time: 0.0075s\n",
      "Epoch: 1985 loss_train: 0.5708 acc_train: 0.8693 loss_val: 0.5608 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 1986 loss_train: 0.5630 acc_train: 0.8675 loss_val: 0.5606 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1987 loss_train: 0.5791 acc_train: 0.8726 loss_val: 0.5605 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 1988 loss_train: 0.5647 acc_train: 0.8684 loss_val: 0.5603 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 1989 loss_train: 0.5632 acc_train: 0.8629 loss_val: 0.5602 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1990 loss_train: 0.5823 acc_train: 0.8675 loss_val: 0.5601 acc_val: 0.9004 time: 0.0071s\n",
      "Epoch: 1991 loss_train: 0.5641 acc_train: 0.8703 loss_val: 0.5599 acc_val: 0.9004 time: 0.0072s\n",
      "Epoch: 1992 loss_train: 0.5630 acc_train: 0.8730 loss_val: 0.5598 acc_val: 0.9004 time: 0.0070s\n",
      "Epoch: 1993 loss_train: 0.5700 acc_train: 0.8652 loss_val: 0.5597 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1994 loss_train: 0.5612 acc_train: 0.8620 loss_val: 0.5594 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1995 loss_train: 0.5714 acc_train: 0.8615 loss_val: 0.5592 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 1996 loss_train: 0.5824 acc_train: 0.8624 loss_val: 0.5591 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 1997 loss_train: 0.5734 acc_train: 0.8657 loss_val: 0.5590 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 1998 loss_train: 0.5643 acc_train: 0.8675 loss_val: 0.5589 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 1999 loss_train: 0.5663 acc_train: 0.8740 loss_val: 0.5589 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2000 loss_train: 0.5749 acc_train: 0.8606 loss_val: 0.5588 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2001 loss_train: 0.5787 acc_train: 0.8615 loss_val: 0.5587 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2002 loss_train: 0.5627 acc_train: 0.8652 loss_val: 0.5585 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2003 loss_train: 0.5549 acc_train: 0.8703 loss_val: 0.5584 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2004 loss_train: 0.5808 acc_train: 0.8647 loss_val: 0.5583 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2005 loss_train: 0.5707 acc_train: 0.8647 loss_val: 0.5583 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2006 loss_train: 0.5807 acc_train: 0.8573 loss_val: 0.5583 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2007 loss_train: 0.5651 acc_train: 0.8587 loss_val: 0.5582 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2008 loss_train: 0.5782 acc_train: 0.8596 loss_val: 0.5581 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2009 loss_train: 0.5699 acc_train: 0.8693 loss_val: 0.5580 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2010 loss_train: 0.5570 acc_train: 0.8661 loss_val: 0.5578 acc_val: 0.9004 time: 0.0066s\n",
      "Epoch: 2011 loss_train: 0.5753 acc_train: 0.8624 loss_val: 0.5576 acc_val: 0.9004 time: 0.0072s\n",
      "Epoch: 2012 loss_train: 0.5846 acc_train: 0.8647 loss_val: 0.5574 acc_val: 0.9004 time: 0.0075s\n",
      "Epoch: 2013 loss_train: 0.5617 acc_train: 0.8730 loss_val: 0.5571 acc_val: 0.9004 time: 0.0066s\n",
      "Epoch: 2014 loss_train: 0.5685 acc_train: 0.8573 loss_val: 0.5569 acc_val: 0.9004 time: 0.0069s\n",
      "Epoch: 2015 loss_train: 0.5567 acc_train: 0.8684 loss_val: 0.5566 acc_val: 0.9004 time: 0.0072s\n",
      "Epoch: 2016 loss_train: 0.5822 acc_train: 0.8620 loss_val: 0.5564 acc_val: 0.9004 time: 0.0070s\n",
      "Epoch: 2017 loss_train: 0.5446 acc_train: 0.8767 loss_val: 0.5561 acc_val: 0.9004 time: 0.0069s\n",
      "Epoch: 2018 loss_train: 0.5690 acc_train: 0.8620 loss_val: 0.5560 acc_val: 0.9004 time: 0.0069s\n",
      "Epoch: 2019 loss_train: 0.5774 acc_train: 0.8615 loss_val: 0.5559 acc_val: 0.9004 time: 0.0069s\n",
      "Epoch: 2020 loss_train: 0.5729 acc_train: 0.8703 loss_val: 0.5558 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2021 loss_train: 0.5770 acc_train: 0.8569 loss_val: 0.5557 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2022 loss_train: 0.5768 acc_train: 0.8629 loss_val: 0.5557 acc_val: 0.8967 time: 0.0066s\n",
      "Epoch: 2023 loss_train: 0.5653 acc_train: 0.8624 loss_val: 0.5555 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2024 loss_train: 0.5809 acc_train: 0.8717 loss_val: 0.5553 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2025 loss_train: 0.5977 acc_train: 0.8610 loss_val: 0.5551 acc_val: 0.8967 time: 0.0066s\n",
      "Epoch: 2026 loss_train: 0.5695 acc_train: 0.8726 loss_val: 0.5550 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2027 loss_train: 0.5703 acc_train: 0.8684 loss_val: 0.5550 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2028 loss_train: 0.5679 acc_train: 0.8680 loss_val: 0.5550 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2029 loss_train: 0.5681 acc_train: 0.8730 loss_val: 0.5548 acc_val: 0.8967 time: 0.0068s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2030 loss_train: 0.5694 acc_train: 0.8698 loss_val: 0.5546 acc_val: 0.8967 time: 0.0075s\n",
      "Epoch: 2031 loss_train: 0.5755 acc_train: 0.8661 loss_val: 0.5545 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2032 loss_train: 0.5603 acc_train: 0.8749 loss_val: 0.5543 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2033 loss_train: 0.5581 acc_train: 0.8666 loss_val: 0.5540 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2034 loss_train: 0.5583 acc_train: 0.8698 loss_val: 0.5535 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 2035 loss_train: 0.5661 acc_train: 0.8675 loss_val: 0.5529 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2036 loss_train: 0.5532 acc_train: 0.8606 loss_val: 0.5525 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2037 loss_train: 0.5675 acc_train: 0.8629 loss_val: 0.5522 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2038 loss_train: 0.5614 acc_train: 0.8712 loss_val: 0.5519 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2039 loss_train: 0.5600 acc_train: 0.8620 loss_val: 0.5517 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2040 loss_train: 0.5523 acc_train: 0.8698 loss_val: 0.5514 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2041 loss_train: 0.5587 acc_train: 0.8675 loss_val: 0.5512 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2042 loss_train: 0.5747 acc_train: 0.8606 loss_val: 0.5510 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2043 loss_train: 0.5751 acc_train: 0.8684 loss_val: 0.5510 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2044 loss_train: 0.5656 acc_train: 0.8633 loss_val: 0.5510 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2045 loss_train: 0.5660 acc_train: 0.8666 loss_val: 0.5510 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2046 loss_train: 0.5668 acc_train: 0.8740 loss_val: 0.5512 acc_val: 0.8967 time: 0.0065s\n",
      "Epoch: 2047 loss_train: 0.5525 acc_train: 0.8717 loss_val: 0.5513 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2048 loss_train: 0.5576 acc_train: 0.8666 loss_val: 0.5514 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2049 loss_train: 0.5609 acc_train: 0.8703 loss_val: 0.5514 acc_val: 0.8967 time: 0.0066s\n",
      "Epoch: 2050 loss_train: 0.5576 acc_train: 0.8740 loss_val: 0.5512 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2051 loss_train: 0.5643 acc_train: 0.8707 loss_val: 0.5511 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2052 loss_train: 0.5573 acc_train: 0.8767 loss_val: 0.5510 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2053 loss_train: 0.5813 acc_train: 0.8629 loss_val: 0.5509 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2054 loss_train: 0.5772 acc_train: 0.8666 loss_val: 0.5507 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2055 loss_train: 0.5552 acc_train: 0.8638 loss_val: 0.5504 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2056 loss_train: 0.5455 acc_train: 0.8735 loss_val: 0.5501 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2057 loss_train: 0.5600 acc_train: 0.8610 loss_val: 0.5496 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2058 loss_train: 0.5536 acc_train: 0.8753 loss_val: 0.5490 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 2059 loss_train: 0.5584 acc_train: 0.8712 loss_val: 0.5486 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2060 loss_train: 0.5638 acc_train: 0.8712 loss_val: 0.5481 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2061 loss_train: 0.5467 acc_train: 0.8749 loss_val: 0.5477 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 2062 loss_train: 0.5698 acc_train: 0.8657 loss_val: 0.5474 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2063 loss_train: 0.5538 acc_train: 0.8680 loss_val: 0.5473 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2064 loss_train: 0.5538 acc_train: 0.8786 loss_val: 0.5471 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2065 loss_train: 0.5576 acc_train: 0.8657 loss_val: 0.5469 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2066 loss_train: 0.5573 acc_train: 0.8610 loss_val: 0.5467 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2067 loss_train: 0.5533 acc_train: 0.8726 loss_val: 0.5465 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2068 loss_train: 0.5651 acc_train: 0.8601 loss_val: 0.5463 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2069 loss_train: 0.5748 acc_train: 0.8601 loss_val: 0.5462 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2070 loss_train: 0.5653 acc_train: 0.8610 loss_val: 0.5461 acc_val: 0.8967 time: 0.0066s\n",
      "Epoch: 2071 loss_train: 0.5497 acc_train: 0.8666 loss_val: 0.5461 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2072 loss_train: 0.5573 acc_train: 0.8763 loss_val: 0.5461 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2073 loss_train: 0.5588 acc_train: 0.8730 loss_val: 0.5461 acc_val: 0.8967 time: 0.0066s\n",
      "Epoch: 2074 loss_train: 0.5562 acc_train: 0.8721 loss_val: 0.5460 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2075 loss_train: 0.5473 acc_train: 0.8707 loss_val: 0.5460 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2076 loss_train: 0.5582 acc_train: 0.8657 loss_val: 0.5460 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2077 loss_train: 0.5544 acc_train: 0.8657 loss_val: 0.5459 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2078 loss_train: 0.5362 acc_train: 0.8638 loss_val: 0.5458 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2079 loss_train: 0.5538 acc_train: 0.8657 loss_val: 0.5456 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2080 loss_train: 0.5534 acc_train: 0.8638 loss_val: 0.5455 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2081 loss_train: 0.5632 acc_train: 0.8666 loss_val: 0.5454 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2082 loss_train: 0.5596 acc_train: 0.8666 loss_val: 0.5452 acc_val: 0.9004 time: 0.0068s\n",
      "Epoch: 2083 loss_train: 0.5784 acc_train: 0.8661 loss_val: 0.5451 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2084 loss_train: 0.5587 acc_train: 0.8740 loss_val: 0.5451 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2085 loss_train: 0.5822 acc_train: 0.8583 loss_val: 0.5449 acc_val: 0.8967 time: 0.0066s\n",
      "Epoch: 2086 loss_train: 0.5423 acc_train: 0.8786 loss_val: 0.5447 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2087 loss_train: 0.5450 acc_train: 0.8633 loss_val: 0.5446 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2088 loss_train: 0.5633 acc_train: 0.8624 loss_val: 0.5444 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2089 loss_train: 0.5609 acc_train: 0.8592 loss_val: 0.5441 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2090 loss_train: 0.5539 acc_train: 0.8698 loss_val: 0.5440 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2091 loss_train: 0.5571 acc_train: 0.8693 loss_val: 0.5438 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2092 loss_train: 0.5642 acc_train: 0.8675 loss_val: 0.5435 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2093 loss_train: 0.5609 acc_train: 0.8661 loss_val: 0.5433 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2094 loss_train: 0.5651 acc_train: 0.8670 loss_val: 0.5431 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 2095 loss_train: 0.5426 acc_train: 0.8740 loss_val: 0.5430 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2096 loss_train: 0.5407 acc_train: 0.8740 loss_val: 0.5429 acc_val: 0.8967 time: 0.0074s\n",
      "Epoch: 2097 loss_train: 0.5512 acc_train: 0.8661 loss_val: 0.5428 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2098 loss_train: 0.5392 acc_train: 0.8786 loss_val: 0.5427 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2099 loss_train: 0.5371 acc_train: 0.8767 loss_val: 0.5425 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2100 loss_train: 0.5446 acc_train: 0.8823 loss_val: 0.5425 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2101 loss_train: 0.5524 acc_train: 0.8684 loss_val: 0.5426 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2102 loss_train: 0.5413 acc_train: 0.8666 loss_val: 0.5427 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2103 loss_train: 0.5604 acc_train: 0.8643 loss_val: 0.5428 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2104 loss_train: 0.5454 acc_train: 0.8781 loss_val: 0.5428 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2105 loss_train: 0.5521 acc_train: 0.8661 loss_val: 0.5428 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2106 loss_train: 0.5668 acc_train: 0.8698 loss_val: 0.5426 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2107 loss_train: 0.5564 acc_train: 0.8633 loss_val: 0.5423 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2108 loss_train: 0.5520 acc_train: 0.8675 loss_val: 0.5420 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2109 loss_train: 0.5503 acc_train: 0.8670 loss_val: 0.5417 acc_val: 0.8930 time: 0.0065s\n",
      "Epoch: 2110 loss_train: 0.5753 acc_train: 0.8592 loss_val: 0.5414 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2111 loss_train: 0.5453 acc_train: 0.8763 loss_val: 0.5411 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2112 loss_train: 0.5618 acc_train: 0.8703 loss_val: 0.5408 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2113 loss_train: 0.5421 acc_train: 0.8730 loss_val: 0.5405 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2114 loss_train: 0.5386 acc_train: 0.8735 loss_val: 0.5402 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2115 loss_train: 0.5297 acc_train: 0.8707 loss_val: 0.5400 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 2116 loss_train: 0.5519 acc_train: 0.8680 loss_val: 0.5397 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2117 loss_train: 0.5512 acc_train: 0.8717 loss_val: 0.5395 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2118 loss_train: 0.5601 acc_train: 0.8666 loss_val: 0.5393 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2119 loss_train: 0.5302 acc_train: 0.8726 loss_val: 0.5391 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2120 loss_train: 0.5506 acc_train: 0.8744 loss_val: 0.5389 acc_val: 0.8967 time: 0.0075s\n",
      "Epoch: 2121 loss_train: 0.5391 acc_train: 0.8749 loss_val: 0.5387 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 2122 loss_train: 0.5413 acc_train: 0.8712 loss_val: 0.5386 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2123 loss_train: 0.5376 acc_train: 0.8753 loss_val: 0.5385 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2124 loss_train: 0.5515 acc_train: 0.8661 loss_val: 0.5384 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2125 loss_train: 0.5640 acc_train: 0.8684 loss_val: 0.5384 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2126 loss_train: 0.5450 acc_train: 0.8707 loss_val: 0.5384 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2127 loss_train: 0.5395 acc_train: 0.8790 loss_val: 0.5385 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2128 loss_train: 0.5364 acc_train: 0.8823 loss_val: 0.5386 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2129 loss_train: 0.5554 acc_train: 0.8684 loss_val: 0.5387 acc_val: 0.8930 time: 0.0069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2130 loss_train: 0.5550 acc_train: 0.8633 loss_val: 0.5386 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2131 loss_train: 0.5505 acc_train: 0.8717 loss_val: 0.5385 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2132 loss_train: 0.5289 acc_train: 0.8740 loss_val: 0.5383 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2133 loss_train: 0.5491 acc_train: 0.8638 loss_val: 0.5380 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2134 loss_train: 0.5223 acc_train: 0.8735 loss_val: 0.5377 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2135 loss_train: 0.5463 acc_train: 0.8804 loss_val: 0.5374 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2136 loss_train: 0.5538 acc_train: 0.8730 loss_val: 0.5370 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2137 loss_train: 0.5275 acc_train: 0.8758 loss_val: 0.5368 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2138 loss_train: 0.5514 acc_train: 0.8726 loss_val: 0.5366 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2139 loss_train: 0.5469 acc_train: 0.8758 loss_val: 0.5363 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2140 loss_train: 0.5572 acc_train: 0.8675 loss_val: 0.5362 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2141 loss_train: 0.5377 acc_train: 0.8744 loss_val: 0.5360 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2142 loss_train: 0.5683 acc_train: 0.8661 loss_val: 0.5359 acc_val: 0.8967 time: 0.0067s\n",
      "Epoch: 2143 loss_train: 0.5414 acc_train: 0.8767 loss_val: 0.5359 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2144 loss_train: 0.5473 acc_train: 0.8726 loss_val: 0.5359 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2145 loss_train: 0.5453 acc_train: 0.8675 loss_val: 0.5359 acc_val: 0.8967 time: 0.0068s\n",
      "Epoch: 2146 loss_train: 0.5545 acc_train: 0.8684 loss_val: 0.5358 acc_val: 0.8967 time: 0.0069s\n",
      "Epoch: 2147 loss_train: 0.5561 acc_train: 0.8693 loss_val: 0.5358 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2148 loss_train: 0.5367 acc_train: 0.8758 loss_val: 0.5357 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2149 loss_train: 0.5368 acc_train: 0.8684 loss_val: 0.5357 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2150 loss_train: 0.5472 acc_train: 0.8781 loss_val: 0.5356 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2151 loss_train: 0.5574 acc_train: 0.8629 loss_val: 0.5355 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2152 loss_train: 0.5351 acc_train: 0.8693 loss_val: 0.5354 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2153 loss_train: 0.5342 acc_train: 0.8749 loss_val: 0.5354 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2154 loss_train: 0.5369 acc_train: 0.8744 loss_val: 0.5352 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2155 loss_train: 0.5452 acc_train: 0.8689 loss_val: 0.5351 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2156 loss_train: 0.5448 acc_train: 0.8620 loss_val: 0.5349 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2157 loss_train: 0.5489 acc_train: 0.8740 loss_val: 0.5348 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2158 loss_train: 0.5444 acc_train: 0.8693 loss_val: 0.5346 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2159 loss_train: 0.5418 acc_train: 0.8643 loss_val: 0.5343 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2160 loss_train: 0.5354 acc_train: 0.8744 loss_val: 0.5341 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2161 loss_train: 0.5541 acc_train: 0.8744 loss_val: 0.5338 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2162 loss_train: 0.5405 acc_train: 0.8730 loss_val: 0.5335 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2163 loss_train: 0.5439 acc_train: 0.8693 loss_val: 0.5334 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2164 loss_train: 0.5386 acc_train: 0.8726 loss_val: 0.5333 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2165 loss_train: 0.5485 acc_train: 0.8638 loss_val: 0.5332 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2166 loss_train: 0.5475 acc_train: 0.8684 loss_val: 0.5332 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2167 loss_train: 0.5360 acc_train: 0.8753 loss_val: 0.5331 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2168 loss_train: 0.5339 acc_train: 0.8661 loss_val: 0.5331 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2169 loss_train: 0.5552 acc_train: 0.8721 loss_val: 0.5331 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2170 loss_train: 0.5465 acc_train: 0.8684 loss_val: 0.5332 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2171 loss_train: 0.5405 acc_train: 0.8712 loss_val: 0.5331 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2172 loss_train: 0.5223 acc_train: 0.8735 loss_val: 0.5330 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2173 loss_train: 0.5390 acc_train: 0.8615 loss_val: 0.5329 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2174 loss_train: 0.5458 acc_train: 0.8753 loss_val: 0.5328 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2175 loss_train: 0.5316 acc_train: 0.8735 loss_val: 0.5325 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2176 loss_train: 0.5391 acc_train: 0.8777 loss_val: 0.5322 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2177 loss_train: 0.5312 acc_train: 0.8758 loss_val: 0.5319 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2178 loss_train: 0.5470 acc_train: 0.8670 loss_val: 0.5316 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2179 loss_train: 0.5463 acc_train: 0.8629 loss_val: 0.5314 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2180 loss_train: 0.5163 acc_train: 0.8813 loss_val: 0.5312 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2181 loss_train: 0.5417 acc_train: 0.8777 loss_val: 0.5311 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2182 loss_train: 0.5393 acc_train: 0.8744 loss_val: 0.5310 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2183 loss_train: 0.5414 acc_train: 0.8790 loss_val: 0.5309 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2184 loss_train: 0.5458 acc_train: 0.8758 loss_val: 0.5309 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2185 loss_train: 0.5279 acc_train: 0.8698 loss_val: 0.5309 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2186 loss_train: 0.5310 acc_train: 0.8666 loss_val: 0.5308 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2187 loss_train: 0.5503 acc_train: 0.8661 loss_val: 0.5309 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2188 loss_train: 0.5504 acc_train: 0.8744 loss_val: 0.5310 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2189 loss_train: 0.5661 acc_train: 0.8698 loss_val: 0.5310 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2190 loss_train: 0.5378 acc_train: 0.8712 loss_val: 0.5309 acc_val: 0.8930 time: 0.0065s\n",
      "Epoch: 2191 loss_train: 0.5352 acc_train: 0.8730 loss_val: 0.5309 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2192 loss_train: 0.5446 acc_train: 0.8717 loss_val: 0.5307 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2193 loss_train: 0.5238 acc_train: 0.8790 loss_val: 0.5305 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2194 loss_train: 0.5507 acc_train: 0.8698 loss_val: 0.5302 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2195 loss_train: 0.5341 acc_train: 0.8763 loss_val: 0.5299 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2196 loss_train: 0.5166 acc_train: 0.8735 loss_val: 0.5297 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2197 loss_train: 0.5396 acc_train: 0.8615 loss_val: 0.5294 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2198 loss_train: 0.5324 acc_train: 0.8675 loss_val: 0.5292 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2199 loss_train: 0.5490 acc_train: 0.8666 loss_val: 0.5290 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2200 loss_train: 0.5421 acc_train: 0.8698 loss_val: 0.5289 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2201 loss_train: 0.5426 acc_train: 0.8721 loss_val: 0.5289 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2202 loss_train: 0.5332 acc_train: 0.8693 loss_val: 0.5289 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2203 loss_train: 0.5435 acc_train: 0.8661 loss_val: 0.5289 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2204 loss_train: 0.5449 acc_train: 0.8753 loss_val: 0.5290 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2205 loss_train: 0.5341 acc_train: 0.8767 loss_val: 0.5290 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2206 loss_train: 0.5529 acc_train: 0.8726 loss_val: 0.5291 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2207 loss_train: 0.5480 acc_train: 0.8795 loss_val: 0.5290 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2208 loss_train: 0.5383 acc_train: 0.8735 loss_val: 0.5290 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2209 loss_train: 0.5199 acc_train: 0.8832 loss_val: 0.5289 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2210 loss_train: 0.5233 acc_train: 0.8758 loss_val: 0.5289 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2211 loss_train: 0.5414 acc_train: 0.8684 loss_val: 0.5289 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 2212 loss_train: 0.5269 acc_train: 0.8795 loss_val: 0.5288 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2213 loss_train: 0.5181 acc_train: 0.8809 loss_val: 0.5287 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2214 loss_train: 0.5238 acc_train: 0.8749 loss_val: 0.5285 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 2215 loss_train: 0.5476 acc_train: 0.8652 loss_val: 0.5285 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2216 loss_train: 0.5290 acc_train: 0.8753 loss_val: 0.5284 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2217 loss_train: 0.5306 acc_train: 0.8855 loss_val: 0.5283 acc_val: 0.8930 time: 0.0065s\n",
      "Epoch: 2218 loss_train: 0.5252 acc_train: 0.8753 loss_val: 0.5282 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2219 loss_train: 0.5392 acc_train: 0.8721 loss_val: 0.5280 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2220 loss_train: 0.5491 acc_train: 0.8657 loss_val: 0.5278 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2221 loss_train: 0.5296 acc_train: 0.8698 loss_val: 0.5276 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2222 loss_train: 0.5143 acc_train: 0.8878 loss_val: 0.5274 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2223 loss_train: 0.5322 acc_train: 0.8712 loss_val: 0.5271 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2224 loss_train: 0.5188 acc_train: 0.8827 loss_val: 0.5267 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2225 loss_train: 0.5427 acc_train: 0.8670 loss_val: 0.5263 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2226 loss_train: 0.5357 acc_train: 0.8749 loss_val: 0.5260 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2227 loss_train: 0.5324 acc_train: 0.8740 loss_val: 0.5257 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2228 loss_train: 0.5370 acc_train: 0.8726 loss_val: 0.5255 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2229 loss_train: 0.5377 acc_train: 0.8763 loss_val: 0.5255 acc_val: 0.8930 time: 0.0070s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2230 loss_train: 0.5407 acc_train: 0.8726 loss_val: 0.5254 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2231 loss_train: 0.5236 acc_train: 0.8753 loss_val: 0.5254 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2232 loss_train: 0.5280 acc_train: 0.8823 loss_val: 0.5254 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2233 loss_train: 0.5292 acc_train: 0.8790 loss_val: 0.5253 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2234 loss_train: 0.5193 acc_train: 0.8818 loss_val: 0.5253 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2235 loss_train: 0.5307 acc_train: 0.8680 loss_val: 0.5252 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2236 loss_train: 0.5397 acc_train: 0.8657 loss_val: 0.5252 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2237 loss_train: 0.5350 acc_train: 0.8684 loss_val: 0.5251 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2238 loss_train: 0.5497 acc_train: 0.8689 loss_val: 0.5251 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2239 loss_train: 0.5215 acc_train: 0.8758 loss_val: 0.5250 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2240 loss_train: 0.5156 acc_train: 0.8804 loss_val: 0.5249 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2241 loss_train: 0.5195 acc_train: 0.8693 loss_val: 0.5247 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2242 loss_train: 0.5399 acc_train: 0.8726 loss_val: 0.5245 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2243 loss_train: 0.5333 acc_train: 0.8661 loss_val: 0.5242 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2244 loss_train: 0.5290 acc_train: 0.8684 loss_val: 0.5239 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2245 loss_train: 0.5395 acc_train: 0.8717 loss_val: 0.5236 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2246 loss_train: 0.5162 acc_train: 0.8823 loss_val: 0.5232 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2247 loss_train: 0.5309 acc_train: 0.8693 loss_val: 0.5229 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2248 loss_train: 0.5390 acc_train: 0.8703 loss_val: 0.5226 acc_val: 0.8967 time: 0.0071s\n",
      "Epoch: 2249 loss_train: 0.5240 acc_train: 0.8790 loss_val: 0.5224 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2250 loss_train: 0.5184 acc_train: 0.8735 loss_val: 0.5223 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2251 loss_train: 0.5204 acc_train: 0.8772 loss_val: 0.5223 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2252 loss_train: 0.5409 acc_train: 0.8749 loss_val: 0.5223 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2253 loss_train: 0.5410 acc_train: 0.8717 loss_val: 0.5222 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2254 loss_train: 0.5307 acc_train: 0.8670 loss_val: 0.5221 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2255 loss_train: 0.5308 acc_train: 0.8712 loss_val: 0.5221 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2256 loss_train: 0.5276 acc_train: 0.8813 loss_val: 0.5220 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2257 loss_train: 0.5176 acc_train: 0.8740 loss_val: 0.5219 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2258 loss_train: 0.5381 acc_train: 0.8767 loss_val: 0.5218 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2259 loss_train: 0.5224 acc_train: 0.8786 loss_val: 0.5217 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2260 loss_train: 0.5244 acc_train: 0.8740 loss_val: 0.5216 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2261 loss_train: 0.5280 acc_train: 0.8777 loss_val: 0.5216 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2262 loss_train: 0.5386 acc_train: 0.8777 loss_val: 0.5216 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2263 loss_train: 0.5255 acc_train: 0.8721 loss_val: 0.5217 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2264 loss_train: 0.5254 acc_train: 0.8670 loss_val: 0.5217 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2265 loss_train: 0.5342 acc_train: 0.8758 loss_val: 0.5217 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2266 loss_train: 0.5467 acc_train: 0.8735 loss_val: 0.5217 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2267 loss_train: 0.5341 acc_train: 0.8790 loss_val: 0.5217 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2268 loss_train: 0.5384 acc_train: 0.8633 loss_val: 0.5215 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2269 loss_train: 0.5392 acc_train: 0.8730 loss_val: 0.5213 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2270 loss_train: 0.5096 acc_train: 0.8717 loss_val: 0.5213 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2271 loss_train: 0.5193 acc_train: 0.8735 loss_val: 0.5212 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2272 loss_train: 0.5206 acc_train: 0.8744 loss_val: 0.5211 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2273 loss_train: 0.5161 acc_train: 0.8800 loss_val: 0.5211 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2274 loss_train: 0.5285 acc_train: 0.8707 loss_val: 0.5209 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2275 loss_train: 0.5267 acc_train: 0.8721 loss_val: 0.5206 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2276 loss_train: 0.5243 acc_train: 0.8675 loss_val: 0.5204 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2277 loss_train: 0.5280 acc_train: 0.8790 loss_val: 0.5202 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2278 loss_train: 0.5249 acc_train: 0.8758 loss_val: 0.5200 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2279 loss_train: 0.5387 acc_train: 0.8698 loss_val: 0.5199 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2280 loss_train: 0.5195 acc_train: 0.8744 loss_val: 0.5198 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2281 loss_train: 0.5421 acc_train: 0.8707 loss_val: 0.5196 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2282 loss_train: 0.5206 acc_train: 0.8809 loss_val: 0.5194 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2283 loss_train: 0.5250 acc_train: 0.8790 loss_val: 0.5191 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2284 loss_train: 0.5286 acc_train: 0.8744 loss_val: 0.5190 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2285 loss_train: 0.5256 acc_train: 0.8740 loss_val: 0.5188 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2286 loss_train: 0.5247 acc_train: 0.8730 loss_val: 0.5186 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2287 loss_train: 0.5256 acc_train: 0.8698 loss_val: 0.5185 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2288 loss_train: 0.5217 acc_train: 0.8767 loss_val: 0.5185 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2289 loss_train: 0.5229 acc_train: 0.8763 loss_val: 0.5184 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2290 loss_train: 0.5209 acc_train: 0.8758 loss_val: 0.5184 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2291 loss_train: 0.5220 acc_train: 0.8790 loss_val: 0.5184 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2292 loss_train: 0.5304 acc_train: 0.8721 loss_val: 0.5183 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2293 loss_train: 0.5427 acc_train: 0.8684 loss_val: 0.5182 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2294 loss_train: 0.5209 acc_train: 0.8813 loss_val: 0.5182 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2295 loss_train: 0.5278 acc_train: 0.8735 loss_val: 0.5182 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2296 loss_train: 0.5215 acc_train: 0.8740 loss_val: 0.5181 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2297 loss_train: 0.5180 acc_train: 0.8795 loss_val: 0.5179 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2298 loss_train: 0.5224 acc_train: 0.8800 loss_val: 0.5177 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2299 loss_train: 0.5417 acc_train: 0.8763 loss_val: 0.5176 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2300 loss_train: 0.5400 acc_train: 0.8712 loss_val: 0.5174 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2301 loss_train: 0.5332 acc_train: 0.8744 loss_val: 0.5172 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2302 loss_train: 0.5197 acc_train: 0.8790 loss_val: 0.5171 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2303 loss_train: 0.5363 acc_train: 0.8749 loss_val: 0.5169 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2304 loss_train: 0.5249 acc_train: 0.8777 loss_val: 0.5167 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2305 loss_train: 0.5257 acc_train: 0.8790 loss_val: 0.5165 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2306 loss_train: 0.5302 acc_train: 0.8763 loss_val: 0.5165 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2307 loss_train: 0.5198 acc_train: 0.8800 loss_val: 0.5165 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2308 loss_train: 0.5241 acc_train: 0.8693 loss_val: 0.5166 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2309 loss_train: 0.5141 acc_train: 0.8800 loss_val: 0.5168 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2310 loss_train: 0.5300 acc_train: 0.8786 loss_val: 0.5169 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2311 loss_train: 0.5229 acc_train: 0.8721 loss_val: 0.5169 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2312 loss_train: 0.5382 acc_train: 0.8717 loss_val: 0.5170 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2313 loss_train: 0.5287 acc_train: 0.8767 loss_val: 0.5169 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2314 loss_train: 0.5215 acc_train: 0.8675 loss_val: 0.5166 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2315 loss_train: 0.5189 acc_train: 0.8712 loss_val: 0.5163 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2316 loss_train: 0.5248 acc_train: 0.8781 loss_val: 0.5160 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2317 loss_train: 0.5309 acc_train: 0.8786 loss_val: 0.5156 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2318 loss_train: 0.5324 acc_train: 0.8740 loss_val: 0.5151 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2319 loss_train: 0.5285 acc_train: 0.8703 loss_val: 0.5147 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2320 loss_train: 0.5254 acc_train: 0.8721 loss_val: 0.5143 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2321 loss_train: 0.5173 acc_train: 0.8740 loss_val: 0.5139 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2322 loss_train: 0.5149 acc_train: 0.8726 loss_val: 0.5136 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2323 loss_train: 0.5171 acc_train: 0.8772 loss_val: 0.5135 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2324 loss_train: 0.5214 acc_train: 0.8809 loss_val: 0.5134 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2325 loss_train: 0.5167 acc_train: 0.8730 loss_val: 0.5134 acc_val: 0.8967 time: 0.0070s\n",
      "Epoch: 2326 loss_train: 0.5227 acc_train: 0.8670 loss_val: 0.5135 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2327 loss_train: 0.5188 acc_train: 0.8767 loss_val: 0.5135 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2328 loss_train: 0.5192 acc_train: 0.8837 loss_val: 0.5136 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2329 loss_train: 0.5418 acc_train: 0.8689 loss_val: 0.5137 acc_val: 0.8930 time: 0.0073s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2330 loss_train: 0.5293 acc_train: 0.8726 loss_val: 0.5137 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2331 loss_train: 0.5151 acc_train: 0.8740 loss_val: 0.5138 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2332 loss_train: 0.5237 acc_train: 0.8744 loss_val: 0.5137 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2333 loss_train: 0.5059 acc_train: 0.8790 loss_val: 0.5137 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2334 loss_train: 0.5241 acc_train: 0.8749 loss_val: 0.5137 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2335 loss_train: 0.5344 acc_train: 0.8804 loss_val: 0.5135 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2336 loss_train: 0.5210 acc_train: 0.8800 loss_val: 0.5134 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2337 loss_train: 0.5162 acc_train: 0.8740 loss_val: 0.5131 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2338 loss_train: 0.5206 acc_train: 0.8735 loss_val: 0.5127 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2339 loss_train: 0.5179 acc_train: 0.8749 loss_val: 0.5125 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2340 loss_train: 0.5039 acc_train: 0.8800 loss_val: 0.5122 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2341 loss_train: 0.5146 acc_train: 0.8837 loss_val: 0.5120 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2342 loss_train: 0.5395 acc_train: 0.8712 loss_val: 0.5120 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2343 loss_train: 0.5204 acc_train: 0.8795 loss_val: 0.5119 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2344 loss_train: 0.5196 acc_train: 0.8795 loss_val: 0.5119 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2345 loss_train: 0.5296 acc_train: 0.8707 loss_val: 0.5119 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2346 loss_train: 0.4984 acc_train: 0.8800 loss_val: 0.5119 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2347 loss_train: 0.5245 acc_train: 0.8823 loss_val: 0.5120 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2348 loss_train: 0.5152 acc_train: 0.8763 loss_val: 0.5123 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2349 loss_train: 0.5403 acc_train: 0.8670 loss_val: 0.5125 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2350 loss_train: 0.5214 acc_train: 0.8753 loss_val: 0.5126 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2351 loss_train: 0.5230 acc_train: 0.8680 loss_val: 0.5127 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2352 loss_train: 0.5390 acc_train: 0.8804 loss_val: 0.5129 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2353 loss_train: 0.5166 acc_train: 0.8758 loss_val: 0.5129 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2354 loss_train: 0.5205 acc_train: 0.8772 loss_val: 0.5129 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2355 loss_train: 0.5249 acc_train: 0.8827 loss_val: 0.5128 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2356 loss_train: 0.5184 acc_train: 0.8661 loss_val: 0.5126 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2357 loss_train: 0.5273 acc_train: 0.8703 loss_val: 0.5125 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2358 loss_train: 0.5161 acc_train: 0.8790 loss_val: 0.5123 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2359 loss_train: 0.5129 acc_train: 0.8818 loss_val: 0.5121 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2360 loss_train: 0.5070 acc_train: 0.8841 loss_val: 0.5119 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2361 loss_train: 0.5106 acc_train: 0.8809 loss_val: 0.5117 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2362 loss_train: 0.5062 acc_train: 0.8813 loss_val: 0.5115 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2363 loss_train: 0.5218 acc_train: 0.8777 loss_val: 0.5113 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2364 loss_train: 0.5239 acc_train: 0.8730 loss_val: 0.5110 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2365 loss_train: 0.5275 acc_train: 0.8772 loss_val: 0.5107 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2366 loss_train: 0.5153 acc_train: 0.8827 loss_val: 0.5103 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2367 loss_train: 0.5169 acc_train: 0.8800 loss_val: 0.5101 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2368 loss_train: 0.5181 acc_train: 0.8827 loss_val: 0.5098 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2369 loss_train: 0.5219 acc_train: 0.8804 loss_val: 0.5097 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2370 loss_train: 0.5250 acc_train: 0.8726 loss_val: 0.5096 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2371 loss_train: 0.5136 acc_train: 0.8786 loss_val: 0.5095 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2372 loss_train: 0.5223 acc_train: 0.8809 loss_val: 0.5095 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2373 loss_train: 0.5309 acc_train: 0.8620 loss_val: 0.5095 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2374 loss_train: 0.5116 acc_train: 0.8809 loss_val: 0.5094 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2375 loss_train: 0.5073 acc_train: 0.8795 loss_val: 0.5093 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2376 loss_train: 0.5352 acc_train: 0.8666 loss_val: 0.5092 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2377 loss_train: 0.5162 acc_train: 0.8758 loss_val: 0.5091 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2378 loss_train: 0.5074 acc_train: 0.8818 loss_val: 0.5089 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2379 loss_train: 0.5037 acc_train: 0.8749 loss_val: 0.5088 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2380 loss_train: 0.5303 acc_train: 0.8749 loss_val: 0.5088 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2381 loss_train: 0.5129 acc_train: 0.8689 loss_val: 0.5087 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2382 loss_train: 0.5145 acc_train: 0.8813 loss_val: 0.5087 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2383 loss_train: 0.5086 acc_train: 0.8809 loss_val: 0.5088 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2384 loss_train: 0.4978 acc_train: 0.8832 loss_val: 0.5089 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2385 loss_train: 0.5217 acc_train: 0.8809 loss_val: 0.5090 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2386 loss_train: 0.5084 acc_train: 0.8675 loss_val: 0.5090 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2387 loss_train: 0.5263 acc_train: 0.8721 loss_val: 0.5091 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2388 loss_train: 0.5039 acc_train: 0.8740 loss_val: 0.5091 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2389 loss_train: 0.5116 acc_train: 0.8740 loss_val: 0.5090 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2390 loss_train: 0.5221 acc_train: 0.8763 loss_val: 0.5090 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2391 loss_train: 0.5175 acc_train: 0.8717 loss_val: 0.5090 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2392 loss_train: 0.5282 acc_train: 0.8740 loss_val: 0.5088 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2393 loss_train: 0.5264 acc_train: 0.8717 loss_val: 0.5087 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2394 loss_train: 0.5172 acc_train: 0.8698 loss_val: 0.5086 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2395 loss_train: 0.5153 acc_train: 0.8758 loss_val: 0.5085 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2396 loss_train: 0.5084 acc_train: 0.8795 loss_val: 0.5085 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2397 loss_train: 0.5169 acc_train: 0.8790 loss_val: 0.5085 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2398 loss_train: 0.5133 acc_train: 0.8813 loss_val: 0.5085 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2399 loss_train: 0.4920 acc_train: 0.8823 loss_val: 0.5084 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2400 loss_train: 0.5029 acc_train: 0.8763 loss_val: 0.5084 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2401 loss_train: 0.5050 acc_train: 0.8832 loss_val: 0.5083 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2402 loss_train: 0.5277 acc_train: 0.8680 loss_val: 0.5083 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2403 loss_train: 0.5324 acc_train: 0.8721 loss_val: 0.5082 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 2404 loss_train: 0.5115 acc_train: 0.8790 loss_val: 0.5081 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 2405 loss_train: 0.5138 acc_train: 0.8832 loss_val: 0.5081 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 2406 loss_train: 0.5119 acc_train: 0.8763 loss_val: 0.5081 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2407 loss_train: 0.5074 acc_train: 0.8767 loss_val: 0.5080 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2408 loss_train: 0.5139 acc_train: 0.8790 loss_val: 0.5080 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2409 loss_train: 0.5191 acc_train: 0.8749 loss_val: 0.5080 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2410 loss_train: 0.5017 acc_train: 0.8763 loss_val: 0.5079 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2411 loss_train: 0.5163 acc_train: 0.8735 loss_val: 0.5079 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2412 loss_train: 0.5067 acc_train: 0.8790 loss_val: 0.5079 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2413 loss_train: 0.5246 acc_train: 0.8744 loss_val: 0.5078 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2414 loss_train: 0.5088 acc_train: 0.8721 loss_val: 0.5076 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2415 loss_train: 0.5008 acc_train: 0.8800 loss_val: 0.5075 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2416 loss_train: 0.5163 acc_train: 0.8698 loss_val: 0.5073 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2417 loss_train: 0.4978 acc_train: 0.8850 loss_val: 0.5071 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2418 loss_train: 0.4989 acc_train: 0.8850 loss_val: 0.5070 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2419 loss_train: 0.5054 acc_train: 0.8703 loss_val: 0.5068 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2420 loss_train: 0.5061 acc_train: 0.8818 loss_val: 0.5067 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2421 loss_train: 0.5114 acc_train: 0.8749 loss_val: 0.5066 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2422 loss_train: 0.5031 acc_train: 0.8781 loss_val: 0.5064 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2423 loss_train: 0.5145 acc_train: 0.8698 loss_val: 0.5063 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2424 loss_train: 0.5266 acc_train: 0.8744 loss_val: 0.5062 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2425 loss_train: 0.5207 acc_train: 0.8767 loss_val: 0.5062 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2426 loss_train: 0.5131 acc_train: 0.8818 loss_val: 0.5062 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2427 loss_train: 0.5043 acc_train: 0.8790 loss_val: 0.5062 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 2428 loss_train: 0.5033 acc_train: 0.8846 loss_val: 0.5063 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2429 loss_train: 0.5185 acc_train: 0.8827 loss_val: 0.5063 acc_val: 0.8893 time: 0.0071s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2430 loss_train: 0.4982 acc_train: 0.8855 loss_val: 0.5062 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2431 loss_train: 0.5253 acc_train: 0.8726 loss_val: 0.5061 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2432 loss_train: 0.4912 acc_train: 0.8920 loss_val: 0.5060 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2433 loss_train: 0.5079 acc_train: 0.8813 loss_val: 0.5058 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2434 loss_train: 0.5173 acc_train: 0.8744 loss_val: 0.5055 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2435 loss_train: 0.5140 acc_train: 0.8777 loss_val: 0.5052 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2436 loss_train: 0.5195 acc_train: 0.8647 loss_val: 0.5048 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2437 loss_train: 0.5234 acc_train: 0.8744 loss_val: 0.5044 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2438 loss_train: 0.5035 acc_train: 0.8837 loss_val: 0.5041 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2439 loss_train: 0.5079 acc_train: 0.8786 loss_val: 0.5038 acc_val: 0.8930 time: 0.0066s\n",
      "Epoch: 2440 loss_train: 0.5227 acc_train: 0.8795 loss_val: 0.5036 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2441 loss_train: 0.4945 acc_train: 0.8767 loss_val: 0.5034 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2442 loss_train: 0.5114 acc_train: 0.8786 loss_val: 0.5032 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2443 loss_train: 0.5402 acc_train: 0.8657 loss_val: 0.5031 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2444 loss_train: 0.5053 acc_train: 0.8855 loss_val: 0.5031 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2445 loss_train: 0.5203 acc_train: 0.8726 loss_val: 0.5031 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2446 loss_train: 0.4991 acc_train: 0.8873 loss_val: 0.5031 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2447 loss_train: 0.5028 acc_train: 0.8897 loss_val: 0.5032 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2448 loss_train: 0.5026 acc_train: 0.8800 loss_val: 0.5033 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2449 loss_train: 0.5083 acc_train: 0.8726 loss_val: 0.5034 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2450 loss_train: 0.5216 acc_train: 0.8781 loss_val: 0.5036 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2451 loss_train: 0.5013 acc_train: 0.8767 loss_val: 0.5037 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2452 loss_train: 0.5080 acc_train: 0.8763 loss_val: 0.5037 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2453 loss_train: 0.4915 acc_train: 0.8841 loss_val: 0.5037 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 2454 loss_train: 0.5095 acc_train: 0.8804 loss_val: 0.5036 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 2455 loss_train: 0.5023 acc_train: 0.8772 loss_val: 0.5035 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 2456 loss_train: 0.5085 acc_train: 0.8795 loss_val: 0.5034 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2457 loss_train: 0.5071 acc_train: 0.8781 loss_val: 0.5034 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2458 loss_train: 0.5161 acc_train: 0.8800 loss_val: 0.5033 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2459 loss_train: 0.5178 acc_train: 0.8703 loss_val: 0.5032 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2460 loss_train: 0.4958 acc_train: 0.8860 loss_val: 0.5031 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2461 loss_train: 0.5091 acc_train: 0.8809 loss_val: 0.5031 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2462 loss_train: 0.4998 acc_train: 0.8795 loss_val: 0.5030 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2463 loss_train: 0.5316 acc_train: 0.8620 loss_val: 0.5030 acc_val: 0.8930 time: 0.0068s\n",
      "Epoch: 2464 loss_train: 0.5062 acc_train: 0.8804 loss_val: 0.5030 acc_val: 0.8930 time: 0.0070s\n",
      "Epoch: 2465 loss_train: 0.4982 acc_train: 0.8717 loss_val: 0.5030 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2466 loss_train: 0.4992 acc_train: 0.8850 loss_val: 0.5030 acc_val: 0.8893 time: 0.0067s\n",
      "Epoch: 2467 loss_train: 0.5020 acc_train: 0.8786 loss_val: 0.5030 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2468 loss_train: 0.5145 acc_train: 0.8744 loss_val: 0.5029 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2469 loss_train: 0.4968 acc_train: 0.8730 loss_val: 0.5028 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 2470 loss_train: 0.4977 acc_train: 0.8804 loss_val: 0.5026 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 2471 loss_train: 0.5056 acc_train: 0.8795 loss_val: 0.5024 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2472 loss_train: 0.4994 acc_train: 0.8883 loss_val: 0.5024 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2473 loss_train: 0.4906 acc_train: 0.8795 loss_val: 0.5023 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2474 loss_train: 0.5096 acc_train: 0.8795 loss_val: 0.5023 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2475 loss_train: 0.4918 acc_train: 0.8818 loss_val: 0.5023 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2476 loss_train: 0.4986 acc_train: 0.8813 loss_val: 0.5024 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2477 loss_train: 0.5138 acc_train: 0.8749 loss_val: 0.5024 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2478 loss_train: 0.4925 acc_train: 0.8869 loss_val: 0.5025 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 2479 loss_train: 0.5113 acc_train: 0.8864 loss_val: 0.5024 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2480 loss_train: 0.4972 acc_train: 0.8730 loss_val: 0.5023 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 2481 loss_train: 0.4999 acc_train: 0.8809 loss_val: 0.5021 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2482 loss_train: 0.5167 acc_train: 0.8721 loss_val: 0.5020 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2483 loss_train: 0.5044 acc_train: 0.8818 loss_val: 0.5018 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2484 loss_train: 0.5076 acc_train: 0.8758 loss_val: 0.5015 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2485 loss_train: 0.4941 acc_train: 0.8837 loss_val: 0.5013 acc_val: 0.8893 time: 0.0070s\n",
      "Epoch: 2486 loss_train: 0.5013 acc_train: 0.8795 loss_val: 0.5012 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2487 loss_train: 0.5115 acc_train: 0.8758 loss_val: 0.5012 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2488 loss_train: 0.4895 acc_train: 0.8846 loss_val: 0.5012 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2489 loss_train: 0.5071 acc_train: 0.8804 loss_val: 0.5012 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2490 loss_train: 0.5010 acc_train: 0.8800 loss_val: 0.5012 acc_val: 0.8893 time: 0.0066s\n",
      "Epoch: 2491 loss_train: 0.5101 acc_train: 0.8753 loss_val: 0.5012 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2492 loss_train: 0.5232 acc_train: 0.8781 loss_val: 0.5012 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2493 loss_train: 0.5157 acc_train: 0.8726 loss_val: 0.5011 acc_val: 0.8930 time: 0.0067s\n",
      "Epoch: 2494 loss_train: 0.5209 acc_train: 0.8800 loss_val: 0.5010 acc_val: 0.8930 time: 0.0069s\n",
      "Epoch: 2495 loss_train: 0.5089 acc_train: 0.8777 loss_val: 0.5009 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2496 loss_train: 0.5136 acc_train: 0.8758 loss_val: 0.5008 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2497 loss_train: 0.5106 acc_train: 0.8800 loss_val: 0.5007 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2498 loss_train: 0.5190 acc_train: 0.8809 loss_val: 0.5007 acc_val: 0.8893 time: 0.0069s\n",
      "Epoch: 2499 loss_train: 0.4960 acc_train: 0.8781 loss_val: 0.5006 acc_val: 0.8893 time: 0.0068s\n",
      "Epoch: 2500 loss_train: 0.5086 acc_train: 0.8735 loss_val: 0.5005 acc_val: 0.8893 time: 0.0072s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.3272s\n",
      "Test set results: loss= 0.5847 accuracy= 0.8598\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t_total = time.time()\n",
    "acc_trains, acc_vals, loss_trains, loss_vals = [], [], [], []\n",
    "for epoch in range(epochs):\n",
    "    loss_train, loss_val, acc_train, acc_val = train(epoch)\n",
    "    acc_trains.append(acc_train)\n",
    "    acc_vals.append(acc_val)\n",
    "    loss_trains.append(loss_train)\n",
    "    loss_vals.append(loss_val)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "# Testing\n",
    "acc_test = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c6c8f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCN</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.859779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Training Accuracy %  Testing Accuracy %\n",
       "0   GCN               0.8735            0.859779"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model_adj = pd.DataFrame(data=[[\"GCN\", acc_trains[-1], acc_test]],columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "# compare_models = compare_models.append(compare_model_3,ignore_index=True)\n",
    "compare_model_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "85cd85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_model_adj.to_csv('./compare_model_adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "48c8c670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Training Process')\n",
    "plt.plot(range(len(loss_trains)), loss_trains, color='r')\n",
    "# plt.plot(range(len(loss_trains)), loss_trains, color='r')\n",
    "plt.ylabel('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig('training_loss.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bd7bcef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0., len(loss_trains), 1)\n",
    "y1 = loss_trains\n",
    "y2 = acc_trains\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x, y1, 'b', label='Loss')\n",
    "ax1.set_ylabel('Training Loss')\n",
    "ax1.set_title(\"Train Process\")\n",
    "\n",
    "ax2 = ax1.twinx()  # this is the important function\n",
    "ax2.plot(x, y2, 'r', label='Accuracy')\n",
    "ax2.set_xlim([0, len(loss_trains)])\n",
    "ax2.set_ylabel('Training Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax1.legend(loc='lower right')\n",
    "ax2.legend(loc='lower left')\n",
    "plt.savefig('Training Process.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cb8bc5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0., len(loss_vals), 1)\n",
    "y1 = loss_vals\n",
    "y2 = acc_vals\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x, y1, 'b', label='Loss')\n",
    "ax1.set_ylabel('Validation Loss')\n",
    "ax1.set_title(\"Validations\")\n",
    "\n",
    "ax2 = ax1.twinx()  # this is the important function\n",
    "ax2.plot(x, y2, 'r', label='Accuracy')\n",
    "ax2.set_xlim([0, len(loss_trains)])\n",
    "ax2.set_ylabel('Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax1.legend(loc='lower right')\n",
    "ax2.legend(loc='lower left')\n",
    "plt.savefig('Validations.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f5e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ida",
   "language": "python",
   "name": "ida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
