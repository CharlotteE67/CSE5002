{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584393ad",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8950ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from gcn.models import GCN\n",
    "from gcn.utils import load_data, accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fff4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6f03980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "adj, features, labels, idx_train, idx_val, idx_test, idx, idx_map = load_data(split=[0.8, 0.1, 0.1], path=\"./cora/\")\n",
    "# split dataset into train, validation and test for 8:1:1\n",
    "\n",
    "if use_cuda:\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c91bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if not fastmode:\n",
    "        # Evaluate validation set performance separately,\n",
    "        # deactivates dropout during validation run.\n",
    "        model.eval()\n",
    "        output = model(features, adj)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_train.item(), loss_val.item(), acc_train.item(), acc_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df536dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    return acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "146f1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "lr = 1e-3  # Initial learning rate.\n",
    "weight_decay = 5e-4  # Weight decay (L2 loss on parameters).\n",
    "hidden = 16  # Number of hidden units.\n",
    "dropout = 0.5 # Dropout rate (1 - keep probability).\n",
    "epochs = 2500  # Number of epochs to train.\n",
    "fastmode = False # Validate during training pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c447e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2880f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 1.9224 acc_train: 0.2424 loss_val: 1.9336 acc_val: 0.2694 time: 0.0092s\n",
      "Epoch: 0002 loss_train: 1.9227 acc_train: 0.2622 loss_val: 1.9323 acc_val: 0.2768 time: 0.0069s\n",
      "Epoch: 0003 loss_train: 1.9205 acc_train: 0.2682 loss_val: 1.9310 acc_val: 0.2804 time: 0.0073s\n",
      "Epoch: 0004 loss_train: 1.9211 acc_train: 0.2692 loss_val: 1.9298 acc_val: 0.2768 time: 0.0071s\n",
      "Epoch: 0005 loss_train: 1.9184 acc_train: 0.2886 loss_val: 1.9285 acc_val: 0.2841 time: 0.0073s\n",
      "Epoch: 0006 loss_train: 1.9176 acc_train: 0.2881 loss_val: 1.9273 acc_val: 0.2878 time: 0.0073s\n",
      "Epoch: 0007 loss_train: 1.9195 acc_train: 0.2881 loss_val: 1.9261 acc_val: 0.2878 time: 0.0076s\n",
      "Epoch: 0008 loss_train: 1.9162 acc_train: 0.2927 loss_val: 1.9249 acc_val: 0.2878 time: 0.0071s\n",
      "Epoch: 0009 loss_train: 1.9150 acc_train: 0.2959 loss_val: 1.9238 acc_val: 0.2878 time: 0.0071s\n",
      "Epoch: 0010 loss_train: 1.9141 acc_train: 0.2987 loss_val: 1.9226 acc_val: 0.2952 time: 0.0070s\n",
      "Epoch: 0011 loss_train: 1.9109 acc_train: 0.3001 loss_val: 1.9214 acc_val: 0.2952 time: 0.0088s\n",
      "Epoch: 0012 loss_train: 1.9132 acc_train: 0.3001 loss_val: 1.9203 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0013 loss_train: 1.9117 acc_train: 0.2996 loss_val: 1.9192 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0014 loss_train: 1.9089 acc_train: 0.3001 loss_val: 1.9180 acc_val: 0.2952 time: 0.0074s\n",
      "Epoch: 0015 loss_train: 1.9053 acc_train: 0.3015 loss_val: 1.9170 acc_val: 0.2952 time: 0.0074s\n",
      "Epoch: 0016 loss_train: 1.9062 acc_train: 0.3019 loss_val: 1.9159 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0017 loss_train: 1.9047 acc_train: 0.3010 loss_val: 1.9148 acc_val: 0.2952 time: 0.0089s\n",
      "Epoch: 0018 loss_train: 1.9017 acc_train: 0.3015 loss_val: 1.9137 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0019 loss_train: 1.9049 acc_train: 0.3019 loss_val: 1.9127 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0020 loss_train: 1.9026 acc_train: 0.3010 loss_val: 1.9117 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0021 loss_train: 1.8978 acc_train: 0.3019 loss_val: 1.9106 acc_val: 0.2952 time: 0.0092s\n",
      "Epoch: 0022 loss_train: 1.9026 acc_train: 0.3019 loss_val: 1.9096 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0023 loss_train: 1.8978 acc_train: 0.3019 loss_val: 1.9086 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0024 loss_train: 1.8998 acc_train: 0.3019 loss_val: 1.9075 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0025 loss_train: 1.8990 acc_train: 0.3019 loss_val: 1.9065 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0026 loss_train: 1.8986 acc_train: 0.3019 loss_val: 1.9055 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0027 loss_train: 1.8973 acc_train: 0.3019 loss_val: 1.9044 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0028 loss_train: 1.8962 acc_train: 0.3019 loss_val: 1.9034 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0029 loss_train: 1.8919 acc_train: 0.3019 loss_val: 1.9024 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0030 loss_train: 1.8960 acc_train: 0.3019 loss_val: 1.9013 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0031 loss_train: 1.8905 acc_train: 0.3019 loss_val: 1.9003 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0032 loss_train: 1.8945 acc_train: 0.3019 loss_val: 1.8993 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0033 loss_train: 1.8922 acc_train: 0.3019 loss_val: 1.8983 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0034 loss_train: 1.8958 acc_train: 0.3019 loss_val: 1.8972 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0035 loss_train: 1.8896 acc_train: 0.3019 loss_val: 1.8962 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0036 loss_train: 1.8926 acc_train: 0.3019 loss_val: 1.8952 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0037 loss_train: 1.8902 acc_train: 0.3019 loss_val: 1.8941 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0038 loss_train: 1.8881 acc_train: 0.3019 loss_val: 1.8931 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0039 loss_train: 1.8867 acc_train: 0.3019 loss_val: 1.8921 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0040 loss_train: 1.8852 acc_train: 0.3019 loss_val: 1.8910 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0041 loss_train: 1.8900 acc_train: 0.3019 loss_val: 1.8900 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0042 loss_train: 1.8818 acc_train: 0.3019 loss_val: 1.8890 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0043 loss_train: 1.8791 acc_train: 0.3019 loss_val: 1.8879 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0044 loss_train: 1.8845 acc_train: 0.3019 loss_val: 1.8869 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0045 loss_train: 1.8782 acc_train: 0.3019 loss_val: 1.8859 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0046 loss_train: 1.8750 acc_train: 0.3019 loss_val: 1.8848 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0047 loss_train: 1.8797 acc_train: 0.3019 loss_val: 1.8838 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0048 loss_train: 1.8782 acc_train: 0.3019 loss_val: 1.8828 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0049 loss_train: 1.8791 acc_train: 0.3019 loss_val: 1.8817 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0050 loss_train: 1.8772 acc_train: 0.3019 loss_val: 1.8807 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0051 loss_train: 1.8799 acc_train: 0.3019 loss_val: 1.8797 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0052 loss_train: 1.8760 acc_train: 0.3019 loss_val: 1.8787 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0053 loss_train: 1.8716 acc_train: 0.3019 loss_val: 1.8777 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0054 loss_train: 1.8689 acc_train: 0.3019 loss_val: 1.8767 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0055 loss_train: 1.8716 acc_train: 0.3019 loss_val: 1.8757 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0056 loss_train: 1.8735 acc_train: 0.3019 loss_val: 1.8747 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0057 loss_train: 1.8710 acc_train: 0.3019 loss_val: 1.8737 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0058 loss_train: 1.8670 acc_train: 0.3019 loss_val: 1.8727 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0059 loss_train: 1.8699 acc_train: 0.3019 loss_val: 1.8717 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0060 loss_train: 1.8687 acc_train: 0.3019 loss_val: 1.8707 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0061 loss_train: 1.8652 acc_train: 0.3019 loss_val: 1.8697 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0062 loss_train: 1.8658 acc_train: 0.3019 loss_val: 1.8687 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0063 loss_train: 1.8640 acc_train: 0.3019 loss_val: 1.8677 acc_val: 0.2952 time: 0.0074s\n",
      "Epoch: 0064 loss_train: 1.8632 acc_train: 0.3019 loss_val: 1.8667 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0065 loss_train: 1.8706 acc_train: 0.3019 loss_val: 1.8657 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0066 loss_train: 1.8606 acc_train: 0.3019 loss_val: 1.8647 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0067 loss_train: 1.8616 acc_train: 0.3019 loss_val: 1.8637 acc_val: 0.2952 time: 0.0092s\n",
      "Epoch: 0068 loss_train: 1.8598 acc_train: 0.3019 loss_val: 1.8627 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0069 loss_train: 1.8618 acc_train: 0.3019 loss_val: 1.8618 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0070 loss_train: 1.8634 acc_train: 0.3019 loss_val: 1.8608 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0071 loss_train: 1.8608 acc_train: 0.3019 loss_val: 1.8598 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0072 loss_train: 1.8595 acc_train: 0.3019 loss_val: 1.8589 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0073 loss_train: 1.8578 acc_train: 0.3019 loss_val: 1.8579 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0074 loss_train: 1.8541 acc_train: 0.3019 loss_val: 1.8570 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0075 loss_train: 1.8537 acc_train: 0.3019 loss_val: 1.8560 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0076 loss_train: 1.8578 acc_train: 0.3019 loss_val: 1.8551 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0077 loss_train: 1.8557 acc_train: 0.3019 loss_val: 1.8541 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0078 loss_train: 1.8519 acc_train: 0.3019 loss_val: 1.8532 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0079 loss_train: 1.8451 acc_train: 0.3019 loss_val: 1.8522 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0080 loss_train: 1.8503 acc_train: 0.3019 loss_val: 1.8512 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0081 loss_train: 1.8482 acc_train: 0.3019 loss_val: 1.8503 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0082 loss_train: 1.8581 acc_train: 0.3019 loss_val: 1.8493 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0083 loss_train: 1.8523 acc_train: 0.3019 loss_val: 1.8483 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0084 loss_train: 1.8463 acc_train: 0.3019 loss_val: 1.8473 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0085 loss_train: 1.8507 acc_train: 0.3019 loss_val: 1.8464 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0086 loss_train: 1.8491 acc_train: 0.3019 loss_val: 1.8454 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0087 loss_train: 1.8446 acc_train: 0.3019 loss_val: 1.8444 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0088 loss_train: 1.8404 acc_train: 0.3019 loss_val: 1.8433 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0089 loss_train: 1.8409 acc_train: 0.3019 loss_val: 1.8423 acc_val: 0.2952 time: 0.0082s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0090 loss_train: 1.8520 acc_train: 0.3019 loss_val: 1.8413 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0091 loss_train: 1.8414 acc_train: 0.3019 loss_val: 1.8403 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0092 loss_train: 1.8427 acc_train: 0.3019 loss_val: 1.8393 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0093 loss_train: 1.8444 acc_train: 0.3019 loss_val: 1.8383 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0094 loss_train: 1.8344 acc_train: 0.3019 loss_val: 1.8373 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0095 loss_train: 1.8374 acc_train: 0.3019 loss_val: 1.8364 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0096 loss_train: 1.8410 acc_train: 0.3019 loss_val: 1.8354 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0097 loss_train: 1.8387 acc_train: 0.3019 loss_val: 1.8344 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0098 loss_train: 1.8371 acc_train: 0.3019 loss_val: 1.8334 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0099 loss_train: 1.8324 acc_train: 0.3019 loss_val: 1.8324 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0100 loss_train: 1.8353 acc_train: 0.3019 loss_val: 1.8315 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0101 loss_train: 1.8321 acc_train: 0.3019 loss_val: 1.8305 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0102 loss_train: 1.8272 acc_train: 0.3019 loss_val: 1.8295 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0103 loss_train: 1.8347 acc_train: 0.3019 loss_val: 1.8285 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0104 loss_train: 1.8325 acc_train: 0.3019 loss_val: 1.8276 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0105 loss_train: 1.8336 acc_train: 0.3019 loss_val: 1.8266 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0106 loss_train: 1.8295 acc_train: 0.3019 loss_val: 1.8256 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0107 loss_train: 1.8237 acc_train: 0.3019 loss_val: 1.8247 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0108 loss_train: 1.8277 acc_train: 0.3019 loss_val: 1.8238 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0109 loss_train: 1.8260 acc_train: 0.3019 loss_val: 1.8228 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0110 loss_train: 1.8304 acc_train: 0.3019 loss_val: 1.8219 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0111 loss_train: 1.8237 acc_train: 0.3019 loss_val: 1.8210 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0112 loss_train: 1.8223 acc_train: 0.3019 loss_val: 1.8200 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0113 loss_train: 1.8265 acc_train: 0.3019 loss_val: 1.8191 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0114 loss_train: 1.8211 acc_train: 0.3019 loss_val: 1.8182 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0115 loss_train: 1.8191 acc_train: 0.3019 loss_val: 1.8173 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0116 loss_train: 1.8234 acc_train: 0.3019 loss_val: 1.8164 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0117 loss_train: 1.8220 acc_train: 0.3019 loss_val: 1.8155 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0118 loss_train: 1.8178 acc_train: 0.3019 loss_val: 1.8146 acc_val: 0.2952 time: 0.0074s\n",
      "Epoch: 0119 loss_train: 1.8270 acc_train: 0.3019 loss_val: 1.8137 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0120 loss_train: 1.8187 acc_train: 0.3019 loss_val: 1.8128 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0121 loss_train: 1.8173 acc_train: 0.3019 loss_val: 1.8119 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0122 loss_train: 1.8091 acc_train: 0.3019 loss_val: 1.8110 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0123 loss_train: 1.8226 acc_train: 0.3019 loss_val: 1.8101 acc_val: 0.2952 time: 0.0074s\n",
      "Epoch: 0124 loss_train: 1.8073 acc_train: 0.3019 loss_val: 1.8093 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0125 loss_train: 1.8093 acc_train: 0.3019 loss_val: 1.8084 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0126 loss_train: 1.8155 acc_train: 0.3019 loss_val: 1.8075 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0127 loss_train: 1.8132 acc_train: 0.3019 loss_val: 1.8067 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0128 loss_train: 1.8146 acc_train: 0.3019 loss_val: 1.8058 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0129 loss_train: 1.8127 acc_train: 0.3019 loss_val: 1.8050 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0130 loss_train: 1.8152 acc_train: 0.3019 loss_val: 1.8041 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0131 loss_train: 1.8140 acc_train: 0.3019 loss_val: 1.8033 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0132 loss_train: 1.8088 acc_train: 0.3019 loss_val: 1.8025 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0133 loss_train: 1.8103 acc_train: 0.3019 loss_val: 1.8016 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0134 loss_train: 1.8001 acc_train: 0.3019 loss_val: 1.8008 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0135 loss_train: 1.8030 acc_train: 0.3019 loss_val: 1.8000 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0136 loss_train: 1.8067 acc_train: 0.3019 loss_val: 1.7991 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0137 loss_train: 1.8016 acc_train: 0.3019 loss_val: 1.7983 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0138 loss_train: 1.8030 acc_train: 0.3019 loss_val: 1.7975 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0139 loss_train: 1.8037 acc_train: 0.3019 loss_val: 1.7967 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0140 loss_train: 1.8052 acc_train: 0.3019 loss_val: 1.7959 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0141 loss_train: 1.8024 acc_train: 0.3019 loss_val: 1.7951 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0142 loss_train: 1.8077 acc_train: 0.3019 loss_val: 1.7943 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0143 loss_train: 1.8005 acc_train: 0.3019 loss_val: 1.7935 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0144 loss_train: 1.8013 acc_train: 0.3019 loss_val: 1.7927 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0145 loss_train: 1.7996 acc_train: 0.3019 loss_val: 1.7919 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0146 loss_train: 1.7946 acc_train: 0.3019 loss_val: 1.7911 acc_val: 0.2952 time: 0.0071s\n",
      "Epoch: 0147 loss_train: 1.7991 acc_train: 0.3019 loss_val: 1.7903 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0148 loss_train: 1.8038 acc_train: 0.3019 loss_val: 1.7896 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0149 loss_train: 1.7932 acc_train: 0.3019 loss_val: 1.7888 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0150 loss_train: 1.7921 acc_train: 0.3019 loss_val: 1.7880 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0151 loss_train: 1.7857 acc_train: 0.3019 loss_val: 1.7872 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0152 loss_train: 1.7896 acc_train: 0.3019 loss_val: 1.7864 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0153 loss_train: 1.7985 acc_train: 0.3019 loss_val: 1.7857 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0154 loss_train: 1.7955 acc_train: 0.3019 loss_val: 1.7849 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0155 loss_train: 1.7895 acc_train: 0.3019 loss_val: 1.7842 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0156 loss_train: 1.8039 acc_train: 0.3019 loss_val: 1.7834 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0157 loss_train: 1.7927 acc_train: 0.3019 loss_val: 1.7827 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0158 loss_train: 1.7874 acc_train: 0.3019 loss_val: 1.7820 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0159 loss_train: 1.7930 acc_train: 0.3019 loss_val: 1.7812 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0160 loss_train: 1.7868 acc_train: 0.3019 loss_val: 1.7805 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0161 loss_train: 1.7927 acc_train: 0.3019 loss_val: 1.7797 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0162 loss_train: 1.7857 acc_train: 0.3019 loss_val: 1.7790 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0163 loss_train: 1.7828 acc_train: 0.3019 loss_val: 1.7782 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0164 loss_train: 1.7894 acc_train: 0.3019 loss_val: 1.7775 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0165 loss_train: 1.7817 acc_train: 0.3019 loss_val: 1.7768 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0166 loss_train: 1.7832 acc_train: 0.3019 loss_val: 1.7760 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0167 loss_train: 1.7884 acc_train: 0.3019 loss_val: 1.7753 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0168 loss_train: 1.7825 acc_train: 0.3019 loss_val: 1.7745 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0169 loss_train: 1.7797 acc_train: 0.3019 loss_val: 1.7738 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0170 loss_train: 1.7812 acc_train: 0.3019 loss_val: 1.7730 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0171 loss_train: 1.7854 acc_train: 0.3019 loss_val: 1.7723 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0172 loss_train: 1.7764 acc_train: 0.3019 loss_val: 1.7715 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0173 loss_train: 1.7776 acc_train: 0.3019 loss_val: 1.7707 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0174 loss_train: 1.7712 acc_train: 0.3019 loss_val: 1.7699 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0175 loss_train: 1.7783 acc_train: 0.3024 loss_val: 1.7692 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0176 loss_train: 1.7756 acc_train: 0.3019 loss_val: 1.7684 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0177 loss_train: 1.7783 acc_train: 0.3019 loss_val: 1.7676 acc_val: 0.2952 time: 0.0078s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0178 loss_train: 1.7719 acc_train: 0.3019 loss_val: 1.7669 acc_val: 0.2952 time: 0.0089s\n",
      "Epoch: 0179 loss_train: 1.7721 acc_train: 0.3019 loss_val: 1.7661 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0180 loss_train: 1.7733 acc_train: 0.3019 loss_val: 1.7653 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0181 loss_train: 1.7704 acc_train: 0.3019 loss_val: 1.7646 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0182 loss_train: 1.7726 acc_train: 0.3019 loss_val: 1.7638 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0183 loss_train: 1.7740 acc_train: 0.3019 loss_val: 1.7631 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0184 loss_train: 1.7823 acc_train: 0.3019 loss_val: 1.7624 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0185 loss_train: 1.7763 acc_train: 0.3019 loss_val: 1.7616 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0186 loss_train: 1.7728 acc_train: 0.3019 loss_val: 1.7609 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0187 loss_train: 1.7796 acc_train: 0.3019 loss_val: 1.7601 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0188 loss_train: 1.7694 acc_train: 0.3019 loss_val: 1.7594 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0189 loss_train: 1.7646 acc_train: 0.3019 loss_val: 1.7587 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0190 loss_train: 1.7666 acc_train: 0.3019 loss_val: 1.7579 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0191 loss_train: 1.7758 acc_train: 0.3019 loss_val: 1.7572 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0192 loss_train: 1.7679 acc_train: 0.3019 loss_val: 1.7565 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0193 loss_train: 1.7688 acc_train: 0.3019 loss_val: 1.7557 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0194 loss_train: 1.7596 acc_train: 0.3019 loss_val: 1.7550 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0195 loss_train: 1.7632 acc_train: 0.3024 loss_val: 1.7543 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0196 loss_train: 1.7584 acc_train: 0.3019 loss_val: 1.7535 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0197 loss_train: 1.7586 acc_train: 0.3019 loss_val: 1.7528 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0198 loss_train: 1.7531 acc_train: 0.3019 loss_val: 1.7521 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0199 loss_train: 1.7691 acc_train: 0.3019 loss_val: 1.7513 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0200 loss_train: 1.7565 acc_train: 0.3019 loss_val: 1.7506 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0201 loss_train: 1.7615 acc_train: 0.3019 loss_val: 1.7499 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0202 loss_train: 1.7583 acc_train: 0.3019 loss_val: 1.7491 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0203 loss_train: 1.7543 acc_train: 0.3019 loss_val: 1.7484 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0204 loss_train: 1.7512 acc_train: 0.3019 loss_val: 1.7477 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0205 loss_train: 1.7614 acc_train: 0.3019 loss_val: 1.7469 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0206 loss_train: 1.7393 acc_train: 0.3019 loss_val: 1.7462 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0207 loss_train: 1.7487 acc_train: 0.3019 loss_val: 1.7454 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0208 loss_train: 1.7487 acc_train: 0.3019 loss_val: 1.7446 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0209 loss_train: 1.7650 acc_train: 0.3019 loss_val: 1.7439 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0210 loss_train: 1.7505 acc_train: 0.3033 loss_val: 1.7431 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0211 loss_train: 1.7517 acc_train: 0.3019 loss_val: 1.7423 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0212 loss_train: 1.7518 acc_train: 0.3019 loss_val: 1.7415 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0213 loss_train: 1.7498 acc_train: 0.3024 loss_val: 1.7407 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0214 loss_train: 1.7452 acc_train: 0.3019 loss_val: 1.7399 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0215 loss_train: 1.7406 acc_train: 0.3019 loss_val: 1.7391 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0216 loss_train: 1.7391 acc_train: 0.3024 loss_val: 1.7383 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0217 loss_train: 1.7414 acc_train: 0.3019 loss_val: 1.7374 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0218 loss_train: 1.7459 acc_train: 0.3019 loss_val: 1.7366 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0219 loss_train: 1.7427 acc_train: 0.3019 loss_val: 1.7358 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0220 loss_train: 1.7473 acc_train: 0.3019 loss_val: 1.7349 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0221 loss_train: 1.7388 acc_train: 0.3029 loss_val: 1.7341 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0222 loss_train: 1.7359 acc_train: 0.3024 loss_val: 1.7332 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0223 loss_train: 1.7447 acc_train: 0.3019 loss_val: 1.7324 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0224 loss_train: 1.7391 acc_train: 0.3019 loss_val: 1.7315 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0225 loss_train: 1.7388 acc_train: 0.3029 loss_val: 1.7307 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0226 loss_train: 1.7405 acc_train: 0.3029 loss_val: 1.7298 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0227 loss_train: 1.7346 acc_train: 0.3042 loss_val: 1.7289 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0228 loss_train: 1.7445 acc_train: 0.3019 loss_val: 1.7281 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0229 loss_train: 1.7321 acc_train: 0.3024 loss_val: 1.7272 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0230 loss_train: 1.7306 acc_train: 0.3019 loss_val: 1.7263 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0231 loss_train: 1.7295 acc_train: 0.3024 loss_val: 1.7254 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0232 loss_train: 1.7300 acc_train: 0.3029 loss_val: 1.7245 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0233 loss_train: 1.7376 acc_train: 0.3029 loss_val: 1.7237 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0234 loss_train: 1.7346 acc_train: 0.3024 loss_val: 1.7228 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0235 loss_train: 1.7293 acc_train: 0.3024 loss_val: 1.7218 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0236 loss_train: 1.7217 acc_train: 0.3033 loss_val: 1.7209 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0237 loss_train: 1.7185 acc_train: 0.3024 loss_val: 1.7200 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0238 loss_train: 1.7210 acc_train: 0.3038 loss_val: 1.7191 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0239 loss_train: 1.7239 acc_train: 0.3019 loss_val: 1.7182 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0240 loss_train: 1.7248 acc_train: 0.3019 loss_val: 1.7172 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0241 loss_train: 1.7158 acc_train: 0.3019 loss_val: 1.7163 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0242 loss_train: 1.7272 acc_train: 0.3024 loss_val: 1.7153 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0243 loss_train: 1.7222 acc_train: 0.3029 loss_val: 1.7144 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0244 loss_train: 1.7160 acc_train: 0.3024 loss_val: 1.7134 acc_val: 0.2952 time: 0.0088s\n",
      "Epoch: 0245 loss_train: 1.7257 acc_train: 0.3029 loss_val: 1.7124 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0246 loss_train: 1.7092 acc_train: 0.3019 loss_val: 1.7115 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0247 loss_train: 1.7092 acc_train: 0.3029 loss_val: 1.7105 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0248 loss_train: 1.7160 acc_train: 0.3029 loss_val: 1.7095 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0249 loss_train: 1.7122 acc_train: 0.3019 loss_val: 1.7085 acc_val: 0.2952 time: 0.0086s\n",
      "Epoch: 0250 loss_train: 1.7165 acc_train: 0.3038 loss_val: 1.7075 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0251 loss_train: 1.7119 acc_train: 0.3019 loss_val: 1.7065 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0252 loss_train: 1.7164 acc_train: 0.3033 loss_val: 1.7055 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0253 loss_train: 1.7198 acc_train: 0.3024 loss_val: 1.7045 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0254 loss_train: 1.7097 acc_train: 0.3047 loss_val: 1.7035 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0255 loss_train: 1.7094 acc_train: 0.3052 loss_val: 1.7025 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0256 loss_train: 1.7137 acc_train: 0.3038 loss_val: 1.7015 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0257 loss_train: 1.7094 acc_train: 0.3038 loss_val: 1.7005 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0258 loss_train: 1.7151 acc_train: 0.3033 loss_val: 1.6996 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0259 loss_train: 1.7111 acc_train: 0.3047 loss_val: 1.6986 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0260 loss_train: 1.7077 acc_train: 0.3042 loss_val: 1.6976 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0261 loss_train: 1.6963 acc_train: 0.3038 loss_val: 1.6966 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0262 loss_train: 1.6981 acc_train: 0.3052 loss_val: 1.6957 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0263 loss_train: 1.7024 acc_train: 0.3052 loss_val: 1.6947 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0264 loss_train: 1.7092 acc_train: 0.3066 loss_val: 1.6937 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0265 loss_train: 1.7014 acc_train: 0.3033 loss_val: 1.6927 acc_val: 0.2952 time: 0.0075s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0266 loss_train: 1.7016 acc_train: 0.3052 loss_val: 1.6917 acc_val: 0.2952 time: 0.0079s\n",
      "Epoch: 0267 loss_train: 1.6971 acc_train: 0.3066 loss_val: 1.6907 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0268 loss_train: 1.6936 acc_train: 0.3047 loss_val: 1.6897 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0269 loss_train: 1.6897 acc_train: 0.3052 loss_val: 1.6887 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0270 loss_train: 1.6921 acc_train: 0.3061 loss_val: 1.6877 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0271 loss_train: 1.6921 acc_train: 0.3070 loss_val: 1.6867 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0272 loss_train: 1.6944 acc_train: 0.3066 loss_val: 1.6857 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0273 loss_train: 1.6850 acc_train: 0.3070 loss_val: 1.6846 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0274 loss_train: 1.6911 acc_train: 0.3066 loss_val: 1.6836 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0275 loss_train: 1.6860 acc_train: 0.3084 loss_val: 1.6825 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0276 loss_train: 1.6927 acc_train: 0.3061 loss_val: 1.6814 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0277 loss_train: 1.6903 acc_train: 0.3070 loss_val: 1.6804 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0278 loss_train: 1.6893 acc_train: 0.3079 loss_val: 1.6793 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0279 loss_train: 1.6803 acc_train: 0.3116 loss_val: 1.6782 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0280 loss_train: 1.6886 acc_train: 0.3089 loss_val: 1.6772 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0281 loss_train: 1.6815 acc_train: 0.3084 loss_val: 1.6761 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0282 loss_train: 1.6806 acc_train: 0.3038 loss_val: 1.6750 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0283 loss_train: 1.6734 acc_train: 0.3172 loss_val: 1.6739 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0284 loss_train: 1.6792 acc_train: 0.3139 loss_val: 1.6727 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0285 loss_train: 1.6792 acc_train: 0.3070 loss_val: 1.6716 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0286 loss_train: 1.6724 acc_train: 0.3167 loss_val: 1.6705 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0287 loss_train: 1.6878 acc_train: 0.3093 loss_val: 1.6693 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0288 loss_train: 1.6703 acc_train: 0.3107 loss_val: 1.6682 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0289 loss_train: 1.6765 acc_train: 0.3070 loss_val: 1.6670 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0290 loss_train: 1.6557 acc_train: 0.3130 loss_val: 1.6659 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0291 loss_train: 1.6703 acc_train: 0.3126 loss_val: 1.6647 acc_val: 0.2952 time: 0.0080s\n",
      "Epoch: 0292 loss_train: 1.6598 acc_train: 0.3121 loss_val: 1.6635 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0293 loss_train: 1.6596 acc_train: 0.3130 loss_val: 1.6623 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0294 loss_train: 1.6639 acc_train: 0.3102 loss_val: 1.6611 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0295 loss_train: 1.6714 acc_train: 0.3116 loss_val: 1.6600 acc_val: 0.2952 time: 0.0083s\n",
      "Epoch: 0296 loss_train: 1.6651 acc_train: 0.3144 loss_val: 1.6588 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0297 loss_train: 1.6567 acc_train: 0.3227 loss_val: 1.6576 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0298 loss_train: 1.6657 acc_train: 0.3139 loss_val: 1.6564 acc_val: 0.2952 time: 0.0074s\n",
      "Epoch: 0299 loss_train: 1.6682 acc_train: 0.3098 loss_val: 1.6551 acc_val: 0.2952 time: 0.0073s\n",
      "Epoch: 0300 loss_train: 1.6607 acc_train: 0.3139 loss_val: 1.6539 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0301 loss_train: 1.6572 acc_train: 0.3153 loss_val: 1.6527 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0302 loss_train: 1.6557 acc_train: 0.3176 loss_val: 1.6514 acc_val: 0.2952 time: 0.0081s\n",
      "Epoch: 0303 loss_train: 1.6572 acc_train: 0.3089 loss_val: 1.6502 acc_val: 0.2952 time: 0.0078s\n",
      "Epoch: 0304 loss_train: 1.6603 acc_train: 0.3126 loss_val: 1.6489 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0305 loss_train: 1.6479 acc_train: 0.3163 loss_val: 1.6476 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0306 loss_train: 1.6516 acc_train: 0.3186 loss_val: 1.6464 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0307 loss_train: 1.6434 acc_train: 0.3209 loss_val: 1.6451 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0308 loss_train: 1.6609 acc_train: 0.3139 loss_val: 1.6438 acc_val: 0.2952 time: 0.0076s\n",
      "Epoch: 0309 loss_train: 1.6312 acc_train: 0.3227 loss_val: 1.6424 acc_val: 0.2952 time: 0.0087s\n",
      "Epoch: 0310 loss_train: 1.6487 acc_train: 0.3250 loss_val: 1.6411 acc_val: 0.2952 time: 0.0090s\n",
      "Epoch: 0311 loss_train: 1.6416 acc_train: 0.3181 loss_val: 1.6398 acc_val: 0.2952 time: 0.0085s\n",
      "Epoch: 0312 loss_train: 1.6429 acc_train: 0.3070 loss_val: 1.6385 acc_val: 0.2952 time: 0.0088s\n",
      "Epoch: 0313 loss_train: 1.6425 acc_train: 0.3218 loss_val: 1.6372 acc_val: 0.2952 time: 0.0077s\n",
      "Epoch: 0314 loss_train: 1.6417 acc_train: 0.3186 loss_val: 1.6358 acc_val: 0.2952 time: 0.0075s\n",
      "Epoch: 0315 loss_train: 1.6363 acc_train: 0.3250 loss_val: 1.6345 acc_val: 0.2952 time: 0.0072s\n",
      "Epoch: 0316 loss_train: 1.6342 acc_train: 0.3186 loss_val: 1.6331 acc_val: 0.2952 time: 0.0082s\n",
      "Epoch: 0317 loss_train: 1.6288 acc_train: 0.3135 loss_val: 1.6318 acc_val: 0.2952 time: 0.0084s\n",
      "Epoch: 0318 loss_train: 1.6338 acc_train: 0.3218 loss_val: 1.6304 acc_val: 0.2989 time: 0.0078s\n",
      "Epoch: 0319 loss_train: 1.6272 acc_train: 0.3347 loss_val: 1.6290 acc_val: 0.2989 time: 0.0078s\n",
      "Epoch: 0320 loss_train: 1.6373 acc_train: 0.3269 loss_val: 1.6277 acc_val: 0.2989 time: 0.0081s\n",
      "Epoch: 0321 loss_train: 1.6262 acc_train: 0.3361 loss_val: 1.6263 acc_val: 0.2989 time: 0.0083s\n",
      "Epoch: 0322 loss_train: 1.6409 acc_train: 0.3236 loss_val: 1.6249 acc_val: 0.3026 time: 0.0084s\n",
      "Epoch: 0323 loss_train: 1.6202 acc_train: 0.3296 loss_val: 1.6235 acc_val: 0.3026 time: 0.0087s\n",
      "Epoch: 0324 loss_train: 1.6318 acc_train: 0.3223 loss_val: 1.6222 acc_val: 0.3026 time: 0.0077s\n",
      "Epoch: 0325 loss_train: 1.6315 acc_train: 0.3264 loss_val: 1.6208 acc_val: 0.3026 time: 0.0075s\n",
      "Epoch: 0326 loss_train: 1.6164 acc_train: 0.3292 loss_val: 1.6195 acc_val: 0.3026 time: 0.0072s\n",
      "Epoch: 0327 loss_train: 1.6078 acc_train: 0.3292 loss_val: 1.6181 acc_val: 0.3026 time: 0.0083s\n",
      "Epoch: 0328 loss_train: 1.6154 acc_train: 0.3310 loss_val: 1.6167 acc_val: 0.3026 time: 0.0083s\n",
      "Epoch: 0329 loss_train: 1.6075 acc_train: 0.3204 loss_val: 1.6154 acc_val: 0.3026 time: 0.0080s\n",
      "Epoch: 0330 loss_train: 1.6194 acc_train: 0.3407 loss_val: 1.6140 acc_val: 0.3026 time: 0.0078s\n",
      "Epoch: 0331 loss_train: 1.6211 acc_train: 0.3301 loss_val: 1.6127 acc_val: 0.3026 time: 0.0082s\n",
      "Epoch: 0332 loss_train: 1.6148 acc_train: 0.3301 loss_val: 1.6113 acc_val: 0.3026 time: 0.0089s\n",
      "Epoch: 0333 loss_train: 1.6064 acc_train: 0.3500 loss_val: 1.6098 acc_val: 0.3026 time: 0.0085s\n",
      "Epoch: 0334 loss_train: 1.6078 acc_train: 0.3329 loss_val: 1.6084 acc_val: 0.3026 time: 0.0086s\n",
      "Epoch: 0335 loss_train: 1.6258 acc_train: 0.3273 loss_val: 1.6069 acc_val: 0.3026 time: 0.0077s\n",
      "Epoch: 0336 loss_train: 1.5996 acc_train: 0.3486 loss_val: 1.6055 acc_val: 0.3026 time: 0.0079s\n",
      "Epoch: 0337 loss_train: 1.5981 acc_train: 0.3435 loss_val: 1.6040 acc_val: 0.3026 time: 0.0079s\n",
      "Epoch: 0338 loss_train: 1.5982 acc_train: 0.3292 loss_val: 1.6025 acc_val: 0.3026 time: 0.0083s\n",
      "Epoch: 0339 loss_train: 1.6018 acc_train: 0.3361 loss_val: 1.6010 acc_val: 0.3063 time: 0.0083s\n",
      "Epoch: 0340 loss_train: 1.5961 acc_train: 0.3435 loss_val: 1.5995 acc_val: 0.3063 time: 0.0079s\n",
      "Epoch: 0341 loss_train: 1.6040 acc_train: 0.3370 loss_val: 1.5981 acc_val: 0.3063 time: 0.0077s\n",
      "Epoch: 0342 loss_train: 1.6020 acc_train: 0.3416 loss_val: 1.5966 acc_val: 0.3063 time: 0.0080s\n",
      "Epoch: 0343 loss_train: 1.6007 acc_train: 0.3352 loss_val: 1.5952 acc_val: 0.3063 time: 0.0082s\n",
      "Epoch: 0344 loss_train: 1.5969 acc_train: 0.3370 loss_val: 1.5937 acc_val: 0.3063 time: 0.0084s\n",
      "Epoch: 0345 loss_train: 1.5791 acc_train: 0.3472 loss_val: 1.5922 acc_val: 0.3063 time: 0.0085s\n",
      "Epoch: 0346 loss_train: 1.5977 acc_train: 0.3324 loss_val: 1.5907 acc_val: 0.3063 time: 0.0079s\n",
      "Epoch: 0347 loss_train: 1.6014 acc_train: 0.3380 loss_val: 1.5892 acc_val: 0.3063 time: 0.0079s\n",
      "Epoch: 0348 loss_train: 1.5778 acc_train: 0.3458 loss_val: 1.5878 acc_val: 0.3063 time: 0.0079s\n",
      "Epoch: 0349 loss_train: 1.5908 acc_train: 0.3343 loss_val: 1.5863 acc_val: 0.3063 time: 0.0082s\n",
      "Epoch: 0350 loss_train: 1.5898 acc_train: 0.3453 loss_val: 1.5848 acc_val: 0.3063 time: 0.0083s\n",
      "Epoch: 0351 loss_train: 1.5800 acc_train: 0.3680 loss_val: 1.5834 acc_val: 0.3100 time: 0.0077s\n",
      "Epoch: 0352 loss_train: 1.5796 acc_train: 0.3560 loss_val: 1.5819 acc_val: 0.3100 time: 0.0078s\n",
      "Epoch: 0353 loss_train: 1.5830 acc_train: 0.3430 loss_val: 1.5804 acc_val: 0.3100 time: 0.0079s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0354 loss_train: 1.5693 acc_train: 0.3472 loss_val: 1.5789 acc_val: 0.3100 time: 0.0087s\n",
      "Epoch: 0355 loss_train: 1.5763 acc_train: 0.3560 loss_val: 1.5774 acc_val: 0.3100 time: 0.0083s\n",
      "Epoch: 0356 loss_train: 1.5749 acc_train: 0.3707 loss_val: 1.5759 acc_val: 0.3100 time: 0.0087s\n",
      "Epoch: 0357 loss_train: 1.5692 acc_train: 0.3546 loss_val: 1.5744 acc_val: 0.3137 time: 0.0078s\n",
      "Epoch: 0358 loss_train: 1.5768 acc_train: 0.3587 loss_val: 1.5729 acc_val: 0.3137 time: 0.0079s\n",
      "Epoch: 0359 loss_train: 1.5808 acc_train: 0.3610 loss_val: 1.5714 acc_val: 0.3137 time: 0.0079s\n",
      "Epoch: 0360 loss_train: 1.5813 acc_train: 0.3596 loss_val: 1.5699 acc_val: 0.3137 time: 0.0083s\n",
      "Epoch: 0361 loss_train: 1.5771 acc_train: 0.3606 loss_val: 1.5683 acc_val: 0.3137 time: 0.0082s\n",
      "Epoch: 0362 loss_train: 1.5653 acc_train: 0.3652 loss_val: 1.5667 acc_val: 0.3137 time: 0.0079s\n",
      "Epoch: 0363 loss_train: 1.5611 acc_train: 0.3804 loss_val: 1.5651 acc_val: 0.3173 time: 0.0078s\n",
      "Epoch: 0364 loss_train: 1.5491 acc_train: 0.3790 loss_val: 1.5635 acc_val: 0.3173 time: 0.0079s\n",
      "Epoch: 0365 loss_train: 1.5633 acc_train: 0.3596 loss_val: 1.5619 acc_val: 0.3173 time: 0.0082s\n",
      "Epoch: 0366 loss_train: 1.5657 acc_train: 0.3587 loss_val: 1.5603 acc_val: 0.3173 time: 0.0084s\n",
      "Epoch: 0367 loss_train: 1.5567 acc_train: 0.3610 loss_val: 1.5588 acc_val: 0.3173 time: 0.0085s\n",
      "Epoch: 0368 loss_train: 1.5622 acc_train: 0.3740 loss_val: 1.5572 acc_val: 0.3173 time: 0.0076s\n",
      "Epoch: 0369 loss_train: 1.5541 acc_train: 0.3827 loss_val: 1.5556 acc_val: 0.3173 time: 0.0084s\n",
      "Epoch: 0370 loss_train: 1.5459 acc_train: 0.3823 loss_val: 1.5540 acc_val: 0.3173 time: 0.0083s\n",
      "Epoch: 0371 loss_train: 1.5595 acc_train: 0.3587 loss_val: 1.5524 acc_val: 0.3173 time: 0.0084s\n",
      "Epoch: 0372 loss_train: 1.5647 acc_train: 0.3583 loss_val: 1.5508 acc_val: 0.3173 time: 0.0086s\n",
      "Epoch: 0373 loss_train: 1.5473 acc_train: 0.3781 loss_val: 1.5492 acc_val: 0.3210 time: 0.0076s\n",
      "Epoch: 0374 loss_train: 1.5357 acc_train: 0.3887 loss_val: 1.5476 acc_val: 0.3210 time: 0.0075s\n",
      "Epoch: 0375 loss_train: 1.5472 acc_train: 0.3717 loss_val: 1.5460 acc_val: 0.3210 time: 0.0072s\n",
      "Epoch: 0376 loss_train: 1.5468 acc_train: 0.3860 loss_val: 1.5444 acc_val: 0.3210 time: 0.0089s\n",
      "Epoch: 0377 loss_train: 1.5535 acc_train: 0.3786 loss_val: 1.5428 acc_val: 0.3247 time: 0.0083s\n",
      "Epoch: 0378 loss_train: 1.5412 acc_train: 0.3832 loss_val: 1.5412 acc_val: 0.3247 time: 0.0077s\n",
      "Epoch: 0379 loss_train: 1.5423 acc_train: 0.3832 loss_val: 1.5396 acc_val: 0.3284 time: 0.0078s\n",
      "Epoch: 0380 loss_train: 1.5341 acc_train: 0.3855 loss_val: 1.5381 acc_val: 0.3284 time: 0.0082s\n",
      "Epoch: 0381 loss_train: 1.5427 acc_train: 0.3767 loss_val: 1.5365 acc_val: 0.3358 time: 0.0081s\n",
      "Epoch: 0382 loss_train: 1.5279 acc_train: 0.4007 loss_val: 1.5349 acc_val: 0.3395 time: 0.0084s\n",
      "Epoch: 0383 loss_train: 1.5338 acc_train: 0.3929 loss_val: 1.5333 acc_val: 0.3432 time: 0.0086s\n",
      "Epoch: 0384 loss_train: 1.5414 acc_train: 0.3735 loss_val: 1.5317 acc_val: 0.3469 time: 0.0078s\n",
      "Epoch: 0385 loss_train: 1.5247 acc_train: 0.4095 loss_val: 1.5301 acc_val: 0.3506 time: 0.0074s\n",
      "Epoch: 0386 loss_train: 1.5288 acc_train: 0.4063 loss_val: 1.5285 acc_val: 0.3506 time: 0.0072s\n",
      "Epoch: 0387 loss_train: 1.5198 acc_train: 0.4077 loss_val: 1.5269 acc_val: 0.3542 time: 0.0083s\n",
      "Epoch: 0388 loss_train: 1.5149 acc_train: 0.4127 loss_val: 1.5253 acc_val: 0.3542 time: 0.0082s\n",
      "Epoch: 0389 loss_train: 1.5257 acc_train: 0.3915 loss_val: 1.5237 acc_val: 0.3542 time: 0.0082s\n",
      "Epoch: 0390 loss_train: 1.5281 acc_train: 0.3966 loss_val: 1.5221 acc_val: 0.3542 time: 0.0078s\n",
      "Epoch: 0391 loss_train: 1.5289 acc_train: 0.3873 loss_val: 1.5206 acc_val: 0.3542 time: 0.0082s\n",
      "Epoch: 0392 loss_train: 1.5109 acc_train: 0.4178 loss_val: 1.5190 acc_val: 0.3579 time: 0.0083s\n",
      "Epoch: 0393 loss_train: 1.5188 acc_train: 0.4077 loss_val: 1.5174 acc_val: 0.3579 time: 0.0084s\n",
      "Epoch: 0394 loss_train: 1.5257 acc_train: 0.3961 loss_val: 1.5159 acc_val: 0.3579 time: 0.0087s\n",
      "Epoch: 0395 loss_train: 1.5127 acc_train: 0.4141 loss_val: 1.5143 acc_val: 0.3579 time: 0.0077s\n",
      "Epoch: 0396 loss_train: 1.5100 acc_train: 0.4317 loss_val: 1.5128 acc_val: 0.3579 time: 0.0074s\n",
      "Epoch: 0397 loss_train: 1.5038 acc_train: 0.4229 loss_val: 1.5113 acc_val: 0.3653 time: 0.0072s\n",
      "Epoch: 0398 loss_train: 1.5060 acc_train: 0.4035 loss_val: 1.5097 acc_val: 0.3690 time: 0.0088s\n",
      "Epoch: 0399 loss_train: 1.5035 acc_train: 0.4155 loss_val: 1.5082 acc_val: 0.3727 time: 0.0082s\n",
      "Epoch: 0400 loss_train: 1.4927 acc_train: 0.4317 loss_val: 1.5067 acc_val: 0.3727 time: 0.0081s\n",
      "Epoch: 0401 loss_train: 1.4888 acc_train: 0.4335 loss_val: 1.5051 acc_val: 0.3764 time: 0.0078s\n",
      "Epoch: 0402 loss_train: 1.5047 acc_train: 0.4123 loss_val: 1.5035 acc_val: 0.3764 time: 0.0081s\n",
      "Epoch: 0403 loss_train: 1.5087 acc_train: 0.4114 loss_val: 1.5019 acc_val: 0.3764 time: 0.0082s\n",
      "Epoch: 0404 loss_train: 1.5027 acc_train: 0.4058 loss_val: 1.5004 acc_val: 0.3764 time: 0.0083s\n",
      "Epoch: 0405 loss_train: 1.4961 acc_train: 0.4261 loss_val: 1.4988 acc_val: 0.3801 time: 0.0087s\n",
      "Epoch: 0406 loss_train: 1.4928 acc_train: 0.4524 loss_val: 1.4972 acc_val: 0.3838 time: 0.0078s\n",
      "Epoch: 0407 loss_train: 1.5002 acc_train: 0.4141 loss_val: 1.4955 acc_val: 0.3838 time: 0.0074s\n",
      "Epoch: 0408 loss_train: 1.4838 acc_train: 0.4229 loss_val: 1.4939 acc_val: 0.3911 time: 0.0072s\n",
      "Epoch: 0409 loss_train: 1.4913 acc_train: 0.4224 loss_val: 1.4922 acc_val: 0.3948 time: 0.0082s\n",
      "Epoch: 0410 loss_train: 1.4870 acc_train: 0.4335 loss_val: 1.4906 acc_val: 0.4059 time: 0.0082s\n",
      "Epoch: 0411 loss_train: 1.4797 acc_train: 0.4349 loss_val: 1.4890 acc_val: 0.4059 time: 0.0083s\n",
      "Epoch: 0412 loss_train: 1.4739 acc_train: 0.4538 loss_val: 1.4873 acc_val: 0.4133 time: 0.0078s\n",
      "Epoch: 0413 loss_train: 1.4784 acc_train: 0.4441 loss_val: 1.4856 acc_val: 0.4133 time: 0.0083s\n",
      "Epoch: 0414 loss_train: 1.4707 acc_train: 0.4686 loss_val: 1.4839 acc_val: 0.4207 time: 0.0083s\n",
      "Epoch: 0415 loss_train: 1.4823 acc_train: 0.4409 loss_val: 1.4821 acc_val: 0.4207 time: 0.0085s\n",
      "Epoch: 0416 loss_train: 1.4800 acc_train: 0.4404 loss_val: 1.4804 acc_val: 0.4207 time: 0.0086s\n",
      "Epoch: 0417 loss_train: 1.4781 acc_train: 0.4363 loss_val: 1.4787 acc_val: 0.4207 time: 0.0078s\n",
      "Epoch: 0418 loss_train: 1.4798 acc_train: 0.4312 loss_val: 1.4770 acc_val: 0.4207 time: 0.0076s\n",
      "Epoch: 0419 loss_train: 1.4684 acc_train: 0.4497 loss_val: 1.4754 acc_val: 0.4207 time: 0.0074s\n",
      "Epoch: 0420 loss_train: 1.4791 acc_train: 0.4335 loss_val: 1.4737 acc_val: 0.4207 time: 0.0086s\n",
      "Epoch: 0421 loss_train: 1.4768 acc_train: 0.4561 loss_val: 1.4720 acc_val: 0.4207 time: 0.0083s\n",
      "Epoch: 0422 loss_train: 1.4658 acc_train: 0.4658 loss_val: 1.4703 acc_val: 0.4207 time: 0.0079s\n",
      "Epoch: 0423 loss_train: 1.4688 acc_train: 0.4658 loss_val: 1.4686 acc_val: 0.4244 time: 0.0120s\n",
      "Epoch: 0424 loss_train: 1.4750 acc_train: 0.4437 loss_val: 1.4670 acc_val: 0.4354 time: 0.0074s\n",
      "Epoch: 0425 loss_train: 1.4579 acc_train: 0.4774 loss_val: 1.4653 acc_val: 0.4391 time: 0.0080s\n",
      "Epoch: 0426 loss_train: 1.4667 acc_train: 0.4617 loss_val: 1.4637 acc_val: 0.4391 time: 0.0082s\n",
      "Epoch: 0427 loss_train: 1.4484 acc_train: 0.4825 loss_val: 1.4621 acc_val: 0.4391 time: 0.0085s\n",
      "Epoch: 0428 loss_train: 1.4587 acc_train: 0.4681 loss_val: 1.4604 acc_val: 0.4465 time: 0.0080s\n",
      "Epoch: 0429 loss_train: 1.4509 acc_train: 0.4723 loss_val: 1.4588 acc_val: 0.4502 time: 0.0080s\n",
      "Epoch: 0430 loss_train: 1.4595 acc_train: 0.4621 loss_val: 1.4572 acc_val: 0.4502 time: 0.0082s\n",
      "Epoch: 0431 loss_train: 1.4434 acc_train: 0.4912 loss_val: 1.4555 acc_val: 0.4502 time: 0.0084s\n",
      "Epoch: 0432 loss_train: 1.4631 acc_train: 0.4534 loss_val: 1.4539 acc_val: 0.4502 time: 0.0085s\n",
      "Epoch: 0433 loss_train: 1.4566 acc_train: 0.4603 loss_val: 1.4523 acc_val: 0.4539 time: 0.0078s\n",
      "Epoch: 0434 loss_train: 1.4621 acc_train: 0.4566 loss_val: 1.4507 acc_val: 0.4613 time: 0.0077s\n",
      "Epoch: 0435 loss_train: 1.4552 acc_train: 0.4885 loss_val: 1.4492 acc_val: 0.4613 time: 0.0076s\n",
      "Epoch: 0436 loss_train: 1.4502 acc_train: 0.4843 loss_val: 1.4476 acc_val: 0.4613 time: 0.0083s\n",
      "Epoch: 0437 loss_train: 1.4385 acc_train: 0.4880 loss_val: 1.4460 acc_val: 0.4613 time: 0.0082s\n",
      "Epoch: 0438 loss_train: 1.4479 acc_train: 0.4848 loss_val: 1.4444 acc_val: 0.4649 time: 0.0076s\n",
      "Epoch: 0439 loss_train: 1.4345 acc_train: 0.5180 loss_val: 1.4427 acc_val: 0.4686 time: 0.0078s\n",
      "Epoch: 0440 loss_train: 1.4426 acc_train: 0.4848 loss_val: 1.4411 acc_val: 0.4686 time: 0.0081s\n",
      "Epoch: 0441 loss_train: 1.4420 acc_train: 0.4991 loss_val: 1.4394 acc_val: 0.4686 time: 0.0083s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0442 loss_train: 1.4374 acc_train: 0.4898 loss_val: 1.4378 acc_val: 0.4686 time: 0.0084s\n",
      "Epoch: 0443 loss_train: 1.4379 acc_train: 0.5018 loss_val: 1.4361 acc_val: 0.4686 time: 0.0087s\n",
      "Epoch: 0444 loss_train: 1.4261 acc_train: 0.4991 loss_val: 1.4344 acc_val: 0.4686 time: 0.0077s\n",
      "Epoch: 0445 loss_train: 1.4260 acc_train: 0.4940 loss_val: 1.4327 acc_val: 0.4686 time: 0.0074s\n",
      "Epoch: 0446 loss_train: 1.4321 acc_train: 0.4972 loss_val: 1.4310 acc_val: 0.4686 time: 0.0072s\n",
      "Epoch: 0447 loss_train: 1.4351 acc_train: 0.4972 loss_val: 1.4292 acc_val: 0.4686 time: 0.0082s\n",
      "Epoch: 0448 loss_train: 1.4243 acc_train: 0.5162 loss_val: 1.4274 acc_val: 0.4723 time: 0.0081s\n",
      "Epoch: 0449 loss_train: 1.4181 acc_train: 0.5139 loss_val: 1.4257 acc_val: 0.4723 time: 0.0082s\n",
      "Epoch: 0450 loss_train: 1.4333 acc_train: 0.4889 loss_val: 1.4239 acc_val: 0.4797 time: 0.0078s\n",
      "Epoch: 0451 loss_train: 1.4036 acc_train: 0.5088 loss_val: 1.4222 acc_val: 0.4834 time: 0.0084s\n",
      "Epoch: 0452 loss_train: 1.4185 acc_train: 0.5143 loss_val: 1.4205 acc_val: 0.4834 time: 0.0083s\n",
      "Epoch: 0453 loss_train: 1.4151 acc_train: 0.5180 loss_val: 1.4189 acc_val: 0.4871 time: 0.0083s\n",
      "Epoch: 0454 loss_train: 1.4230 acc_train: 0.5199 loss_val: 1.4172 acc_val: 0.4871 time: 0.0087s\n",
      "Epoch: 0455 loss_train: 1.4217 acc_train: 0.5092 loss_val: 1.4155 acc_val: 0.4908 time: 0.0078s\n",
      "Epoch: 0456 loss_train: 1.4200 acc_train: 0.5088 loss_val: 1.4138 acc_val: 0.4982 time: 0.0074s\n",
      "Epoch: 0457 loss_train: 1.4136 acc_train: 0.5203 loss_val: 1.4121 acc_val: 0.5018 time: 0.0072s\n",
      "Epoch: 0458 loss_train: 1.4111 acc_train: 0.5074 loss_val: 1.4105 acc_val: 0.5018 time: 0.0083s\n",
      "Epoch: 0459 loss_train: 1.4019 acc_train: 0.5259 loss_val: 1.4088 acc_val: 0.5055 time: 0.0082s\n",
      "Epoch: 0460 loss_train: 1.4134 acc_train: 0.5194 loss_val: 1.4072 acc_val: 0.5092 time: 0.0079s\n",
      "Epoch: 0461 loss_train: 1.4009 acc_train: 0.5323 loss_val: 1.4055 acc_val: 0.5092 time: 0.0078s\n",
      "Epoch: 0462 loss_train: 1.3916 acc_train: 0.5416 loss_val: 1.4038 acc_val: 0.5129 time: 0.0083s\n",
      "Epoch: 0463 loss_train: 1.4176 acc_train: 0.5051 loss_val: 1.4022 acc_val: 0.5166 time: 0.0082s\n",
      "Epoch: 0464 loss_train: 1.3915 acc_train: 0.5425 loss_val: 1.4005 acc_val: 0.5166 time: 0.0090s\n",
      "Epoch: 0465 loss_train: 1.3806 acc_train: 0.5494 loss_val: 1.3989 acc_val: 0.5166 time: 0.0086s\n",
      "Epoch: 0466 loss_train: 1.3940 acc_train: 0.5249 loss_val: 1.3973 acc_val: 0.5166 time: 0.0077s\n",
      "Epoch: 0467 loss_train: 1.3945 acc_train: 0.5425 loss_val: 1.3956 acc_val: 0.5166 time: 0.0073s\n",
      "Epoch: 0468 loss_train: 1.4002 acc_train: 0.5235 loss_val: 1.3940 acc_val: 0.5166 time: 0.0072s\n",
      "Epoch: 0469 loss_train: 1.3796 acc_train: 0.5360 loss_val: 1.3923 acc_val: 0.5203 time: 0.0082s\n",
      "Epoch: 0470 loss_train: 1.3894 acc_train: 0.5434 loss_val: 1.3906 acc_val: 0.5240 time: 0.0081s\n",
      "Epoch: 0471 loss_train: 1.3769 acc_train: 0.5545 loss_val: 1.3889 acc_val: 0.5277 time: 0.0082s\n",
      "Epoch: 0472 loss_train: 1.3998 acc_train: 0.5374 loss_val: 1.3873 acc_val: 0.5277 time: 0.0078s\n",
      "Epoch: 0473 loss_train: 1.3847 acc_train: 0.5480 loss_val: 1.3856 acc_val: 0.5277 time: 0.0081s\n",
      "Epoch: 0474 loss_train: 1.3770 acc_train: 0.5416 loss_val: 1.3839 acc_val: 0.5314 time: 0.0083s\n",
      "Epoch: 0475 loss_train: 1.3765 acc_train: 0.5512 loss_val: 1.3822 acc_val: 0.5314 time: 0.0083s\n",
      "Epoch: 0476 loss_train: 1.3741 acc_train: 0.5471 loss_val: 1.3806 acc_val: 0.5314 time: 0.0086s\n",
      "Epoch: 0477 loss_train: 1.3710 acc_train: 0.5355 loss_val: 1.3789 acc_val: 0.5314 time: 0.0077s\n",
      "Epoch: 0478 loss_train: 1.3916 acc_train: 0.5425 loss_val: 1.3773 acc_val: 0.5314 time: 0.0074s\n",
      "Epoch: 0479 loss_train: 1.3767 acc_train: 0.5480 loss_val: 1.3756 acc_val: 0.5314 time: 0.0072s\n",
      "Epoch: 0480 loss_train: 1.3771 acc_train: 0.5563 loss_val: 1.3740 acc_val: 0.5314 time: 0.0083s\n",
      "Epoch: 0481 loss_train: 1.3657 acc_train: 0.5637 loss_val: 1.3723 acc_val: 0.5314 time: 0.0081s\n",
      "Epoch: 0482 loss_train: 1.3776 acc_train: 0.5619 loss_val: 1.3707 acc_val: 0.5314 time: 0.0082s\n",
      "Epoch: 0483 loss_train: 1.3722 acc_train: 0.5572 loss_val: 1.3691 acc_val: 0.5314 time: 0.0078s\n",
      "Epoch: 0484 loss_train: 1.3739 acc_train: 0.5416 loss_val: 1.3674 acc_val: 0.5387 time: 0.0085s\n",
      "Epoch: 0485 loss_train: 1.3787 acc_train: 0.5480 loss_val: 1.3658 acc_val: 0.5424 time: 0.0083s\n",
      "Epoch: 0486 loss_train: 1.3685 acc_train: 0.5559 loss_val: 1.3642 acc_val: 0.5461 time: 0.0091s\n",
      "Epoch: 0487 loss_train: 1.3542 acc_train: 0.5693 loss_val: 1.3625 acc_val: 0.5461 time: 0.0088s\n",
      "Epoch: 0488 loss_train: 1.3565 acc_train: 0.5517 loss_val: 1.3609 acc_val: 0.5572 time: 0.0078s\n",
      "Epoch: 0489 loss_train: 1.3572 acc_train: 0.5651 loss_val: 1.3592 acc_val: 0.5572 time: 0.0087s\n",
      "Epoch: 0490 loss_train: 1.3627 acc_train: 0.5512 loss_val: 1.3575 acc_val: 0.5572 time: 0.0084s\n",
      "Epoch: 0491 loss_train: 1.3605 acc_train: 0.5679 loss_val: 1.3559 acc_val: 0.5572 time: 0.0084s\n",
      "Epoch: 0492 loss_train: 1.3574 acc_train: 0.5688 loss_val: 1.3543 acc_val: 0.5572 time: 0.0084s\n",
      "Epoch: 0493 loss_train: 1.3607 acc_train: 0.5596 loss_val: 1.3527 acc_val: 0.5609 time: 0.0079s\n",
      "Epoch: 0494 loss_train: 1.3587 acc_train: 0.5554 loss_val: 1.3512 acc_val: 0.5646 time: 0.0075s\n",
      "Epoch: 0495 loss_train: 1.3524 acc_train: 0.5776 loss_val: 1.3496 acc_val: 0.5646 time: 0.0072s\n",
      "Epoch: 0496 loss_train: 1.3615 acc_train: 0.5697 loss_val: 1.3480 acc_val: 0.5646 time: 0.0082s\n",
      "Epoch: 0497 loss_train: 1.3439 acc_train: 0.5785 loss_val: 1.3465 acc_val: 0.5683 time: 0.0081s\n",
      "Epoch: 0498 loss_train: 1.3575 acc_train: 0.5757 loss_val: 1.3450 acc_val: 0.5720 time: 0.0082s\n",
      "Epoch: 0499 loss_train: 1.3405 acc_train: 0.5951 loss_val: 1.3435 acc_val: 0.5720 time: 0.0075s\n",
      "Epoch: 0500 loss_train: 1.3486 acc_train: 0.5822 loss_val: 1.3420 acc_val: 0.5720 time: 0.0086s\n",
      "Epoch: 0501 loss_train: 1.3377 acc_train: 0.5789 loss_val: 1.3405 acc_val: 0.5720 time: 0.0083s\n",
      "Epoch: 0502 loss_train: 1.3442 acc_train: 0.5697 loss_val: 1.3390 acc_val: 0.5720 time: 0.0085s\n",
      "Epoch: 0503 loss_train: 1.3271 acc_train: 0.6030 loss_val: 1.3375 acc_val: 0.5756 time: 0.0085s\n",
      "Epoch: 0504 loss_train: 1.3344 acc_train: 0.6103 loss_val: 1.3361 acc_val: 0.5756 time: 0.0080s\n",
      "Epoch: 0505 loss_train: 1.3229 acc_train: 0.5886 loss_val: 1.3346 acc_val: 0.5756 time: 0.0076s\n",
      "Epoch: 0506 loss_train: 1.3316 acc_train: 0.5693 loss_val: 1.3331 acc_val: 0.5756 time: 0.0072s\n",
      "Epoch: 0507 loss_train: 1.3471 acc_train: 0.5743 loss_val: 1.3316 acc_val: 0.5756 time: 0.0082s\n",
      "Epoch: 0508 loss_train: 1.3192 acc_train: 0.5937 loss_val: 1.3301 acc_val: 0.5756 time: 0.0089s\n",
      "Epoch: 0509 loss_train: 1.3160 acc_train: 0.6016 loss_val: 1.3286 acc_val: 0.5756 time: 0.0077s\n",
      "Epoch: 0510 loss_train: 1.3192 acc_train: 0.6076 loss_val: 1.3271 acc_val: 0.5756 time: 0.0078s\n",
      "Epoch: 0511 loss_train: 1.3071 acc_train: 0.6108 loss_val: 1.3256 acc_val: 0.5793 time: 0.0081s\n",
      "Epoch: 0512 loss_train: 1.3197 acc_train: 0.5951 loss_val: 1.3240 acc_val: 0.5867 time: 0.0083s\n",
      "Epoch: 0513 loss_train: 1.3257 acc_train: 0.5923 loss_val: 1.3224 acc_val: 0.5867 time: 0.0084s\n",
      "Epoch: 0514 loss_train: 1.3196 acc_train: 0.5863 loss_val: 1.3208 acc_val: 0.5904 time: 0.0086s\n",
      "Epoch: 0515 loss_train: 1.3176 acc_train: 0.6002 loss_val: 1.3192 acc_val: 0.5904 time: 0.0077s\n",
      "Epoch: 0516 loss_train: 1.3219 acc_train: 0.5900 loss_val: 1.3176 acc_val: 0.5941 time: 0.0075s\n",
      "Epoch: 0517 loss_train: 1.3140 acc_train: 0.6057 loss_val: 1.3160 acc_val: 0.5904 time: 0.0073s\n",
      "Epoch: 0518 loss_train: 1.3174 acc_train: 0.6103 loss_val: 1.3144 acc_val: 0.5941 time: 0.0082s\n",
      "Epoch: 0519 loss_train: 1.3183 acc_train: 0.6002 loss_val: 1.3128 acc_val: 0.5978 time: 0.0082s\n",
      "Epoch: 0520 loss_train: 1.3133 acc_train: 0.6131 loss_val: 1.3112 acc_val: 0.6015 time: 0.0081s\n",
      "Epoch: 0521 loss_train: 1.3079 acc_train: 0.6066 loss_val: 1.3095 acc_val: 0.6015 time: 0.0078s\n",
      "Epoch: 0522 loss_train: 1.3120 acc_train: 0.6043 loss_val: 1.3079 acc_val: 0.6015 time: 0.0081s\n",
      "Epoch: 0523 loss_train: 1.2922 acc_train: 0.6117 loss_val: 1.3063 acc_val: 0.6052 time: 0.0083s\n",
      "Epoch: 0524 loss_train: 1.2992 acc_train: 0.6071 loss_val: 1.3046 acc_val: 0.6089 time: 0.0084s\n",
      "Epoch: 0525 loss_train: 1.2999 acc_train: 0.6034 loss_val: 1.3030 acc_val: 0.6162 time: 0.0086s\n",
      "Epoch: 0526 loss_train: 1.2986 acc_train: 0.6251 loss_val: 1.3013 acc_val: 0.6199 time: 0.0078s\n",
      "Epoch: 0527 loss_train: 1.3093 acc_train: 0.5919 loss_val: 1.2997 acc_val: 0.6199 time: 0.0075s\n",
      "Epoch: 0528 loss_train: 1.2835 acc_train: 0.6293 loss_val: 1.2980 acc_val: 0.6199 time: 0.0072s\n",
      "Epoch: 0529 loss_train: 1.3078 acc_train: 0.6066 loss_val: 1.2965 acc_val: 0.6199 time: 0.0085s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0530 loss_train: 1.3015 acc_train: 0.6094 loss_val: 1.2949 acc_val: 0.6199 time: 0.0089s\n",
      "Epoch: 0531 loss_train: 1.2965 acc_train: 0.6066 loss_val: 1.2934 acc_val: 0.6199 time: 0.0076s\n",
      "Epoch: 0532 loss_train: 1.2777 acc_train: 0.6371 loss_val: 1.2919 acc_val: 0.6199 time: 0.0078s\n",
      "Epoch: 0533 loss_train: 1.2876 acc_train: 0.5974 loss_val: 1.2905 acc_val: 0.6199 time: 0.0083s\n",
      "Epoch: 0534 loss_train: 1.2926 acc_train: 0.6145 loss_val: 1.2890 acc_val: 0.6199 time: 0.0083s\n",
      "Epoch: 0535 loss_train: 1.2724 acc_train: 0.6265 loss_val: 1.2875 acc_val: 0.6199 time: 0.0083s\n",
      "Epoch: 0536 loss_train: 1.2903 acc_train: 0.6205 loss_val: 1.2861 acc_val: 0.6199 time: 0.0085s\n",
      "Epoch: 0537 loss_train: 1.2851 acc_train: 0.6219 loss_val: 1.2846 acc_val: 0.6199 time: 0.0078s\n",
      "Epoch: 0538 loss_train: 1.2805 acc_train: 0.6163 loss_val: 1.2832 acc_val: 0.6199 time: 0.0078s\n",
      "Epoch: 0539 loss_train: 1.2803 acc_train: 0.6122 loss_val: 1.2817 acc_val: 0.6199 time: 0.0076s\n",
      "Epoch: 0540 loss_train: 1.2878 acc_train: 0.6011 loss_val: 1.2804 acc_val: 0.6199 time: 0.0082s\n",
      "Epoch: 0541 loss_train: 1.2863 acc_train: 0.6196 loss_val: 1.2790 acc_val: 0.6199 time: 0.0081s\n",
      "Epoch: 0542 loss_train: 1.2776 acc_train: 0.6334 loss_val: 1.2777 acc_val: 0.6199 time: 0.0076s\n",
      "Epoch: 0543 loss_train: 1.2705 acc_train: 0.6357 loss_val: 1.2764 acc_val: 0.6199 time: 0.0079s\n",
      "Epoch: 0544 loss_train: 1.2801 acc_train: 0.6265 loss_val: 1.2751 acc_val: 0.6199 time: 0.0081s\n",
      "Epoch: 0545 loss_train: 1.2870 acc_train: 0.6163 loss_val: 1.2739 acc_val: 0.6199 time: 0.0083s\n",
      "Epoch: 0546 loss_train: 1.2784 acc_train: 0.6316 loss_val: 1.2726 acc_val: 0.6199 time: 0.0084s\n",
      "Epoch: 0547 loss_train: 1.2671 acc_train: 0.6260 loss_val: 1.2714 acc_val: 0.6199 time: 0.0086s\n",
      "Epoch: 0548 loss_train: 1.2742 acc_train: 0.6200 loss_val: 1.2701 acc_val: 0.6236 time: 0.0077s\n",
      "Epoch: 0549 loss_train: 1.2698 acc_train: 0.6256 loss_val: 1.2687 acc_val: 0.6310 time: 0.0087s\n",
      "Epoch: 0550 loss_train: 1.2699 acc_train: 0.6265 loss_val: 1.2673 acc_val: 0.6310 time: 0.0083s\n",
      "Epoch: 0551 loss_train: 1.2618 acc_train: 0.6385 loss_val: 1.2660 acc_val: 0.6310 time: 0.0084s\n",
      "Epoch: 0552 loss_train: 1.2480 acc_train: 0.6454 loss_val: 1.2646 acc_val: 0.6310 time: 0.0094s\n",
      "Epoch: 0553 loss_train: 1.2514 acc_train: 0.6353 loss_val: 1.2632 acc_val: 0.6310 time: 0.0077s\n",
      "Epoch: 0554 loss_train: 1.2584 acc_train: 0.6394 loss_val: 1.2617 acc_val: 0.6310 time: 0.0073s\n",
      "Epoch: 0555 loss_train: 1.2548 acc_train: 0.6288 loss_val: 1.2603 acc_val: 0.6310 time: 0.0072s\n",
      "Epoch: 0556 loss_train: 1.2438 acc_train: 0.6307 loss_val: 1.2588 acc_val: 0.6310 time: 0.0082s\n",
      "Epoch: 0557 loss_train: 1.2751 acc_train: 0.6131 loss_val: 1.2575 acc_val: 0.6310 time: 0.0081s\n",
      "Epoch: 0558 loss_train: 1.2493 acc_train: 0.6353 loss_val: 1.2560 acc_val: 0.6347 time: 0.0082s\n",
      "Epoch: 0559 loss_train: 1.2453 acc_train: 0.6500 loss_val: 1.2546 acc_val: 0.6384 time: 0.0078s\n",
      "Epoch: 0560 loss_train: 1.2439 acc_train: 0.6413 loss_val: 1.2532 acc_val: 0.6421 time: 0.0083s\n",
      "Epoch: 0561 loss_train: 1.2454 acc_train: 0.6362 loss_val: 1.2519 acc_val: 0.6421 time: 0.0083s\n",
      "Epoch: 0562 loss_train: 1.2636 acc_train: 0.6242 loss_val: 1.2506 acc_val: 0.6421 time: 0.0084s\n",
      "Epoch: 0563 loss_train: 1.2556 acc_train: 0.6265 loss_val: 1.2493 acc_val: 0.6421 time: 0.0086s\n",
      "Epoch: 0564 loss_train: 1.2474 acc_train: 0.6325 loss_val: 1.2481 acc_val: 0.6421 time: 0.0076s\n",
      "Epoch: 0565 loss_train: 1.2462 acc_train: 0.6496 loss_val: 1.2468 acc_val: 0.6421 time: 0.0075s\n",
      "Epoch: 0566 loss_train: 1.2505 acc_train: 0.6362 loss_val: 1.2457 acc_val: 0.6421 time: 0.0071s\n",
      "Epoch: 0567 loss_train: 1.2695 acc_train: 0.6357 loss_val: 1.2444 acc_val: 0.6421 time: 0.0081s\n",
      "Epoch: 0568 loss_train: 1.2423 acc_train: 0.6482 loss_val: 1.2431 acc_val: 0.6421 time: 0.0081s\n",
      "Epoch: 0569 loss_train: 1.2505 acc_train: 0.6339 loss_val: 1.2418 acc_val: 0.6421 time: 0.0082s\n",
      "Epoch: 0570 loss_train: 1.2482 acc_train: 0.6394 loss_val: 1.2405 acc_val: 0.6421 time: 0.0077s\n",
      "Epoch: 0571 loss_train: 1.2423 acc_train: 0.6417 loss_val: 1.2391 acc_val: 0.6421 time: 0.0082s\n",
      "Epoch: 0572 loss_train: 1.2447 acc_train: 0.6427 loss_val: 1.2378 acc_val: 0.6421 time: 0.0084s\n",
      "Epoch: 0573 loss_train: 1.2378 acc_train: 0.6339 loss_val: 1.2363 acc_val: 0.6421 time: 0.0083s\n",
      "Epoch: 0574 loss_train: 1.2192 acc_train: 0.6417 loss_val: 1.2349 acc_val: 0.6421 time: 0.0086s\n",
      "Epoch: 0575 loss_train: 1.2317 acc_train: 0.6464 loss_val: 1.2335 acc_val: 0.6421 time: 0.0085s\n",
      "Epoch: 0576 loss_train: 1.2395 acc_train: 0.6353 loss_val: 1.2320 acc_val: 0.6421 time: 0.0076s\n",
      "Epoch: 0577 loss_train: 1.2432 acc_train: 0.6311 loss_val: 1.2306 acc_val: 0.6421 time: 0.0076s\n",
      "Epoch: 0578 loss_train: 1.2293 acc_train: 0.6464 loss_val: 1.2291 acc_val: 0.6421 time: 0.0083s\n",
      "Epoch: 0579 loss_train: 1.2311 acc_train: 0.6445 loss_val: 1.2278 acc_val: 0.6421 time: 0.0082s\n",
      "Epoch: 0580 loss_train: 1.2127 acc_train: 0.6593 loss_val: 1.2263 acc_val: 0.6421 time: 0.0077s\n",
      "Epoch: 0581 loss_train: 1.2225 acc_train: 0.6427 loss_val: 1.2249 acc_val: 0.6421 time: 0.0081s\n",
      "Epoch: 0582 loss_train: 1.2292 acc_train: 0.6464 loss_val: 1.2236 acc_val: 0.6421 time: 0.0080s\n",
      "Epoch: 0583 loss_train: 1.2251 acc_train: 0.6422 loss_val: 1.2222 acc_val: 0.6421 time: 0.0082s\n",
      "Epoch: 0584 loss_train: 1.2247 acc_train: 0.6533 loss_val: 1.2208 acc_val: 0.6421 time: 0.0084s\n",
      "Epoch: 0585 loss_train: 1.2360 acc_train: 0.6357 loss_val: 1.2194 acc_val: 0.6421 time: 0.0086s\n",
      "Epoch: 0586 loss_train: 1.2140 acc_train: 0.6445 loss_val: 1.2181 acc_val: 0.6421 time: 0.0078s\n",
      "Epoch: 0587 loss_train: 1.2233 acc_train: 0.6459 loss_val: 1.2168 acc_val: 0.6421 time: 0.0080s\n",
      "Epoch: 0588 loss_train: 1.2108 acc_train: 0.6537 loss_val: 1.2156 acc_val: 0.6421 time: 0.0078s\n",
      "Epoch: 0589 loss_train: 1.2123 acc_train: 0.6399 loss_val: 1.2144 acc_val: 0.6421 time: 0.0082s\n",
      "Epoch: 0590 loss_train: 1.2097 acc_train: 0.6556 loss_val: 1.2132 acc_val: 0.6421 time: 0.0082s\n",
      "Epoch: 0591 loss_train: 1.2249 acc_train: 0.6427 loss_val: 1.2120 acc_val: 0.6421 time: 0.0078s\n",
      "Epoch: 0592 loss_train: 1.2039 acc_train: 0.6537 loss_val: 1.2108 acc_val: 0.6421 time: 0.0077s\n",
      "Epoch: 0593 loss_train: 1.1995 acc_train: 0.6579 loss_val: 1.2096 acc_val: 0.6421 time: 0.0080s\n",
      "Epoch: 0594 loss_train: 1.2015 acc_train: 0.6537 loss_val: 1.2084 acc_val: 0.6421 time: 0.0083s\n",
      "Epoch: 0595 loss_train: 1.2059 acc_train: 0.6459 loss_val: 1.2072 acc_val: 0.6421 time: 0.0083s\n",
      "Epoch: 0596 loss_train: 1.1970 acc_train: 0.6574 loss_val: 1.2060 acc_val: 0.6421 time: 0.0085s\n",
      "Epoch: 0597 loss_train: 1.2197 acc_train: 0.6454 loss_val: 1.2048 acc_val: 0.6421 time: 0.0081s\n",
      "Epoch: 0598 loss_train: 1.2319 acc_train: 0.6343 loss_val: 1.2036 acc_val: 0.6421 time: 0.0079s\n",
      "Epoch: 0599 loss_train: 1.2022 acc_train: 0.6524 loss_val: 1.2023 acc_val: 0.6458 time: 0.0079s\n",
      "Epoch: 0600 loss_train: 1.2094 acc_train: 0.6565 loss_val: 1.2011 acc_val: 0.6458 time: 0.0083s\n",
      "Epoch: 0601 loss_train: 1.2070 acc_train: 0.6477 loss_val: 1.1998 acc_val: 0.6458 time: 0.0083s\n",
      "Epoch: 0602 loss_train: 1.2093 acc_train: 0.6560 loss_val: 1.1986 acc_val: 0.6531 time: 0.0079s\n",
      "Epoch: 0603 loss_train: 1.1952 acc_train: 0.6560 loss_val: 1.1974 acc_val: 0.6531 time: 0.0078s\n",
      "Epoch: 0604 loss_train: 1.1969 acc_train: 0.6708 loss_val: 1.1963 acc_val: 0.6531 time: 0.0079s\n",
      "Epoch: 0605 loss_train: 1.1988 acc_train: 0.6699 loss_val: 1.1951 acc_val: 0.6531 time: 0.0082s\n",
      "Epoch: 0606 loss_train: 1.1934 acc_train: 0.6487 loss_val: 1.1939 acc_val: 0.6568 time: 0.0083s\n",
      "Epoch: 0607 loss_train: 1.1878 acc_train: 0.6616 loss_val: 1.1928 acc_val: 0.6605 time: 0.0085s\n",
      "Epoch: 0608 loss_train: 1.1902 acc_train: 0.6588 loss_val: 1.1916 acc_val: 0.6605 time: 0.0077s\n",
      "Epoch: 0609 loss_train: 1.1898 acc_train: 0.6597 loss_val: 1.1904 acc_val: 0.6642 time: 0.0084s\n",
      "Epoch: 0610 loss_train: 1.1990 acc_train: 0.6537 loss_val: 1.1893 acc_val: 0.6679 time: 0.0082s\n",
      "Epoch: 0611 loss_train: 1.1780 acc_train: 0.6685 loss_val: 1.1880 acc_val: 0.6716 time: 0.0083s\n",
      "Epoch: 0612 loss_train: 1.1842 acc_train: 0.6722 loss_val: 1.1869 acc_val: 0.6716 time: 0.0087s\n",
      "Epoch: 0613 loss_train: 1.1833 acc_train: 0.6588 loss_val: 1.1857 acc_val: 0.6716 time: 0.0076s\n",
      "Epoch: 0614 loss_train: 1.1853 acc_train: 0.6565 loss_val: 1.1844 acc_val: 0.6716 time: 0.0073s\n",
      "Epoch: 0615 loss_train: 1.1836 acc_train: 0.6717 loss_val: 1.1831 acc_val: 0.6716 time: 0.0072s\n",
      "Epoch: 0616 loss_train: 1.1887 acc_train: 0.6620 loss_val: 1.1818 acc_val: 0.6716 time: 0.0083s\n",
      "Epoch: 0617 loss_train: 1.1819 acc_train: 0.6537 loss_val: 1.1804 acc_val: 0.6753 time: 0.0082s\n",
      "Epoch: 0618 loss_train: 1.1872 acc_train: 0.6653 loss_val: 1.1792 acc_val: 0.6753 time: 0.0082s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0619 loss_train: 1.1904 acc_train: 0.6565 loss_val: 1.1779 acc_val: 0.6753 time: 0.0081s\n",
      "Epoch: 0620 loss_train: 1.1978 acc_train: 0.6704 loss_val: 1.1766 acc_val: 0.6753 time: 0.0082s\n",
      "Epoch: 0621 loss_train: 1.1819 acc_train: 0.6616 loss_val: 1.1754 acc_val: 0.6753 time: 0.0083s\n",
      "Epoch: 0622 loss_train: 1.1953 acc_train: 0.6662 loss_val: 1.1743 acc_val: 0.6753 time: 0.0085s\n",
      "Epoch: 0623 loss_train: 1.1819 acc_train: 0.6745 loss_val: 1.1732 acc_val: 0.6753 time: 0.0087s\n",
      "Epoch: 0624 loss_train: 1.1970 acc_train: 0.6510 loss_val: 1.1721 acc_val: 0.6753 time: 0.0076s\n",
      "Epoch: 0625 loss_train: 1.1846 acc_train: 0.6537 loss_val: 1.1710 acc_val: 0.6753 time: 0.0074s\n",
      "Epoch: 0626 loss_train: 1.1900 acc_train: 0.6524 loss_val: 1.1699 acc_val: 0.6753 time: 0.0072s\n",
      "Epoch: 0627 loss_train: 1.1759 acc_train: 0.6676 loss_val: 1.1689 acc_val: 0.6753 time: 0.0082s\n",
      "Epoch: 0628 loss_train: 1.1711 acc_train: 0.6777 loss_val: 1.1678 acc_val: 0.6753 time: 0.0081s\n",
      "Epoch: 0629 loss_train: 1.1507 acc_train: 0.6722 loss_val: 1.1668 acc_val: 0.6753 time: 0.0082s\n",
      "Epoch: 0630 loss_train: 1.1805 acc_train: 0.6667 loss_val: 1.1657 acc_val: 0.6753 time: 0.0079s\n",
      "Epoch: 0631 loss_train: 1.1691 acc_train: 0.6676 loss_val: 1.1646 acc_val: 0.6753 time: 0.0083s\n",
      "Epoch: 0632 loss_train: 1.1820 acc_train: 0.6482 loss_val: 1.1635 acc_val: 0.6753 time: 0.0082s\n",
      "Epoch: 0633 loss_train: 1.1572 acc_train: 0.6930 loss_val: 1.1624 acc_val: 0.6753 time: 0.0084s\n",
      "Epoch: 0634 loss_train: 1.1495 acc_train: 0.6708 loss_val: 1.1614 acc_val: 0.6753 time: 0.0086s\n",
      "Epoch: 0635 loss_train: 1.1631 acc_train: 0.6690 loss_val: 1.1603 acc_val: 0.6753 time: 0.0076s\n",
      "Epoch: 0636 loss_train: 1.1578 acc_train: 0.6731 loss_val: 1.1592 acc_val: 0.6753 time: 0.0074s\n",
      "Epoch: 0637 loss_train: 1.1656 acc_train: 0.6574 loss_val: 1.1582 acc_val: 0.6790 time: 0.0072s\n",
      "Epoch: 0638 loss_train: 1.1710 acc_train: 0.6676 loss_val: 1.1570 acc_val: 0.6790 time: 0.0082s\n",
      "Epoch: 0639 loss_train: 1.1426 acc_train: 0.6819 loss_val: 1.1559 acc_val: 0.6790 time: 0.0080s\n",
      "Epoch: 0640 loss_train: 1.1720 acc_train: 0.6588 loss_val: 1.1548 acc_val: 0.6790 time: 0.0083s\n",
      "Epoch: 0641 loss_train: 1.1696 acc_train: 0.6704 loss_val: 1.1537 acc_val: 0.6790 time: 0.0081s\n",
      "Epoch: 0642 loss_train: 1.1685 acc_train: 0.6681 loss_val: 1.1526 acc_val: 0.6790 time: 0.0082s\n",
      "Epoch: 0643 loss_train: 1.1586 acc_train: 0.6819 loss_val: 1.1516 acc_val: 0.6790 time: 0.0083s\n",
      "Epoch: 0644 loss_train: 1.1543 acc_train: 0.6745 loss_val: 1.1505 acc_val: 0.6790 time: 0.0084s\n",
      "Epoch: 0645 loss_train: 1.1607 acc_train: 0.6648 loss_val: 1.1495 acc_val: 0.6790 time: 0.0087s\n",
      "Epoch: 0646 loss_train: 1.1515 acc_train: 0.6717 loss_val: 1.1485 acc_val: 0.6790 time: 0.0077s\n",
      "Epoch: 0647 loss_train: 1.1539 acc_train: 0.6796 loss_val: 1.1475 acc_val: 0.6790 time: 0.0074s\n",
      "Epoch: 0648 loss_train: 1.1443 acc_train: 0.6694 loss_val: 1.1465 acc_val: 0.6790 time: 0.0072s\n",
      "Epoch: 0649 loss_train: 1.1455 acc_train: 0.6833 loss_val: 1.1455 acc_val: 0.6790 time: 0.0082s\n",
      "Epoch: 0650 loss_train: 1.1403 acc_train: 0.6851 loss_val: 1.1445 acc_val: 0.6790 time: 0.0082s\n",
      "Epoch: 0651 loss_train: 1.1407 acc_train: 0.6861 loss_val: 1.1434 acc_val: 0.6790 time: 0.0083s\n",
      "Epoch: 0652 loss_train: 1.1570 acc_train: 0.6722 loss_val: 1.1424 acc_val: 0.6790 time: 0.0078s\n",
      "Epoch: 0653 loss_train: 1.1369 acc_train: 0.6921 loss_val: 1.1413 acc_val: 0.6790 time: 0.0082s\n",
      "Epoch: 0654 loss_train: 1.1415 acc_train: 0.6791 loss_val: 1.1402 acc_val: 0.6790 time: 0.0083s\n",
      "Epoch: 0655 loss_train: 1.1566 acc_train: 0.6722 loss_val: 1.1390 acc_val: 0.6790 time: 0.0084s\n",
      "Epoch: 0656 loss_train: 1.1333 acc_train: 0.6898 loss_val: 1.1379 acc_val: 0.6790 time: 0.0086s\n",
      "Epoch: 0657 loss_train: 1.1306 acc_train: 0.6791 loss_val: 1.1369 acc_val: 0.6790 time: 0.0076s\n",
      "Epoch: 0658 loss_train: 1.1360 acc_train: 0.6713 loss_val: 1.1358 acc_val: 0.6790 time: 0.0074s\n",
      "Epoch: 0659 loss_train: 1.1366 acc_train: 0.6579 loss_val: 1.1348 acc_val: 0.6790 time: 0.0072s\n",
      "Epoch: 0660 loss_train: 1.1408 acc_train: 0.6727 loss_val: 1.1337 acc_val: 0.6790 time: 0.0083s\n",
      "Epoch: 0661 loss_train: 1.1406 acc_train: 0.6801 loss_val: 1.1326 acc_val: 0.6790 time: 0.0081s\n",
      "Epoch: 0662 loss_train: 1.1427 acc_train: 0.6847 loss_val: 1.1316 acc_val: 0.6790 time: 0.0083s\n",
      "Epoch: 0663 loss_train: 1.1393 acc_train: 0.6731 loss_val: 1.1305 acc_val: 0.6790 time: 0.0078s\n",
      "Epoch: 0664 loss_train: 1.1453 acc_train: 0.6681 loss_val: 1.1295 acc_val: 0.6827 time: 0.0091s\n",
      "Epoch: 0665 loss_train: 1.1302 acc_train: 0.6847 loss_val: 1.1284 acc_val: 0.6827 time: 0.0083s\n",
      "Epoch: 0666 loss_train: 1.1274 acc_train: 0.6828 loss_val: 1.1274 acc_val: 0.6827 time: 0.0082s\n",
      "Epoch: 0667 loss_train: 1.1313 acc_train: 0.6916 loss_val: 1.1263 acc_val: 0.6827 time: 0.0085s\n",
      "Epoch: 0668 loss_train: 1.1219 acc_train: 0.6990 loss_val: 1.1254 acc_val: 0.6827 time: 0.0076s\n",
      "Epoch: 0669 loss_train: 1.1490 acc_train: 0.6773 loss_val: 1.1244 acc_val: 0.6827 time: 0.0083s\n",
      "Epoch: 0670 loss_train: 1.1408 acc_train: 0.6916 loss_val: 1.1234 acc_val: 0.6827 time: 0.0083s\n",
      "Epoch: 0671 loss_train: 1.1254 acc_train: 0.6824 loss_val: 1.1225 acc_val: 0.6827 time: 0.0085s\n",
      "Epoch: 0672 loss_train: 1.1327 acc_train: 0.6741 loss_val: 1.1216 acc_val: 0.6827 time: 0.0086s\n",
      "Epoch: 0673 loss_train: 1.1209 acc_train: 0.6958 loss_val: 1.1206 acc_val: 0.6827 time: 0.0080s\n",
      "Epoch: 0674 loss_train: 1.1482 acc_train: 0.6768 loss_val: 1.1196 acc_val: 0.6827 time: 0.0075s\n",
      "Epoch: 0675 loss_train: 1.1232 acc_train: 0.6902 loss_val: 1.1186 acc_val: 0.6827 time: 0.0072s\n",
      "Epoch: 0676 loss_train: 1.1182 acc_train: 0.6685 loss_val: 1.1176 acc_val: 0.6827 time: 0.0083s\n",
      "Epoch: 0677 loss_train: 1.1163 acc_train: 0.6958 loss_val: 1.1166 acc_val: 0.6827 time: 0.0082s\n",
      "Epoch: 0678 loss_train: 1.1104 acc_train: 0.6898 loss_val: 1.1156 acc_val: 0.6827 time: 0.0082s\n",
      "Epoch: 0679 loss_train: 1.1184 acc_train: 0.6902 loss_val: 1.1145 acc_val: 0.6827 time: 0.0079s\n",
      "Epoch: 0680 loss_train: 1.1152 acc_train: 0.6870 loss_val: 1.1134 acc_val: 0.6863 time: 0.0082s\n",
      "Epoch: 0681 loss_train: 1.1158 acc_train: 0.6976 loss_val: 1.1123 acc_val: 0.6863 time: 0.0084s\n",
      "Epoch: 0682 loss_train: 1.1296 acc_train: 0.6722 loss_val: 1.1112 acc_val: 0.6900 time: 0.0084s\n",
      "Epoch: 0683 loss_train: 1.0918 acc_train: 0.6981 loss_val: 1.1101 acc_val: 0.6900 time: 0.0087s\n",
      "Epoch: 0684 loss_train: 1.1126 acc_train: 0.6870 loss_val: 1.1089 acc_val: 0.6900 time: 0.0077s\n",
      "Epoch: 0685 loss_train: 1.0954 acc_train: 0.6879 loss_val: 1.1079 acc_val: 0.6937 time: 0.0073s\n",
      "Epoch: 0686 loss_train: 1.1204 acc_train: 0.7004 loss_val: 1.1068 acc_val: 0.6937 time: 0.0079s\n",
      "Epoch: 0687 loss_train: 1.1081 acc_train: 0.6934 loss_val: 1.1058 acc_val: 0.6937 time: 0.0083s\n",
      "Epoch: 0688 loss_train: 1.1223 acc_train: 0.6824 loss_val: 1.1047 acc_val: 0.6937 time: 0.0082s\n",
      "Epoch: 0689 loss_train: 1.1032 acc_train: 0.6842 loss_val: 1.1037 acc_val: 0.6937 time: 0.0078s\n",
      "Epoch: 0690 loss_train: 1.0954 acc_train: 0.7050 loss_val: 1.1026 acc_val: 0.6937 time: 0.0078s\n",
      "Epoch: 0691 loss_train: 1.1181 acc_train: 0.6944 loss_val: 1.1017 acc_val: 0.6937 time: 0.0081s\n",
      "Epoch: 0692 loss_train: 1.1036 acc_train: 0.6731 loss_val: 1.1008 acc_val: 0.6937 time: 0.0083s\n",
      "Epoch: 0693 loss_train: 1.1152 acc_train: 0.6870 loss_val: 1.1000 acc_val: 0.6937 time: 0.0083s\n",
      "Epoch: 0694 loss_train: 1.1014 acc_train: 0.7045 loss_val: 1.0991 acc_val: 0.6937 time: 0.0087s\n",
      "Epoch: 0695 loss_train: 1.1203 acc_train: 0.6837 loss_val: 1.0982 acc_val: 0.6937 time: 0.0076s\n",
      "Epoch: 0696 loss_train: 1.1136 acc_train: 0.6814 loss_val: 1.0974 acc_val: 0.6937 time: 0.0075s\n",
      "Epoch: 0697 loss_train: 1.0837 acc_train: 0.7013 loss_val: 1.0965 acc_val: 0.6974 time: 0.0072s\n",
      "Epoch: 0698 loss_train: 1.0890 acc_train: 0.6907 loss_val: 1.0956 acc_val: 0.7011 time: 0.0082s\n",
      "Epoch: 0699 loss_train: 1.1130 acc_train: 0.6925 loss_val: 1.0947 acc_val: 0.7011 time: 0.0082s\n",
      "Epoch: 0700 loss_train: 1.0893 acc_train: 0.6948 loss_val: 1.0939 acc_val: 0.7011 time: 0.0081s\n",
      "Epoch: 0701 loss_train: 1.0948 acc_train: 0.7031 loss_val: 1.0930 acc_val: 0.7011 time: 0.0078s\n",
      "Epoch: 0702 loss_train: 1.0983 acc_train: 0.6999 loss_val: 1.0922 acc_val: 0.7011 time: 0.0082s\n",
      "Epoch: 0703 loss_train: 1.1035 acc_train: 0.7045 loss_val: 1.0913 acc_val: 0.7048 time: 0.0083s\n",
      "Epoch: 0704 loss_train: 1.0831 acc_train: 0.7064 loss_val: 1.0905 acc_val: 0.7048 time: 0.0085s\n",
      "Epoch: 0705 loss_train: 1.1062 acc_train: 0.6893 loss_val: 1.0896 acc_val: 0.7048 time: 0.0086s\n",
      "Epoch: 0706 loss_train: 1.0804 acc_train: 0.7027 loss_val: 1.0887 acc_val: 0.7048 time: 0.0077s\n",
      "Epoch: 0707 loss_train: 1.0783 acc_train: 0.7013 loss_val: 1.0878 acc_val: 0.7048 time: 0.0074s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0708 loss_train: 1.0936 acc_train: 0.6994 loss_val: 1.0869 acc_val: 0.7048 time: 0.0078s\n",
      "Epoch: 0709 loss_train: 1.0861 acc_train: 0.6888 loss_val: 1.0861 acc_val: 0.7048 time: 0.0083s\n",
      "Epoch: 0710 loss_train: 1.0715 acc_train: 0.7124 loss_val: 1.0851 acc_val: 0.7048 time: 0.0082s\n",
      "Epoch: 0711 loss_train: 1.0974 acc_train: 0.6870 loss_val: 1.0842 acc_val: 0.7048 time: 0.0080s\n",
      "Epoch: 0712 loss_train: 1.0930 acc_train: 0.6921 loss_val: 1.0832 acc_val: 0.7048 time: 0.0078s\n",
      "Epoch: 0713 loss_train: 1.0640 acc_train: 0.7050 loss_val: 1.0822 acc_val: 0.7048 time: 0.0081s\n",
      "Epoch: 0714 loss_train: 1.0915 acc_train: 0.6948 loss_val: 1.0812 acc_val: 0.7048 time: 0.0083s\n",
      "Epoch: 0715 loss_train: 1.0708 acc_train: 0.6990 loss_val: 1.0802 acc_val: 0.7085 time: 0.0084s\n",
      "Epoch: 0716 loss_train: 1.0941 acc_train: 0.6741 loss_val: 1.0792 acc_val: 0.7085 time: 0.0087s\n",
      "Epoch: 0717 loss_train: 1.1044 acc_train: 0.6833 loss_val: 1.0783 acc_val: 0.7085 time: 0.0077s\n",
      "Epoch: 0718 loss_train: 1.0602 acc_train: 0.7114 loss_val: 1.0774 acc_val: 0.7085 time: 0.0074s\n",
      "Epoch: 0719 loss_train: 1.0809 acc_train: 0.6911 loss_val: 1.0764 acc_val: 0.7085 time: 0.0072s\n",
      "Epoch: 0720 loss_train: 1.0890 acc_train: 0.6976 loss_val: 1.0755 acc_val: 0.7085 time: 0.0083s\n",
      "Epoch: 0721 loss_train: 1.0817 acc_train: 0.6944 loss_val: 1.0746 acc_val: 0.7085 time: 0.0082s\n",
      "Epoch: 0722 loss_train: 1.0694 acc_train: 0.7082 loss_val: 1.0737 acc_val: 0.7122 time: 0.0083s\n",
      "Epoch: 0723 loss_train: 1.0602 acc_train: 0.6990 loss_val: 1.0728 acc_val: 0.7122 time: 0.0078s\n",
      "Epoch: 0724 loss_train: 1.0759 acc_train: 0.7036 loss_val: 1.0718 acc_val: 0.7122 time: 0.0083s\n",
      "Epoch: 0725 loss_train: 1.0905 acc_train: 0.6851 loss_val: 1.0709 acc_val: 0.7159 time: 0.0083s\n",
      "Epoch: 0726 loss_train: 1.0924 acc_train: 0.6865 loss_val: 1.0699 acc_val: 0.7159 time: 0.0084s\n",
      "Epoch: 0727 loss_train: 1.0654 acc_train: 0.7073 loss_val: 1.0690 acc_val: 0.7159 time: 0.0085s\n",
      "Epoch: 0728 loss_train: 1.0629 acc_train: 0.7082 loss_val: 1.0681 acc_val: 0.7159 time: 0.0078s\n",
      "Epoch: 0729 loss_train: 1.0700 acc_train: 0.7087 loss_val: 1.0672 acc_val: 0.7159 time: 0.0083s\n",
      "Epoch: 0730 loss_train: 1.0819 acc_train: 0.6999 loss_val: 1.0663 acc_val: 0.7196 time: 0.0090s\n",
      "Epoch: 0731 loss_train: 1.0644 acc_train: 0.7082 loss_val: 1.0655 acc_val: 0.7196 time: 0.0085s\n",
      "Epoch: 0732 loss_train: 1.0744 acc_train: 0.7087 loss_val: 1.0646 acc_val: 0.7196 time: 0.0085s\n",
      "Epoch: 0733 loss_train: 1.0750 acc_train: 0.6953 loss_val: 1.0638 acc_val: 0.7196 time: 0.0079s\n",
      "Epoch: 0734 loss_train: 1.0583 acc_train: 0.7073 loss_val: 1.0629 acc_val: 0.7196 time: 0.0075s\n",
      "Epoch: 0735 loss_train: 1.0659 acc_train: 0.7031 loss_val: 1.0621 acc_val: 0.7196 time: 0.0073s\n",
      "Epoch: 0736 loss_train: 1.0517 acc_train: 0.7179 loss_val: 1.0612 acc_val: 0.7159 time: 0.0080s\n",
      "Epoch: 0737 loss_train: 1.0550 acc_train: 0.7128 loss_val: 1.0604 acc_val: 0.7159 time: 0.0082s\n",
      "Epoch: 0738 loss_train: 1.0769 acc_train: 0.7027 loss_val: 1.0595 acc_val: 0.7159 time: 0.0085s\n",
      "Epoch: 0739 loss_train: 1.0634 acc_train: 0.7073 loss_val: 1.0587 acc_val: 0.7159 time: 0.0075s\n",
      "Epoch: 0740 loss_train: 1.0685 acc_train: 0.7041 loss_val: 1.0579 acc_val: 0.7159 time: 0.0086s\n",
      "Epoch: 0741 loss_train: 1.0705 acc_train: 0.7087 loss_val: 1.0571 acc_val: 0.7159 time: 0.0083s\n",
      "Epoch: 0742 loss_train: 1.0642 acc_train: 0.7004 loss_val: 1.0564 acc_val: 0.7159 time: 0.0084s\n",
      "Epoch: 0743 loss_train: 1.0618 acc_train: 0.7068 loss_val: 1.0555 acc_val: 0.7159 time: 0.0082s\n",
      "Epoch: 0744 loss_train: 1.0602 acc_train: 0.6999 loss_val: 1.0546 acc_val: 0.7159 time: 0.0076s\n",
      "Epoch: 0745 loss_train: 1.0373 acc_train: 0.7202 loss_val: 1.0537 acc_val: 0.7159 time: 0.0074s\n",
      "Epoch: 0746 loss_train: 1.0738 acc_train: 0.7073 loss_val: 1.0529 acc_val: 0.7159 time: 0.0077s\n",
      "Epoch: 0747 loss_train: 1.0575 acc_train: 0.6981 loss_val: 1.0520 acc_val: 0.7159 time: 0.0083s\n",
      "Epoch: 0748 loss_train: 1.0463 acc_train: 0.7128 loss_val: 1.0511 acc_val: 0.7159 time: 0.0083s\n",
      "Epoch: 0749 loss_train: 1.0498 acc_train: 0.6958 loss_val: 1.0503 acc_val: 0.7159 time: 0.0087s\n",
      "Epoch: 0750 loss_train: 1.0395 acc_train: 0.7216 loss_val: 1.0494 acc_val: 0.7159 time: 0.0076s\n",
      "Epoch: 0751 loss_train: 1.0418 acc_train: 0.7184 loss_val: 1.0485 acc_val: 0.7196 time: 0.0082s\n",
      "Epoch: 0752 loss_train: 1.0597 acc_train: 0.7004 loss_val: 1.0477 acc_val: 0.7196 time: 0.0085s\n",
      "Epoch: 0753 loss_train: 1.0396 acc_train: 0.7124 loss_val: 1.0468 acc_val: 0.7196 time: 0.0084s\n",
      "Epoch: 0754 loss_train: 1.0605 acc_train: 0.7004 loss_val: 1.0460 acc_val: 0.7232 time: 0.0082s\n",
      "Epoch: 0755 loss_train: 1.0614 acc_train: 0.7235 loss_val: 1.0452 acc_val: 0.7232 time: 0.0079s\n",
      "Epoch: 0756 loss_train: 1.0541 acc_train: 0.7101 loss_val: 1.0445 acc_val: 0.7232 time: 0.0077s\n",
      "Epoch: 0757 loss_train: 1.0417 acc_train: 0.7110 loss_val: 1.0437 acc_val: 0.7232 time: 0.0078s\n",
      "Epoch: 0758 loss_train: 1.0526 acc_train: 0.7114 loss_val: 1.0430 acc_val: 0.7232 time: 0.0081s\n",
      "Epoch: 0759 loss_train: 1.0443 acc_train: 0.7156 loss_val: 1.0423 acc_val: 0.7232 time: 0.0083s\n",
      "Epoch: 0760 loss_train: 1.0511 acc_train: 0.7304 loss_val: 1.0415 acc_val: 0.7196 time: 0.0085s\n",
      "Epoch: 0761 loss_train: 1.0345 acc_train: 0.7244 loss_val: 1.0407 acc_val: 0.7196 time: 0.0078s\n",
      "Epoch: 0762 loss_train: 1.0517 acc_train: 0.6990 loss_val: 1.0400 acc_val: 0.7196 time: 0.0078s\n",
      "Epoch: 0763 loss_train: 1.0502 acc_train: 0.7110 loss_val: 1.0392 acc_val: 0.7196 time: 0.0078s\n",
      "Epoch: 0764 loss_train: 1.0420 acc_train: 0.6985 loss_val: 1.0385 acc_val: 0.7269 time: 0.0083s\n",
      "Epoch: 0765 loss_train: 1.0264 acc_train: 0.7188 loss_val: 1.0377 acc_val: 0.7269 time: 0.0083s\n",
      "Epoch: 0766 loss_train: 1.0250 acc_train: 0.7133 loss_val: 1.0369 acc_val: 0.7269 time: 0.0078s\n",
      "Epoch: 0767 loss_train: 1.0393 acc_train: 0.7031 loss_val: 1.0361 acc_val: 0.7269 time: 0.0078s\n",
      "Epoch: 0768 loss_train: 1.0443 acc_train: 0.7114 loss_val: 1.0352 acc_val: 0.7306 time: 0.0080s\n",
      "Epoch: 0769 loss_train: 1.0325 acc_train: 0.7151 loss_val: 1.0343 acc_val: 0.7343 time: 0.0082s\n",
      "Epoch: 0770 loss_train: 1.0355 acc_train: 0.7276 loss_val: 1.0335 acc_val: 0.7306 time: 0.0085s\n",
      "Epoch: 0771 loss_train: 1.0393 acc_train: 0.7179 loss_val: 1.0326 acc_val: 0.7306 time: 0.0086s\n",
      "Epoch: 0772 loss_train: 1.0443 acc_train: 0.6976 loss_val: 1.0317 acc_val: 0.7306 time: 0.0077s\n",
      "Epoch: 0773 loss_train: 1.0337 acc_train: 0.7248 loss_val: 1.0309 acc_val: 0.7306 time: 0.0077s\n",
      "Epoch: 0774 loss_train: 1.0413 acc_train: 0.7170 loss_val: 1.0300 acc_val: 0.7306 time: 0.0081s\n",
      "Epoch: 0775 loss_train: 1.0200 acc_train: 0.7262 loss_val: 1.0292 acc_val: 0.7306 time: 0.0084s\n",
      "Epoch: 0776 loss_train: 1.0400 acc_train: 0.7114 loss_val: 1.0283 acc_val: 0.7306 time: 0.0083s\n",
      "Epoch: 0777 loss_train: 1.0113 acc_train: 0.7322 loss_val: 1.0274 acc_val: 0.7343 time: 0.0079s\n",
      "Epoch: 0778 loss_train: 1.0337 acc_train: 0.7221 loss_val: 1.0265 acc_val: 0.7343 time: 0.0078s\n",
      "Epoch: 0779 loss_train: 1.0361 acc_train: 0.7124 loss_val: 1.0256 acc_val: 0.7380 time: 0.0116s\n",
      "Epoch: 0780 loss_train: 1.0131 acc_train: 0.7147 loss_val: 1.0247 acc_val: 0.7417 time: 0.0084s\n",
      "Epoch: 0781 loss_train: 1.0384 acc_train: 0.7207 loss_val: 1.0239 acc_val: 0.7417 time: 0.0082s\n",
      "Epoch: 0782 loss_train: 1.0193 acc_train: 0.7331 loss_val: 1.0232 acc_val: 0.7417 time: 0.0078s\n",
      "Epoch: 0783 loss_train: 1.0234 acc_train: 0.7281 loss_val: 1.0224 acc_val: 0.7417 time: 0.0078s\n",
      "Epoch: 0784 loss_train: 1.0245 acc_train: 0.7151 loss_val: 1.0217 acc_val: 0.7454 time: 0.0081s\n",
      "Epoch: 0785 loss_train: 1.0335 acc_train: 0.7138 loss_val: 1.0209 acc_val: 0.7491 time: 0.0083s\n",
      "Epoch: 0786 loss_train: 1.0357 acc_train: 0.7193 loss_val: 1.0202 acc_val: 0.7491 time: 0.0085s\n",
      "Epoch: 0787 loss_train: 1.0264 acc_train: 0.7082 loss_val: 1.0194 acc_val: 0.7491 time: 0.0086s\n",
      "Epoch: 0788 loss_train: 1.0112 acc_train: 0.7170 loss_val: 1.0187 acc_val: 0.7491 time: 0.0077s\n",
      "Epoch: 0789 loss_train: 1.0133 acc_train: 0.7290 loss_val: 1.0179 acc_val: 0.7491 time: 0.0086s\n",
      "Epoch: 0790 loss_train: 1.0208 acc_train: 0.7211 loss_val: 1.0171 acc_val: 0.7491 time: 0.0083s\n",
      "Epoch: 0791 loss_train: 1.0180 acc_train: 0.7345 loss_val: 1.0163 acc_val: 0.7491 time: 0.0084s\n",
      "Epoch: 0792 loss_train: 1.0131 acc_train: 0.7290 loss_val: 1.0156 acc_val: 0.7491 time: 0.0086s\n",
      "Epoch: 0793 loss_train: 1.0038 acc_train: 0.7262 loss_val: 1.0148 acc_val: 0.7491 time: 0.0079s\n",
      "Epoch: 0794 loss_train: 0.9929 acc_train: 0.7318 loss_val: 1.0140 acc_val: 0.7491 time: 0.0074s\n",
      "Epoch: 0795 loss_train: 1.0315 acc_train: 0.7142 loss_val: 1.0132 acc_val: 0.7491 time: 0.0073s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0796 loss_train: 1.0152 acc_train: 0.7230 loss_val: 1.0124 acc_val: 0.7491 time: 0.0088s\n",
      "Epoch: 0797 loss_train: 1.0277 acc_train: 0.7239 loss_val: 1.0117 acc_val: 0.7491 time: 0.0082s\n",
      "Epoch: 0798 loss_train: 1.0195 acc_train: 0.7096 loss_val: 1.0109 acc_val: 0.7491 time: 0.0083s\n",
      "Epoch: 0799 loss_train: 1.0157 acc_train: 0.7336 loss_val: 1.0100 acc_val: 0.7528 time: 0.0078s\n",
      "Epoch: 0800 loss_train: 1.0285 acc_train: 0.7244 loss_val: 1.0093 acc_val: 0.7565 time: 0.0082s\n",
      "Epoch: 0801 loss_train: 1.0142 acc_train: 0.7281 loss_val: 1.0085 acc_val: 0.7565 time: 0.0082s\n",
      "Epoch: 0802 loss_train: 1.0232 acc_train: 0.7147 loss_val: 1.0077 acc_val: 0.7601 time: 0.0084s\n",
      "Epoch: 0803 loss_train: 1.0283 acc_train: 0.7138 loss_val: 1.0071 acc_val: 0.7601 time: 0.0087s\n",
      "Epoch: 0804 loss_train: 0.9896 acc_train: 0.7442 loss_val: 1.0064 acc_val: 0.7601 time: 0.0076s\n",
      "Epoch: 0805 loss_train: 1.0044 acc_train: 0.7253 loss_val: 1.0057 acc_val: 0.7601 time: 0.0075s\n",
      "Epoch: 0806 loss_train: 1.0220 acc_train: 0.7147 loss_val: 1.0050 acc_val: 0.7601 time: 0.0072s\n",
      "Epoch: 0807 loss_train: 1.0106 acc_train: 0.7290 loss_val: 1.0044 acc_val: 0.7638 time: 0.0082s\n",
      "Epoch: 0808 loss_train: 1.0206 acc_train: 0.7318 loss_val: 1.0037 acc_val: 0.7638 time: 0.0081s\n",
      "Epoch: 0809 loss_train: 1.0233 acc_train: 0.7198 loss_val: 1.0030 acc_val: 0.7638 time: 0.0082s\n",
      "Epoch: 0810 loss_train: 1.0190 acc_train: 0.7147 loss_val: 1.0024 acc_val: 0.7601 time: 0.0078s\n",
      "Epoch: 0811 loss_train: 1.0030 acc_train: 0.7355 loss_val: 1.0017 acc_val: 0.7601 time: 0.0082s\n",
      "Epoch: 0812 loss_train: 1.0020 acc_train: 0.7355 loss_val: 1.0010 acc_val: 0.7601 time: 0.0082s\n",
      "Epoch: 0813 loss_train: 1.0145 acc_train: 0.7262 loss_val: 1.0003 acc_val: 0.7601 time: 0.0084s\n",
      "Epoch: 0814 loss_train: 1.0068 acc_train: 0.7285 loss_val: 0.9996 acc_val: 0.7601 time: 0.0085s\n",
      "Epoch: 0815 loss_train: 1.0051 acc_train: 0.7336 loss_val: 0.9989 acc_val: 0.7601 time: 0.0076s\n",
      "Epoch: 0816 loss_train: 1.0334 acc_train: 0.7221 loss_val: 0.9982 acc_val: 0.7601 time: 0.0074s\n",
      "Epoch: 0817 loss_train: 1.0079 acc_train: 0.7244 loss_val: 0.9976 acc_val: 0.7638 time: 0.0072s\n",
      "Epoch: 0818 loss_train: 1.0038 acc_train: 0.7235 loss_val: 0.9969 acc_val: 0.7601 time: 0.0088s\n",
      "Epoch: 0819 loss_train: 0.9906 acc_train: 0.7396 loss_val: 0.9963 acc_val: 0.7601 time: 0.0084s\n",
      "Epoch: 0820 loss_train: 1.0054 acc_train: 0.7216 loss_val: 0.9956 acc_val: 0.7601 time: 0.0080s\n",
      "Epoch: 0821 loss_train: 0.9925 acc_train: 0.7308 loss_val: 0.9949 acc_val: 0.7601 time: 0.0077s\n",
      "Epoch: 0822 loss_train: 1.0028 acc_train: 0.7308 loss_val: 0.9943 acc_val: 0.7601 time: 0.0082s\n",
      "Epoch: 0823 loss_train: 0.9930 acc_train: 0.7285 loss_val: 0.9936 acc_val: 0.7638 time: 0.0082s\n",
      "Epoch: 0824 loss_train: 1.0037 acc_train: 0.7193 loss_val: 0.9930 acc_val: 0.7638 time: 0.0084s\n",
      "Epoch: 0825 loss_train: 1.0044 acc_train: 0.7308 loss_val: 0.9924 acc_val: 0.7675 time: 0.0087s\n",
      "Epoch: 0826 loss_train: 0.9884 acc_train: 0.7299 loss_val: 0.9916 acc_val: 0.7638 time: 0.0077s\n",
      "Epoch: 0827 loss_train: 0.9925 acc_train: 0.7336 loss_val: 0.9909 acc_val: 0.7638 time: 0.0074s\n",
      "Epoch: 0828 loss_train: 1.0018 acc_train: 0.7355 loss_val: 0.9901 acc_val: 0.7675 time: 0.0072s\n",
      "Epoch: 0829 loss_train: 0.9769 acc_train: 0.7544 loss_val: 0.9893 acc_val: 0.7675 time: 0.0082s\n",
      "Epoch: 0830 loss_train: 1.0026 acc_train: 0.7271 loss_val: 0.9886 acc_val: 0.7675 time: 0.0082s\n",
      "Epoch: 0831 loss_train: 1.0054 acc_train: 0.7428 loss_val: 0.9879 acc_val: 0.7675 time: 0.0080s\n",
      "Epoch: 0832 loss_train: 0.9835 acc_train: 0.7419 loss_val: 0.9872 acc_val: 0.7712 time: 0.0078s\n",
      "Epoch: 0833 loss_train: 1.0064 acc_train: 0.7304 loss_val: 0.9865 acc_val: 0.7712 time: 0.0083s\n",
      "Epoch: 0834 loss_train: 1.0074 acc_train: 0.7184 loss_val: 0.9859 acc_val: 0.7712 time: 0.0083s\n",
      "Epoch: 0835 loss_train: 0.9953 acc_train: 0.7562 loss_val: 0.9852 acc_val: 0.7712 time: 0.0083s\n",
      "Epoch: 0836 loss_train: 1.0006 acc_train: 0.7415 loss_val: 0.9845 acc_val: 0.7675 time: 0.0086s\n",
      "Epoch: 0837 loss_train: 0.9895 acc_train: 0.7322 loss_val: 0.9839 acc_val: 0.7675 time: 0.0076s\n",
      "Epoch: 0838 loss_train: 0.9778 acc_train: 0.7345 loss_val: 0.9833 acc_val: 0.7675 time: 0.0075s\n",
      "Epoch: 0839 loss_train: 0.9934 acc_train: 0.7373 loss_val: 0.9826 acc_val: 0.7675 time: 0.0071s\n",
      "Epoch: 0840 loss_train: 0.9887 acc_train: 0.7299 loss_val: 0.9820 acc_val: 0.7675 time: 0.0088s\n",
      "Epoch: 0841 loss_train: 1.0006 acc_train: 0.7276 loss_val: 0.9813 acc_val: 0.7675 time: 0.0083s\n",
      "Epoch: 0842 loss_train: 0.9807 acc_train: 0.7433 loss_val: 0.9808 acc_val: 0.7675 time: 0.0082s\n",
      "Epoch: 0843 loss_train: 0.9802 acc_train: 0.7336 loss_val: 0.9802 acc_val: 0.7675 time: 0.0077s\n",
      "Epoch: 0844 loss_train: 0.9741 acc_train: 0.7304 loss_val: 0.9798 acc_val: 0.7675 time: 0.0082s\n",
      "Epoch: 0845 loss_train: 0.9915 acc_train: 0.7428 loss_val: 0.9793 acc_val: 0.7675 time: 0.0082s\n",
      "Epoch: 0846 loss_train: 0.9894 acc_train: 0.7405 loss_val: 0.9788 acc_val: 0.7675 time: 0.0084s\n",
      "Epoch: 0847 loss_train: 0.9938 acc_train: 0.7258 loss_val: 0.9782 acc_val: 0.7675 time: 0.0085s\n",
      "Epoch: 0848 loss_train: 0.9741 acc_train: 0.7599 loss_val: 0.9776 acc_val: 0.7675 time: 0.0076s\n",
      "Epoch: 0849 loss_train: 0.9900 acc_train: 0.7313 loss_val: 0.9770 acc_val: 0.7675 time: 0.0084s\n",
      "Epoch: 0850 loss_train: 0.9771 acc_train: 0.7428 loss_val: 0.9764 acc_val: 0.7675 time: 0.0082s\n",
      "Epoch: 0851 loss_train: 0.9864 acc_train: 0.7336 loss_val: 0.9758 acc_val: 0.7675 time: 0.0089s\n",
      "Epoch: 0852 loss_train: 0.9874 acc_train: 0.7258 loss_val: 0.9752 acc_val: 0.7675 time: 0.0085s\n",
      "Epoch: 0853 loss_train: 0.9886 acc_train: 0.7410 loss_val: 0.9745 acc_val: 0.7712 time: 0.0079s\n",
      "Epoch: 0854 loss_train: 0.9772 acc_train: 0.7373 loss_val: 0.9738 acc_val: 0.7712 time: 0.0073s\n",
      "Epoch: 0855 loss_train: 0.9628 acc_train: 0.7285 loss_val: 0.9731 acc_val: 0.7749 time: 0.0074s\n",
      "Epoch: 0856 loss_train: 0.9689 acc_train: 0.7396 loss_val: 0.9724 acc_val: 0.7749 time: 0.0083s\n",
      "Epoch: 0857 loss_train: 0.9806 acc_train: 0.7276 loss_val: 0.9717 acc_val: 0.7749 time: 0.0082s\n",
      "Epoch: 0858 loss_train: 0.9709 acc_train: 0.7447 loss_val: 0.9710 acc_val: 0.7749 time: 0.0081s\n",
      "Epoch: 0859 loss_train: 0.9930 acc_train: 0.7304 loss_val: 0.9704 acc_val: 0.7749 time: 0.0075s\n",
      "Epoch: 0860 loss_train: 0.9679 acc_train: 0.7465 loss_val: 0.9698 acc_val: 0.7749 time: 0.0086s\n",
      "Epoch: 0861 loss_train: 0.9744 acc_train: 0.7479 loss_val: 0.9692 acc_val: 0.7749 time: 0.0082s\n",
      "Epoch: 0862 loss_train: 0.9700 acc_train: 0.7452 loss_val: 0.9685 acc_val: 0.7749 time: 0.0086s\n",
      "Epoch: 0863 loss_train: 0.9842 acc_train: 0.7382 loss_val: 0.9679 acc_val: 0.7749 time: 0.0085s\n",
      "Epoch: 0864 loss_train: 0.9694 acc_train: 0.7433 loss_val: 0.9672 acc_val: 0.7749 time: 0.0080s\n",
      "Epoch: 0865 loss_train: 0.9722 acc_train: 0.7405 loss_val: 0.9666 acc_val: 0.7749 time: 0.0075s\n",
      "Epoch: 0866 loss_train: 0.9918 acc_train: 0.7285 loss_val: 0.9659 acc_val: 0.7749 time: 0.0073s\n",
      "Epoch: 0867 loss_train: 0.9832 acc_train: 0.7290 loss_val: 0.9652 acc_val: 0.7749 time: 0.0082s\n",
      "Epoch: 0868 loss_train: 0.9573 acc_train: 0.7447 loss_val: 0.9646 acc_val: 0.7749 time: 0.0082s\n",
      "Epoch: 0869 loss_train: 0.9590 acc_train: 0.7484 loss_val: 0.9639 acc_val: 0.7749 time: 0.0083s\n",
      "Epoch: 0870 loss_train: 0.9660 acc_train: 0.7599 loss_val: 0.9632 acc_val: 0.7749 time: 0.0078s\n",
      "Epoch: 0871 loss_train: 0.9502 acc_train: 0.7498 loss_val: 0.9626 acc_val: 0.7749 time: 0.0081s\n",
      "Epoch: 0872 loss_train: 0.9677 acc_train: 0.7387 loss_val: 0.9620 acc_val: 0.7749 time: 0.0084s\n",
      "Epoch: 0873 loss_train: 0.9539 acc_train: 0.7535 loss_val: 0.9614 acc_val: 0.7749 time: 0.0085s\n",
      "Epoch: 0874 loss_train: 0.9636 acc_train: 0.7525 loss_val: 0.9607 acc_val: 0.7749 time: 0.0085s\n",
      "Epoch: 0875 loss_train: 0.9536 acc_train: 0.7498 loss_val: 0.9601 acc_val: 0.7749 time: 0.0077s\n",
      "Epoch: 0876 loss_train: 0.9639 acc_train: 0.7415 loss_val: 0.9596 acc_val: 0.7749 time: 0.0075s\n",
      "Epoch: 0877 loss_train: 0.9694 acc_train: 0.7368 loss_val: 0.9590 acc_val: 0.7749 time: 0.0072s\n",
      "Epoch: 0878 loss_train: 0.9889 acc_train: 0.7401 loss_val: 0.9585 acc_val: 0.7749 time: 0.0082s\n",
      "Epoch: 0879 loss_train: 0.9720 acc_train: 0.7415 loss_val: 0.9579 acc_val: 0.7749 time: 0.0082s\n",
      "Epoch: 0880 loss_train: 0.9576 acc_train: 0.7595 loss_val: 0.9574 acc_val: 0.7749 time: 0.0083s\n",
      "Epoch: 0881 loss_train: 0.9502 acc_train: 0.7548 loss_val: 0.9567 acc_val: 0.7749 time: 0.0079s\n",
      "Epoch: 0882 loss_train: 0.9738 acc_train: 0.7442 loss_val: 0.9561 acc_val: 0.7786 time: 0.0084s\n",
      "Epoch: 0883 loss_train: 0.9788 acc_train: 0.7410 loss_val: 0.9555 acc_val: 0.7786 time: 0.0083s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0884 loss_train: 0.9206 acc_train: 0.7645 loss_val: 0.9549 acc_val: 0.7786 time: 0.0089s\n",
      "Epoch: 0885 loss_train: 0.9579 acc_train: 0.7590 loss_val: 0.9544 acc_val: 0.7786 time: 0.0086s\n",
      "Epoch: 0886 loss_train: 0.9594 acc_train: 0.7350 loss_val: 0.9538 acc_val: 0.7786 time: 0.0076s\n",
      "Epoch: 0887 loss_train: 0.9677 acc_train: 0.7392 loss_val: 0.9531 acc_val: 0.7786 time: 0.0073s\n",
      "Epoch: 0888 loss_train: 0.9642 acc_train: 0.7562 loss_val: 0.9525 acc_val: 0.7786 time: 0.0071s\n",
      "Epoch: 0889 loss_train: 0.9679 acc_train: 0.7428 loss_val: 0.9519 acc_val: 0.7786 time: 0.0083s\n",
      "Epoch: 0890 loss_train: 0.9559 acc_train: 0.7479 loss_val: 0.9512 acc_val: 0.7786 time: 0.0080s\n",
      "Epoch: 0891 loss_train: 0.9570 acc_train: 0.7590 loss_val: 0.9505 acc_val: 0.7749 time: 0.0080s\n",
      "Epoch: 0892 loss_train: 0.9642 acc_train: 0.7498 loss_val: 0.9498 acc_val: 0.7749 time: 0.0076s\n",
      "Epoch: 0893 loss_train: 0.9644 acc_train: 0.7539 loss_val: 0.9491 acc_val: 0.7749 time: 0.0087s\n",
      "Epoch: 0894 loss_train: 0.9484 acc_train: 0.7585 loss_val: 0.9485 acc_val: 0.7749 time: 0.0083s\n",
      "Epoch: 0895 loss_train: 0.9653 acc_train: 0.7470 loss_val: 0.9479 acc_val: 0.7749 time: 0.0085s\n",
      "Epoch: 0896 loss_train: 0.9562 acc_train: 0.7313 loss_val: 0.9472 acc_val: 0.7749 time: 0.0085s\n",
      "Epoch: 0897 loss_train: 0.9710 acc_train: 0.7410 loss_val: 0.9466 acc_val: 0.7749 time: 0.0079s\n",
      "Epoch: 0898 loss_train: 0.9387 acc_train: 0.7535 loss_val: 0.9461 acc_val: 0.7749 time: 0.0075s\n",
      "Epoch: 0899 loss_train: 0.9643 acc_train: 0.7405 loss_val: 0.9455 acc_val: 0.7749 time: 0.0072s\n",
      "Epoch: 0900 loss_train: 0.9550 acc_train: 0.7488 loss_val: 0.9449 acc_val: 0.7749 time: 0.0082s\n",
      "Epoch: 0901 loss_train: 0.9355 acc_train: 0.7548 loss_val: 0.9444 acc_val: 0.7749 time: 0.0081s\n",
      "Epoch: 0902 loss_train: 0.9469 acc_train: 0.7525 loss_val: 0.9438 acc_val: 0.7749 time: 0.0081s\n",
      "Epoch: 0903 loss_train: 0.9645 acc_train: 0.7433 loss_val: 0.9433 acc_val: 0.7786 time: 0.0077s\n",
      "Epoch: 0904 loss_train: 0.9595 acc_train: 0.7359 loss_val: 0.9427 acc_val: 0.7786 time: 0.0086s\n",
      "Epoch: 0905 loss_train: 0.9581 acc_train: 0.7336 loss_val: 0.9421 acc_val: 0.7786 time: 0.0082s\n",
      "Epoch: 0906 loss_train: 0.9386 acc_train: 0.7447 loss_val: 0.9416 acc_val: 0.7823 time: 0.0091s\n",
      "Epoch: 0907 loss_train: 0.9389 acc_train: 0.7488 loss_val: 0.9410 acc_val: 0.7823 time: 0.0086s\n",
      "Epoch: 0908 loss_train: 0.9573 acc_train: 0.7401 loss_val: 0.9405 acc_val: 0.7823 time: 0.0078s\n",
      "Epoch: 0909 loss_train: 0.9242 acc_train: 0.7558 loss_val: 0.9400 acc_val: 0.7860 time: 0.0086s\n",
      "Epoch: 0910 loss_train: 0.9358 acc_train: 0.7530 loss_val: 0.9395 acc_val: 0.7860 time: 0.0084s\n",
      "Epoch: 0911 loss_train: 0.9448 acc_train: 0.7433 loss_val: 0.9391 acc_val: 0.7860 time: 0.0084s\n",
      "Epoch: 0912 loss_train: 0.9528 acc_train: 0.7401 loss_val: 0.9386 acc_val: 0.7860 time: 0.0083s\n",
      "Epoch: 0913 loss_train: 0.9497 acc_train: 0.7585 loss_val: 0.9380 acc_val: 0.7860 time: 0.0078s\n",
      "Epoch: 0914 loss_train: 0.9411 acc_train: 0.7618 loss_val: 0.9375 acc_val: 0.7860 time: 0.0076s\n",
      "Epoch: 0915 loss_train: 0.9382 acc_train: 0.7419 loss_val: 0.9368 acc_val: 0.7860 time: 0.0075s\n",
      "Epoch: 0916 loss_train: 0.9541 acc_train: 0.7539 loss_val: 0.9361 acc_val: 0.7860 time: 0.0081s\n",
      "Epoch: 0917 loss_train: 0.9445 acc_train: 0.7530 loss_val: 0.9354 acc_val: 0.7860 time: 0.0082s\n",
      "Epoch: 0918 loss_train: 0.9372 acc_train: 0.7512 loss_val: 0.9347 acc_val: 0.7860 time: 0.0086s\n",
      "Epoch: 0919 loss_train: 0.9301 acc_train: 0.7669 loss_val: 0.9340 acc_val: 0.7823 time: 0.0076s\n",
      "Epoch: 0920 loss_train: 0.9570 acc_train: 0.7498 loss_val: 0.9333 acc_val: 0.7823 time: 0.0081s\n",
      "Epoch: 0921 loss_train: 0.9334 acc_train: 0.7544 loss_val: 0.9327 acc_val: 0.7823 time: 0.0080s\n",
      "Epoch: 0922 loss_train: 0.9255 acc_train: 0.7641 loss_val: 0.9321 acc_val: 0.7823 time: 0.0083s\n",
      "Epoch: 0923 loss_train: 0.9269 acc_train: 0.7738 loss_val: 0.9315 acc_val: 0.7823 time: 0.0084s\n",
      "Epoch: 0924 loss_train: 0.9636 acc_train: 0.7465 loss_val: 0.9310 acc_val: 0.7786 time: 0.0079s\n",
      "Epoch: 0925 loss_train: 0.9388 acc_train: 0.7539 loss_val: 0.9305 acc_val: 0.7786 time: 0.0076s\n",
      "Epoch: 0926 loss_train: 0.9432 acc_train: 0.7576 loss_val: 0.9300 acc_val: 0.7786 time: 0.0079s\n",
      "Epoch: 0927 loss_train: 0.9421 acc_train: 0.7438 loss_val: 0.9295 acc_val: 0.7786 time: 0.0082s\n",
      "Epoch: 0928 loss_train: 0.9438 acc_train: 0.7484 loss_val: 0.9290 acc_val: 0.7786 time: 0.0091s\n",
      "Epoch: 0929 loss_train: 0.9396 acc_train: 0.7664 loss_val: 0.9285 acc_val: 0.7823 time: 0.0086s\n",
      "Epoch: 0930 loss_train: 0.9421 acc_train: 0.7613 loss_val: 0.9281 acc_val: 0.7823 time: 0.0076s\n",
      "Epoch: 0931 loss_train: 0.9333 acc_train: 0.7673 loss_val: 0.9276 acc_val: 0.7823 time: 0.0082s\n",
      "Epoch: 0932 loss_train: 0.9344 acc_train: 0.7585 loss_val: 0.9272 acc_val: 0.7897 time: 0.0082s\n",
      "Epoch: 0933 loss_train: 0.9322 acc_train: 0.7535 loss_val: 0.9268 acc_val: 0.7897 time: 0.0084s\n",
      "Epoch: 0934 loss_train: 0.9186 acc_train: 0.7678 loss_val: 0.9263 acc_val: 0.7897 time: 0.0082s\n",
      "Epoch: 0935 loss_train: 0.9119 acc_train: 0.7622 loss_val: 0.9257 acc_val: 0.7934 time: 0.0078s\n",
      "Epoch: 0936 loss_train: 0.9295 acc_train: 0.7539 loss_val: 0.9252 acc_val: 0.7934 time: 0.0076s\n",
      "Epoch: 0937 loss_train: 0.9337 acc_train: 0.7567 loss_val: 0.9247 acc_val: 0.7934 time: 0.0079s\n",
      "Epoch: 0938 loss_train: 0.9192 acc_train: 0.7659 loss_val: 0.9242 acc_val: 0.7934 time: 0.0083s\n",
      "Epoch: 0939 loss_train: 0.9265 acc_train: 0.7595 loss_val: 0.9236 acc_val: 0.7934 time: 0.0088s\n",
      "Epoch: 0940 loss_train: 0.9252 acc_train: 0.7622 loss_val: 0.9230 acc_val: 0.7934 time: 0.0086s\n",
      "Epoch: 0941 loss_train: 0.9240 acc_train: 0.7613 loss_val: 0.9224 acc_val: 0.7934 time: 0.0077s\n",
      "Epoch: 0942 loss_train: 0.9401 acc_train: 0.7618 loss_val: 0.9218 acc_val: 0.7934 time: 0.0082s\n",
      "Epoch: 0943 loss_train: 0.9245 acc_train: 0.7669 loss_val: 0.9212 acc_val: 0.7934 time: 0.0081s\n",
      "Epoch: 0944 loss_train: 0.9144 acc_train: 0.7664 loss_val: 0.9206 acc_val: 0.7934 time: 0.0084s\n",
      "Epoch: 0945 loss_train: 0.9311 acc_train: 0.7465 loss_val: 0.9201 acc_val: 0.7934 time: 0.0084s\n",
      "Epoch: 0946 loss_train: 0.9424 acc_train: 0.7595 loss_val: 0.9195 acc_val: 0.7934 time: 0.0080s\n",
      "Epoch: 0947 loss_train: 0.9248 acc_train: 0.7627 loss_val: 0.9190 acc_val: 0.7934 time: 0.0076s\n",
      "Epoch: 0948 loss_train: 0.9268 acc_train: 0.7562 loss_val: 0.9184 acc_val: 0.7934 time: 0.0078s\n",
      "Epoch: 0949 loss_train: 0.9177 acc_train: 0.7650 loss_val: 0.9178 acc_val: 0.7934 time: 0.0082s\n",
      "Epoch: 0950 loss_train: 0.9221 acc_train: 0.7669 loss_val: 0.9172 acc_val: 0.7934 time: 0.0090s\n",
      "Epoch: 0951 loss_train: 0.9090 acc_train: 0.7567 loss_val: 0.9166 acc_val: 0.7934 time: 0.0085s\n",
      "Epoch: 0952 loss_train: 0.9200 acc_train: 0.7613 loss_val: 0.9160 acc_val: 0.7934 time: 0.0076s\n",
      "Epoch: 0953 loss_train: 0.9377 acc_train: 0.7479 loss_val: 0.9154 acc_val: 0.7970 time: 0.0083s\n",
      "Epoch: 0954 loss_train: 0.9112 acc_train: 0.7701 loss_val: 0.9147 acc_val: 0.8007 time: 0.0082s\n",
      "Epoch: 0955 loss_train: 0.9496 acc_train: 0.7558 loss_val: 0.9141 acc_val: 0.8007 time: 0.0082s\n",
      "Epoch: 0956 loss_train: 0.9213 acc_train: 0.7585 loss_val: 0.9135 acc_val: 0.8007 time: 0.0082s\n",
      "Epoch: 0957 loss_train: 0.9164 acc_train: 0.7678 loss_val: 0.9129 acc_val: 0.8044 time: 0.0080s\n",
      "Epoch: 0958 loss_train: 0.9319 acc_train: 0.7525 loss_val: 0.9124 acc_val: 0.8044 time: 0.0075s\n",
      "Epoch: 0959 loss_train: 0.9197 acc_train: 0.7687 loss_val: 0.9119 acc_val: 0.8044 time: 0.0079s\n",
      "Epoch: 0960 loss_train: 0.9062 acc_train: 0.7678 loss_val: 0.9114 acc_val: 0.8044 time: 0.0083s\n",
      "Epoch: 0961 loss_train: 0.9249 acc_train: 0.7572 loss_val: 0.9109 acc_val: 0.8044 time: 0.0084s\n",
      "Epoch: 0962 loss_train: 0.9097 acc_train: 0.7816 loss_val: 0.9104 acc_val: 0.8044 time: 0.0085s\n",
      "Epoch: 0963 loss_train: 0.8961 acc_train: 0.7761 loss_val: 0.9099 acc_val: 0.8044 time: 0.0080s\n",
      "Epoch: 0964 loss_train: 0.9153 acc_train: 0.7692 loss_val: 0.9094 acc_val: 0.8044 time: 0.0082s\n",
      "Epoch: 0965 loss_train: 0.9086 acc_train: 0.7733 loss_val: 0.9089 acc_val: 0.8007 time: 0.0079s\n",
      "Epoch: 0966 loss_train: 0.9045 acc_train: 0.7664 loss_val: 0.9083 acc_val: 0.8007 time: 0.0082s\n",
      "Epoch: 0967 loss_train: 0.9320 acc_train: 0.7752 loss_val: 0.9078 acc_val: 0.8007 time: 0.0082s\n",
      "Epoch: 0968 loss_train: 0.9102 acc_train: 0.7678 loss_val: 0.9072 acc_val: 0.8007 time: 0.0079s\n",
      "Epoch: 0969 loss_train: 0.9128 acc_train: 0.7710 loss_val: 0.9066 acc_val: 0.8007 time: 0.0074s\n",
      "Epoch: 0970 loss_train: 0.8989 acc_train: 0.7687 loss_val: 0.9060 acc_val: 0.8007 time: 0.0075s\n",
      "Epoch: 0971 loss_train: 0.9026 acc_train: 0.7765 loss_val: 0.9054 acc_val: 0.8007 time: 0.0081s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0972 loss_train: 0.9069 acc_train: 0.7632 loss_val: 0.9049 acc_val: 0.8007 time: 0.0089s\n",
      "Epoch: 0973 loss_train: 0.9251 acc_train: 0.7521 loss_val: 0.9045 acc_val: 0.8007 time: 0.0083s\n",
      "Epoch: 0974 loss_train: 0.8908 acc_train: 0.7742 loss_val: 0.9041 acc_val: 0.8007 time: 0.0075s\n",
      "Epoch: 0975 loss_train: 0.8989 acc_train: 0.7525 loss_val: 0.9037 acc_val: 0.8044 time: 0.0086s\n",
      "Epoch: 0976 loss_train: 0.9065 acc_train: 0.7576 loss_val: 0.9033 acc_val: 0.8044 time: 0.0081s\n",
      "Epoch: 0977 loss_train: 0.9015 acc_train: 0.7664 loss_val: 0.9028 acc_val: 0.8044 time: 0.0085s\n",
      "Epoch: 0978 loss_train: 0.9051 acc_train: 0.7839 loss_val: 0.9023 acc_val: 0.8044 time: 0.0085s\n",
      "Epoch: 0979 loss_train: 0.8901 acc_train: 0.7752 loss_val: 0.9018 acc_val: 0.8007 time: 0.0079s\n",
      "Epoch: 0980 loss_train: 0.9078 acc_train: 0.7627 loss_val: 0.9012 acc_val: 0.8007 time: 0.0075s\n",
      "Epoch: 0981 loss_train: 0.9183 acc_train: 0.7678 loss_val: 0.9006 acc_val: 0.8007 time: 0.0072s\n",
      "Epoch: 0982 loss_train: 0.8802 acc_train: 0.7669 loss_val: 0.9000 acc_val: 0.8007 time: 0.0082s\n",
      "Epoch: 0983 loss_train: 0.9146 acc_train: 0.7618 loss_val: 0.8994 acc_val: 0.8007 time: 0.0082s\n",
      "Epoch: 0984 loss_train: 0.9096 acc_train: 0.7793 loss_val: 0.8988 acc_val: 0.8007 time: 0.0081s\n",
      "Epoch: 0985 loss_train: 0.9174 acc_train: 0.7747 loss_val: 0.8982 acc_val: 0.8007 time: 0.0076s\n",
      "Epoch: 0986 loss_train: 0.9092 acc_train: 0.7650 loss_val: 0.8977 acc_val: 0.8044 time: 0.0087s\n",
      "Epoch: 0987 loss_train: 0.9028 acc_train: 0.7747 loss_val: 0.8972 acc_val: 0.8044 time: 0.0083s\n",
      "Epoch: 0988 loss_train: 0.9234 acc_train: 0.7636 loss_val: 0.8969 acc_val: 0.8044 time: 0.0085s\n",
      "Epoch: 0989 loss_train: 0.8904 acc_train: 0.7899 loss_val: 0.8965 acc_val: 0.8044 time: 0.0086s\n",
      "Epoch: 0990 loss_train: 0.9169 acc_train: 0.7608 loss_val: 0.8962 acc_val: 0.8044 time: 0.0078s\n",
      "Epoch: 0991 loss_train: 0.8990 acc_train: 0.7682 loss_val: 0.8959 acc_val: 0.8044 time: 0.0075s\n",
      "Epoch: 0992 loss_train: 0.9131 acc_train: 0.7789 loss_val: 0.8955 acc_val: 0.8044 time: 0.0072s\n",
      "Epoch: 0993 loss_train: 0.9153 acc_train: 0.7590 loss_val: 0.8952 acc_val: 0.8044 time: 0.0082s\n",
      "Epoch: 0994 loss_train: 0.9066 acc_train: 0.7705 loss_val: 0.8948 acc_val: 0.8044 time: 0.0086s\n",
      "Epoch: 0995 loss_train: 0.8905 acc_train: 0.7853 loss_val: 0.8943 acc_val: 0.8044 time: 0.0082s\n",
      "Epoch: 0996 loss_train: 0.8910 acc_train: 0.7756 loss_val: 0.8939 acc_val: 0.8044 time: 0.0078s\n",
      "Epoch: 0997 loss_train: 0.8882 acc_train: 0.7673 loss_val: 0.8934 acc_val: 0.8044 time: 0.0082s\n",
      "Epoch: 0998 loss_train: 0.9050 acc_train: 0.7669 loss_val: 0.8929 acc_val: 0.8044 time: 0.0083s\n",
      "Epoch: 0999 loss_train: 0.9097 acc_train: 0.7613 loss_val: 0.8923 acc_val: 0.8044 time: 0.0085s\n",
      "Epoch: 1000 loss_train: 0.9024 acc_train: 0.7664 loss_val: 0.8917 acc_val: 0.8044 time: 0.0085s\n",
      "Epoch: 1001 loss_train: 0.9027 acc_train: 0.7807 loss_val: 0.8912 acc_val: 0.8081 time: 0.0077s\n",
      "Epoch: 1002 loss_train: 0.9044 acc_train: 0.7733 loss_val: 0.8906 acc_val: 0.8081 time: 0.0074s\n",
      "Epoch: 1003 loss_train: 0.9082 acc_train: 0.7604 loss_val: 0.8900 acc_val: 0.8081 time: 0.0072s\n",
      "Epoch: 1004 loss_train: 0.8766 acc_train: 0.7756 loss_val: 0.8894 acc_val: 0.8118 time: 0.0082s\n",
      "Epoch: 1005 loss_train: 0.8965 acc_train: 0.7793 loss_val: 0.8888 acc_val: 0.8118 time: 0.0081s\n",
      "Epoch: 1006 loss_train: 0.8961 acc_train: 0.7673 loss_val: 0.8883 acc_val: 0.8192 time: 0.0084s\n",
      "Epoch: 1007 loss_train: 0.9022 acc_train: 0.7756 loss_val: 0.8877 acc_val: 0.8192 time: 0.0078s\n",
      "Epoch: 1008 loss_train: 0.8869 acc_train: 0.7779 loss_val: 0.8872 acc_val: 0.8192 time: 0.0082s\n",
      "Epoch: 1009 loss_train: 0.9089 acc_train: 0.7659 loss_val: 0.8866 acc_val: 0.8229 time: 0.0083s\n",
      "Epoch: 1010 loss_train: 0.8968 acc_train: 0.7798 loss_val: 0.8861 acc_val: 0.8229 time: 0.0084s\n",
      "Epoch: 1011 loss_train: 0.9086 acc_train: 0.7724 loss_val: 0.8855 acc_val: 0.8229 time: 0.0086s\n",
      "Epoch: 1012 loss_train: 0.9176 acc_train: 0.7572 loss_val: 0.8849 acc_val: 0.8192 time: 0.0076s\n",
      "Epoch: 1013 loss_train: 0.8695 acc_train: 0.7835 loss_val: 0.8844 acc_val: 0.8192 time: 0.0073s\n",
      "Epoch: 1014 loss_train: 0.8763 acc_train: 0.7798 loss_val: 0.8839 acc_val: 0.8192 time: 0.0071s\n",
      "Epoch: 1015 loss_train: 0.8865 acc_train: 0.7770 loss_val: 0.8835 acc_val: 0.8192 time: 0.0082s\n",
      "Epoch: 1016 loss_train: 0.8965 acc_train: 0.7705 loss_val: 0.8830 acc_val: 0.8192 time: 0.0088s\n",
      "Epoch: 1017 loss_train: 0.8963 acc_train: 0.7669 loss_val: 0.8826 acc_val: 0.8155 time: 0.0082s\n",
      "Epoch: 1018 loss_train: 0.8924 acc_train: 0.7705 loss_val: 0.8822 acc_val: 0.8118 time: 0.0078s\n",
      "Epoch: 1019 loss_train: 0.9085 acc_train: 0.7539 loss_val: 0.8819 acc_val: 0.8118 time: 0.0082s\n",
      "Epoch: 1020 loss_train: 0.8890 acc_train: 0.7816 loss_val: 0.8815 acc_val: 0.8155 time: 0.0083s\n",
      "Epoch: 1021 loss_train: 0.8744 acc_train: 0.7673 loss_val: 0.8812 acc_val: 0.8155 time: 0.0085s\n",
      "Epoch: 1022 loss_train: 0.8979 acc_train: 0.7608 loss_val: 0.8809 acc_val: 0.8118 time: 0.0085s\n",
      "Epoch: 1023 loss_train: 0.8691 acc_train: 0.7770 loss_val: 0.8807 acc_val: 0.8118 time: 0.0077s\n",
      "Epoch: 1024 loss_train: 0.8686 acc_train: 0.7724 loss_val: 0.8804 acc_val: 0.8118 time: 0.0074s\n",
      "Epoch: 1025 loss_train: 0.8844 acc_train: 0.7645 loss_val: 0.8800 acc_val: 0.8118 time: 0.0072s\n",
      "Epoch: 1026 loss_train: 0.8761 acc_train: 0.7765 loss_val: 0.8796 acc_val: 0.8118 time: 0.0083s\n",
      "Epoch: 1027 loss_train: 0.8886 acc_train: 0.7775 loss_val: 0.8791 acc_val: 0.8118 time: 0.0082s\n",
      "Epoch: 1028 loss_train: 0.8933 acc_train: 0.7775 loss_val: 0.8787 acc_val: 0.8118 time: 0.0081s\n",
      "Epoch: 1029 loss_train: 0.9092 acc_train: 0.7775 loss_val: 0.8781 acc_val: 0.8118 time: 0.0078s\n",
      "Epoch: 1030 loss_train: 0.8878 acc_train: 0.7849 loss_val: 0.8776 acc_val: 0.8118 time: 0.0079s\n",
      "Epoch: 1031 loss_train: 0.8822 acc_train: 0.7729 loss_val: 0.8770 acc_val: 0.8118 time: 0.0082s\n",
      "Epoch: 1032 loss_train: 0.8718 acc_train: 0.7839 loss_val: 0.8764 acc_val: 0.8155 time: 0.0084s\n",
      "Epoch: 1033 loss_train: 0.8938 acc_train: 0.7678 loss_val: 0.8757 acc_val: 0.8155 time: 0.0085s\n",
      "Epoch: 1034 loss_train: 0.8703 acc_train: 0.7770 loss_val: 0.8750 acc_val: 0.8229 time: 0.0077s\n",
      "Epoch: 1035 loss_train: 0.8611 acc_train: 0.7932 loss_val: 0.8744 acc_val: 0.8229 time: 0.0077s\n",
      "Epoch: 1036 loss_train: 0.8658 acc_train: 0.7922 loss_val: 0.8737 acc_val: 0.8229 time: 0.0075s\n",
      "Epoch: 1037 loss_train: 0.8809 acc_train: 0.7729 loss_val: 0.8731 acc_val: 0.8266 time: 0.0083s\n",
      "Epoch: 1038 loss_train: 0.8957 acc_train: 0.7696 loss_val: 0.8725 acc_val: 0.8266 time: 0.0089s\n",
      "Epoch: 1039 loss_train: 0.8712 acc_train: 0.7825 loss_val: 0.8720 acc_val: 0.8266 time: 0.0078s\n",
      "Epoch: 1040 loss_train: 0.9040 acc_train: 0.7682 loss_val: 0.8715 acc_val: 0.8229 time: 0.0080s\n",
      "Epoch: 1041 loss_train: 0.9102 acc_train: 0.7784 loss_val: 0.8711 acc_val: 0.8229 time: 0.0080s\n",
      "Epoch: 1042 loss_train: 0.8715 acc_train: 0.7756 loss_val: 0.8707 acc_val: 0.8229 time: 0.0083s\n",
      "Epoch: 1043 loss_train: 0.8609 acc_train: 0.7858 loss_val: 0.8704 acc_val: 0.8229 time: 0.0083s\n",
      "Epoch: 1044 loss_train: 0.8784 acc_train: 0.7747 loss_val: 0.8701 acc_val: 0.8229 time: 0.0086s\n",
      "Epoch: 1045 loss_train: 0.8820 acc_train: 0.7816 loss_val: 0.8697 acc_val: 0.8229 time: 0.0078s\n",
      "Epoch: 1046 loss_train: 0.8759 acc_train: 0.7618 loss_val: 0.8695 acc_val: 0.8229 time: 0.0078s\n",
      "Epoch: 1047 loss_train: 0.8748 acc_train: 0.7775 loss_val: 0.8691 acc_val: 0.8266 time: 0.0080s\n",
      "Epoch: 1048 loss_train: 0.8816 acc_train: 0.7886 loss_val: 0.8686 acc_val: 0.8266 time: 0.0083s\n",
      "Epoch: 1049 loss_train: 0.8885 acc_train: 0.7793 loss_val: 0.8682 acc_val: 0.8303 time: 0.0083s\n",
      "Epoch: 1050 loss_train: 0.8839 acc_train: 0.7775 loss_val: 0.8678 acc_val: 0.8266 time: 0.0078s\n",
      "Epoch: 1051 loss_train: 0.8763 acc_train: 0.7835 loss_val: 0.8673 acc_val: 0.8266 time: 0.0077s\n",
      "Epoch: 1052 loss_train: 0.8610 acc_train: 0.7941 loss_val: 0.8669 acc_val: 0.8266 time: 0.0079s\n",
      "Epoch: 1053 loss_train: 0.8695 acc_train: 0.7853 loss_val: 0.8665 acc_val: 0.8266 time: 0.0082s\n",
      "Epoch: 1054 loss_train: 0.8785 acc_train: 0.7881 loss_val: 0.8661 acc_val: 0.8266 time: 0.0082s\n",
      "Epoch: 1055 loss_train: 0.8550 acc_train: 0.7802 loss_val: 0.8657 acc_val: 0.8266 time: 0.0086s\n",
      "Epoch: 1056 loss_train: 0.8583 acc_train: 0.7849 loss_val: 0.8653 acc_val: 0.8229 time: 0.0078s\n",
      "Epoch: 1057 loss_train: 0.8773 acc_train: 0.7747 loss_val: 0.8649 acc_val: 0.8229 time: 0.0072s\n",
      "Epoch: 1058 loss_train: 0.8650 acc_train: 0.7659 loss_val: 0.8644 acc_val: 0.8266 time: 0.0072s\n",
      "Epoch: 1059 loss_train: 0.8656 acc_train: 0.7881 loss_val: 0.8639 acc_val: 0.8266 time: 0.0082s\n",
      "Epoch: 1060 loss_train: 0.8840 acc_train: 0.7673 loss_val: 0.8635 acc_val: 0.8266 time: 0.0082s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1061 loss_train: 0.8604 acc_train: 0.7798 loss_val: 0.8630 acc_val: 0.8266 time: 0.0086s\n",
      "Epoch: 1062 loss_train: 0.8718 acc_train: 0.7816 loss_val: 0.8624 acc_val: 0.8303 time: 0.0086s\n",
      "Epoch: 1063 loss_train: 0.8678 acc_train: 0.7839 loss_val: 0.8620 acc_val: 0.8303 time: 0.0081s\n",
      "Epoch: 1064 loss_train: 0.8827 acc_train: 0.7881 loss_val: 0.8615 acc_val: 0.8303 time: 0.0082s\n",
      "Epoch: 1065 loss_train: 0.8777 acc_train: 0.7738 loss_val: 0.8610 acc_val: 0.8303 time: 0.0085s\n",
      "Epoch: 1066 loss_train: 0.8592 acc_train: 0.7830 loss_val: 0.8607 acc_val: 0.8303 time: 0.0086s\n",
      "Epoch: 1067 loss_train: 0.8592 acc_train: 0.7844 loss_val: 0.8602 acc_val: 0.8303 time: 0.0078s\n",
      "Epoch: 1068 loss_train: 0.8583 acc_train: 0.7830 loss_val: 0.8598 acc_val: 0.8303 time: 0.0082s\n",
      "Epoch: 1069 loss_train: 0.8561 acc_train: 0.7904 loss_val: 0.8595 acc_val: 0.8303 time: 0.0080s\n",
      "Epoch: 1070 loss_train: 0.8647 acc_train: 0.7821 loss_val: 0.8591 acc_val: 0.8339 time: 0.0083s\n",
      "Epoch: 1071 loss_train: 0.8565 acc_train: 0.7890 loss_val: 0.8587 acc_val: 0.8339 time: 0.0082s\n",
      "Epoch: 1072 loss_train: 0.8683 acc_train: 0.7849 loss_val: 0.8583 acc_val: 0.8339 time: 0.0079s\n",
      "Epoch: 1073 loss_train: 0.8522 acc_train: 0.7946 loss_val: 0.8578 acc_val: 0.8376 time: 0.0076s\n",
      "Epoch: 1074 loss_train: 0.8725 acc_train: 0.7862 loss_val: 0.8573 acc_val: 0.8376 time: 0.0080s\n",
      "Epoch: 1075 loss_train: 0.8556 acc_train: 0.7876 loss_val: 0.8569 acc_val: 0.8376 time: 0.0082s\n",
      "Epoch: 1076 loss_train: 0.8616 acc_train: 0.7982 loss_val: 0.8564 acc_val: 0.8376 time: 0.0083s\n",
      "Epoch: 1077 loss_train: 0.8690 acc_train: 0.7765 loss_val: 0.8559 acc_val: 0.8376 time: 0.0085s\n",
      "Epoch: 1078 loss_train: 0.8643 acc_train: 0.7862 loss_val: 0.8554 acc_val: 0.8376 time: 0.0078s\n",
      "Epoch: 1079 loss_train: 0.8772 acc_train: 0.7752 loss_val: 0.8549 acc_val: 0.8376 time: 0.0079s\n",
      "Epoch: 1080 loss_train: 0.8584 acc_train: 0.7807 loss_val: 0.8545 acc_val: 0.8376 time: 0.0078s\n",
      "Epoch: 1081 loss_train: 0.8453 acc_train: 0.7982 loss_val: 0.8540 acc_val: 0.8413 time: 0.0083s\n",
      "Epoch: 1082 loss_train: 0.8496 acc_train: 0.7876 loss_val: 0.8535 acc_val: 0.8413 time: 0.0082s\n",
      "Epoch: 1083 loss_train: 0.8596 acc_train: 0.7821 loss_val: 0.8530 acc_val: 0.8413 time: 0.0085s\n",
      "Epoch: 1084 loss_train: 0.8604 acc_train: 0.7853 loss_val: 0.8525 acc_val: 0.8413 time: 0.0076s\n",
      "Epoch: 1085 loss_train: 0.8434 acc_train: 0.7913 loss_val: 0.8520 acc_val: 0.8450 time: 0.0079s\n",
      "Epoch: 1086 loss_train: 0.8461 acc_train: 0.8001 loss_val: 0.8515 acc_val: 0.8450 time: 0.0083s\n",
      "Epoch: 1087 loss_train: 0.8701 acc_train: 0.7853 loss_val: 0.8511 acc_val: 0.8413 time: 0.0084s\n",
      "Epoch: 1088 loss_train: 0.8624 acc_train: 0.7830 loss_val: 0.8507 acc_val: 0.8413 time: 0.0085s\n",
      "Epoch: 1089 loss_train: 0.8770 acc_train: 0.7807 loss_val: 0.8502 acc_val: 0.8413 time: 0.0076s\n",
      "Epoch: 1090 loss_train: 0.8570 acc_train: 0.7816 loss_val: 0.8499 acc_val: 0.8413 time: 0.0086s\n",
      "Epoch: 1091 loss_train: 0.8724 acc_train: 0.7950 loss_val: 0.8495 acc_val: 0.8413 time: 0.0083s\n",
      "Epoch: 1092 loss_train: 0.8386 acc_train: 0.7964 loss_val: 0.8490 acc_val: 0.8413 time: 0.0084s\n",
      "Epoch: 1093 loss_train: 0.8568 acc_train: 0.7881 loss_val: 0.8486 acc_val: 0.8413 time: 0.0085s\n",
      "Epoch: 1094 loss_train: 0.8570 acc_train: 0.7881 loss_val: 0.8481 acc_val: 0.8413 time: 0.0078s\n",
      "Epoch: 1095 loss_train: 0.8477 acc_train: 0.7844 loss_val: 0.8476 acc_val: 0.8413 time: 0.0074s\n",
      "Epoch: 1096 loss_train: 0.8315 acc_train: 0.8042 loss_val: 0.8472 acc_val: 0.8413 time: 0.0072s\n",
      "Epoch: 1097 loss_train: 0.8356 acc_train: 0.7895 loss_val: 0.8467 acc_val: 0.8450 time: 0.0083s\n",
      "Epoch: 1098 loss_train: 0.8673 acc_train: 0.7867 loss_val: 0.8462 acc_val: 0.8450 time: 0.0082s\n",
      "Epoch: 1099 loss_train: 0.8509 acc_train: 0.7881 loss_val: 0.8458 acc_val: 0.8450 time: 0.0082s\n",
      "Epoch: 1100 loss_train: 0.8697 acc_train: 0.7927 loss_val: 0.8453 acc_val: 0.8450 time: 0.0079s\n",
      "Epoch: 1101 loss_train: 0.8575 acc_train: 0.7876 loss_val: 0.8447 acc_val: 0.8450 time: 0.0082s\n",
      "Epoch: 1102 loss_train: 0.8627 acc_train: 0.7835 loss_val: 0.8442 acc_val: 0.8450 time: 0.0083s\n",
      "Epoch: 1103 loss_train: 0.8581 acc_train: 0.7872 loss_val: 0.8436 acc_val: 0.8450 time: 0.0084s\n",
      "Epoch: 1104 loss_train: 0.8514 acc_train: 0.7890 loss_val: 0.8431 acc_val: 0.8450 time: 0.0086s\n",
      "Epoch: 1105 loss_train: 0.8455 acc_train: 0.7950 loss_val: 0.8426 acc_val: 0.8450 time: 0.0085s\n",
      "Epoch: 1106 loss_train: 0.8480 acc_train: 0.7973 loss_val: 0.8421 acc_val: 0.8450 time: 0.0087s\n",
      "Epoch: 1107 loss_train: 0.8479 acc_train: 0.8001 loss_val: 0.8416 acc_val: 0.8450 time: 0.0084s\n",
      "Epoch: 1108 loss_train: 0.8392 acc_train: 0.7913 loss_val: 0.8410 acc_val: 0.8450 time: 0.0081s\n",
      "Epoch: 1109 loss_train: 0.8616 acc_train: 0.7886 loss_val: 0.8405 acc_val: 0.8450 time: 0.0083s\n",
      "Epoch: 1110 loss_train: 0.8534 acc_train: 0.7779 loss_val: 0.8399 acc_val: 0.8561 time: 0.0078s\n",
      "Epoch: 1111 loss_train: 0.8402 acc_train: 0.7959 loss_val: 0.8394 acc_val: 0.8561 time: 0.0075s\n",
      "Epoch: 1112 loss_train: 0.8470 acc_train: 0.7996 loss_val: 0.8389 acc_val: 0.8561 time: 0.0078s\n",
      "Epoch: 1113 loss_train: 0.8542 acc_train: 0.7830 loss_val: 0.8384 acc_val: 0.8561 time: 0.0081s\n",
      "Epoch: 1114 loss_train: 0.8550 acc_train: 0.7862 loss_val: 0.8378 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1115 loss_train: 0.8556 acc_train: 0.7946 loss_val: 0.8373 acc_val: 0.8561 time: 0.0086s\n",
      "Epoch: 1116 loss_train: 0.8428 acc_train: 0.7964 loss_val: 0.8367 acc_val: 0.8598 time: 0.0076s\n",
      "Epoch: 1117 loss_train: 0.8643 acc_train: 0.7969 loss_val: 0.8362 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1118 loss_train: 0.8508 acc_train: 0.7789 loss_val: 0.8358 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1119 loss_train: 0.8539 acc_train: 0.8015 loss_val: 0.8355 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1120 loss_train: 0.8395 acc_train: 0.7982 loss_val: 0.8351 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1121 loss_train: 0.8296 acc_train: 0.8033 loss_val: 0.8346 acc_val: 0.8598 time: 0.0075s\n",
      "Epoch: 1122 loss_train: 0.8462 acc_train: 0.7904 loss_val: 0.8341 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1123 loss_train: 0.8361 acc_train: 0.7890 loss_val: 0.8337 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1124 loss_train: 0.8373 acc_train: 0.7904 loss_val: 0.8332 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1125 loss_train: 0.8310 acc_train: 0.7886 loss_val: 0.8328 acc_val: 0.8561 time: 0.0083s\n",
      "Epoch: 1126 loss_train: 0.8331 acc_train: 0.8015 loss_val: 0.8323 acc_val: 0.8561 time: 0.0087s\n",
      "Epoch: 1127 loss_train: 0.8283 acc_train: 0.8042 loss_val: 0.8318 acc_val: 0.8561 time: 0.0078s\n",
      "Epoch: 1128 loss_train: 0.8381 acc_train: 0.8098 loss_val: 0.8313 acc_val: 0.8561 time: 0.0085s\n",
      "Epoch: 1129 loss_train: 0.8391 acc_train: 0.7959 loss_val: 0.8308 acc_val: 0.8561 time: 0.0083s\n",
      "Epoch: 1130 loss_train: 0.8493 acc_train: 0.7959 loss_val: 0.8303 acc_val: 0.8561 time: 0.0085s\n",
      "Epoch: 1131 loss_train: 0.8259 acc_train: 0.8163 loss_val: 0.8298 acc_val: 0.8561 time: 0.0083s\n",
      "Epoch: 1132 loss_train: 0.8328 acc_train: 0.7996 loss_val: 0.8293 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1133 loss_train: 0.8225 acc_train: 0.8052 loss_val: 0.8289 acc_val: 0.8598 time: 0.0125s\n",
      "Epoch: 1134 loss_train: 0.8417 acc_train: 0.7895 loss_val: 0.8284 acc_val: 0.8598 time: 0.0084s\n",
      "Epoch: 1135 loss_train: 0.8359 acc_train: 0.8056 loss_val: 0.8280 acc_val: 0.8598 time: 0.0086s\n",
      "Epoch: 1136 loss_train: 0.8287 acc_train: 0.8042 loss_val: 0.8274 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1137 loss_train: 0.8258 acc_train: 0.7987 loss_val: 0.8269 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1138 loss_train: 0.8342 acc_train: 0.8001 loss_val: 0.8263 acc_val: 0.8635 time: 0.0074s\n",
      "Epoch: 1139 loss_train: 0.8338 acc_train: 0.8070 loss_val: 0.8258 acc_val: 0.8598 time: 0.0076s\n",
      "Epoch: 1140 loss_train: 0.8353 acc_train: 0.7964 loss_val: 0.8252 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1141 loss_train: 0.8344 acc_train: 0.7955 loss_val: 0.8247 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1142 loss_train: 0.8263 acc_train: 0.7922 loss_val: 0.8241 acc_val: 0.8598 time: 0.0085s\n",
      "Epoch: 1143 loss_train: 0.8080 acc_train: 0.8093 loss_val: 0.8236 acc_val: 0.8598 time: 0.0075s\n",
      "Epoch: 1144 loss_train: 0.8013 acc_train: 0.8126 loss_val: 0.8231 acc_val: 0.8598 time: 0.0084s\n",
      "Epoch: 1145 loss_train: 0.8552 acc_train: 0.7890 loss_val: 0.8227 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1146 loss_train: 0.8414 acc_train: 0.8033 loss_val: 0.8222 acc_val: 0.8598 time: 0.0084s\n",
      "Epoch: 1147 loss_train: 0.8358 acc_train: 0.7927 loss_val: 0.8217 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1148 loss_train: 0.8150 acc_train: 0.8126 loss_val: 0.8212 acc_val: 0.8598 time: 0.0080s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1149 loss_train: 0.8249 acc_train: 0.7987 loss_val: 0.8207 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1150 loss_train: 0.8344 acc_train: 0.7899 loss_val: 0.8202 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1151 loss_train: 0.8112 acc_train: 0.7987 loss_val: 0.8197 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1152 loss_train: 0.8263 acc_train: 0.8010 loss_val: 0.8192 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1153 loss_train: 0.8265 acc_train: 0.8019 loss_val: 0.8187 acc_val: 0.8598 time: 0.0080s\n",
      "Epoch: 1154 loss_train: 0.8532 acc_train: 0.7899 loss_val: 0.8181 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1155 loss_train: 0.8513 acc_train: 0.7853 loss_val: 0.8177 acc_val: 0.8561 time: 0.0082s\n",
      "Epoch: 1156 loss_train: 0.8308 acc_train: 0.8066 loss_val: 0.8173 acc_val: 0.8561 time: 0.0084s\n",
      "Epoch: 1157 loss_train: 0.8303 acc_train: 0.7978 loss_val: 0.8169 acc_val: 0.8561 time: 0.0084s\n",
      "Epoch: 1158 loss_train: 0.8133 acc_train: 0.8084 loss_val: 0.8164 acc_val: 0.8561 time: 0.0086s\n",
      "Epoch: 1159 loss_train: 0.8156 acc_train: 0.8038 loss_val: 0.8160 acc_val: 0.8561 time: 0.0078s\n",
      "Epoch: 1160 loss_train: 0.8196 acc_train: 0.7996 loss_val: 0.8155 acc_val: 0.8598 time: 0.0076s\n",
      "Epoch: 1161 loss_train: 0.8141 acc_train: 0.8107 loss_val: 0.8150 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1162 loss_train: 0.8246 acc_train: 0.8163 loss_val: 0.8145 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1163 loss_train: 0.8104 acc_train: 0.8029 loss_val: 0.8141 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1164 loss_train: 0.8262 acc_train: 0.7969 loss_val: 0.8136 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1165 loss_train: 0.7992 acc_train: 0.8112 loss_val: 0.8130 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1166 loss_train: 0.8123 acc_train: 0.8024 loss_val: 0.8126 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1167 loss_train: 0.8159 acc_train: 0.8079 loss_val: 0.8122 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1168 loss_train: 0.8446 acc_train: 0.7936 loss_val: 0.8118 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1169 loss_train: 0.8354 acc_train: 0.7996 loss_val: 0.8114 acc_val: 0.8635 time: 0.0086s\n",
      "Epoch: 1170 loss_train: 0.8343 acc_train: 0.7964 loss_val: 0.8109 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1171 loss_train: 0.8131 acc_train: 0.8135 loss_val: 0.8105 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1172 loss_train: 0.8229 acc_train: 0.8052 loss_val: 0.8100 acc_val: 0.8635 time: 0.0076s\n",
      "Epoch: 1173 loss_train: 0.8292 acc_train: 0.7996 loss_val: 0.8095 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1174 loss_train: 0.7963 acc_train: 0.7992 loss_val: 0.8090 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1175 loss_train: 0.8103 acc_train: 0.8121 loss_val: 0.8085 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1176 loss_train: 0.8070 acc_train: 0.8130 loss_val: 0.8080 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1177 loss_train: 0.8052 acc_train: 0.8070 loss_val: 0.8075 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1178 loss_train: 0.8134 acc_train: 0.8079 loss_val: 0.8071 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1179 loss_train: 0.7936 acc_train: 0.8296 loss_val: 0.8066 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1180 loss_train: 0.8066 acc_train: 0.8056 loss_val: 0.8062 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1181 loss_train: 0.8188 acc_train: 0.8029 loss_val: 0.8058 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1182 loss_train: 0.8326 acc_train: 0.8010 loss_val: 0.8055 acc_val: 0.8672 time: 0.0074s\n",
      "Epoch: 1183 loss_train: 0.8198 acc_train: 0.7964 loss_val: 0.8051 acc_val: 0.8672 time: 0.0072s\n",
      "Epoch: 1184 loss_train: 0.8203 acc_train: 0.8167 loss_val: 0.8048 acc_val: 0.8672 time: 0.0083s\n",
      "Epoch: 1185 loss_train: 0.8058 acc_train: 0.7964 loss_val: 0.8045 acc_val: 0.8672 time: 0.0082s\n",
      "Epoch: 1186 loss_train: 0.8152 acc_train: 0.8089 loss_val: 0.8041 acc_val: 0.8672 time: 0.0083s\n",
      "Epoch: 1187 loss_train: 0.8248 acc_train: 0.8006 loss_val: 0.8038 acc_val: 0.8672 time: 0.0078s\n",
      "Epoch: 1188 loss_train: 0.8103 acc_train: 0.8075 loss_val: 0.8035 acc_val: 0.8635 time: 0.0093s\n",
      "Epoch: 1189 loss_train: 0.8188 acc_train: 0.8093 loss_val: 0.8031 acc_val: 0.8672 time: 0.0083s\n",
      "Epoch: 1190 loss_train: 0.8110 acc_train: 0.7964 loss_val: 0.8028 acc_val: 0.8672 time: 0.0085s\n",
      "Epoch: 1191 loss_train: 0.7926 acc_train: 0.8098 loss_val: 0.8025 acc_val: 0.8672 time: 0.0087s\n",
      "Epoch: 1192 loss_train: 0.8002 acc_train: 0.8121 loss_val: 0.8021 acc_val: 0.8672 time: 0.0076s\n",
      "Epoch: 1193 loss_train: 0.8271 acc_train: 0.7955 loss_val: 0.8018 acc_val: 0.8635 time: 0.0092s\n",
      "Epoch: 1194 loss_train: 0.7948 acc_train: 0.8301 loss_val: 0.8015 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1195 loss_train: 0.8224 acc_train: 0.8070 loss_val: 0.8011 acc_val: 0.8635 time: 0.0086s\n",
      "Epoch: 1196 loss_train: 0.8177 acc_train: 0.8121 loss_val: 0.8007 acc_val: 0.8598 time: 0.0086s\n",
      "Epoch: 1197 loss_train: 0.8124 acc_train: 0.8075 loss_val: 0.8002 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1198 loss_train: 0.7978 acc_train: 0.8176 loss_val: 0.7997 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1199 loss_train: 0.7996 acc_train: 0.8066 loss_val: 0.7991 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1200 loss_train: 0.8196 acc_train: 0.8033 loss_val: 0.7985 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1201 loss_train: 0.8096 acc_train: 0.8024 loss_val: 0.7978 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1202 loss_train: 0.8015 acc_train: 0.8033 loss_val: 0.7971 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1203 loss_train: 0.8147 acc_train: 0.8158 loss_val: 0.7964 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1204 loss_train: 0.8240 acc_train: 0.8079 loss_val: 0.7958 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1205 loss_train: 0.8201 acc_train: 0.8015 loss_val: 0.7953 acc_val: 0.8672 time: 0.0082s\n",
      "Epoch: 1206 loss_train: 0.8022 acc_train: 0.8047 loss_val: 0.7948 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1207 loss_train: 0.7985 acc_train: 0.8102 loss_val: 0.7943 acc_val: 0.8635 time: 0.0086s\n",
      "Epoch: 1208 loss_train: 0.8177 acc_train: 0.8042 loss_val: 0.7939 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1209 loss_train: 0.8141 acc_train: 0.7936 loss_val: 0.7936 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1210 loss_train: 0.8005 acc_train: 0.8112 loss_val: 0.7933 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1211 loss_train: 0.8127 acc_train: 0.8195 loss_val: 0.7929 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1212 loss_train: 0.7991 acc_train: 0.8093 loss_val: 0.7925 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1213 loss_train: 0.7897 acc_train: 0.8158 loss_val: 0.7921 acc_val: 0.8635 time: 0.0076s\n",
      "Epoch: 1214 loss_train: 0.8085 acc_train: 0.7913 loss_val: 0.7917 acc_val: 0.8635 time: 0.0075s\n",
      "Epoch: 1215 loss_train: 0.7888 acc_train: 0.8079 loss_val: 0.7914 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1216 loss_train: 0.7903 acc_train: 0.8056 loss_val: 0.7911 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1217 loss_train: 0.8040 acc_train: 0.8126 loss_val: 0.7908 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1218 loss_train: 0.8090 acc_train: 0.8070 loss_val: 0.7905 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1219 loss_train: 0.8003 acc_train: 0.8084 loss_val: 0.7902 acc_val: 0.8635 time: 0.0075s\n",
      "Epoch: 1220 loss_train: 0.7847 acc_train: 0.8264 loss_val: 0.7900 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1221 loss_train: 0.8080 acc_train: 0.8001 loss_val: 0.7896 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1222 loss_train: 0.8049 acc_train: 0.7978 loss_val: 0.7892 acc_val: 0.8672 time: 0.0085s\n",
      "Epoch: 1223 loss_train: 0.7997 acc_train: 0.8163 loss_val: 0.7888 acc_val: 0.8672 time: 0.0082s\n",
      "Epoch: 1224 loss_train: 0.7961 acc_train: 0.8126 loss_val: 0.7884 acc_val: 0.8708 time: 0.0078s\n",
      "Epoch: 1225 loss_train: 0.7889 acc_train: 0.8144 loss_val: 0.7880 acc_val: 0.8708 time: 0.0073s\n",
      "Epoch: 1226 loss_train: 0.8005 acc_train: 0.8218 loss_val: 0.7876 acc_val: 0.8672 time: 0.0078s\n",
      "Epoch: 1227 loss_train: 0.8174 acc_train: 0.7904 loss_val: 0.7872 acc_val: 0.8672 time: 0.0082s\n",
      "Epoch: 1228 loss_train: 0.7916 acc_train: 0.8176 loss_val: 0.7867 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1229 loss_train: 0.8033 acc_train: 0.8070 loss_val: 0.7862 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1230 loss_train: 0.7927 acc_train: 0.8024 loss_val: 0.7858 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1231 loss_train: 0.8068 acc_train: 0.8061 loss_val: 0.7852 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1232 loss_train: 0.7872 acc_train: 0.8102 loss_val: 0.7847 acc_val: 0.8598 time: 0.0079s\n",
      "Epoch: 1233 loss_train: 0.7778 acc_train: 0.8204 loss_val: 0.7841 acc_val: 0.8561 time: 0.0083s\n",
      "Epoch: 1234 loss_train: 0.7939 acc_train: 0.8121 loss_val: 0.7835 acc_val: 0.8561 time: 0.0082s\n",
      "Epoch: 1235 loss_train: 0.7710 acc_train: 0.8158 loss_val: 0.7830 acc_val: 0.8561 time: 0.0078s\n",
      "Epoch: 1236 loss_train: 0.7795 acc_train: 0.8204 loss_val: 0.7825 acc_val: 0.8561 time: 0.0078s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1237 loss_train: 0.7961 acc_train: 0.8001 loss_val: 0.7820 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1238 loss_train: 0.7941 acc_train: 0.8139 loss_val: 0.7815 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1239 loss_train: 0.8080 acc_train: 0.8019 loss_val: 0.7811 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1240 loss_train: 0.7730 acc_train: 0.8223 loss_val: 0.7807 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1241 loss_train: 0.8078 acc_train: 0.8195 loss_val: 0.7803 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1242 loss_train: 0.7893 acc_train: 0.8139 loss_val: 0.7799 acc_val: 0.8635 time: 0.0073s\n",
      "Epoch: 1243 loss_train: 0.7882 acc_train: 0.8250 loss_val: 0.7795 acc_val: 0.8635 time: 0.0073s\n",
      "Epoch: 1244 loss_train: 0.8091 acc_train: 0.8079 loss_val: 0.7791 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1245 loss_train: 0.7876 acc_train: 0.8121 loss_val: 0.7786 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1246 loss_train: 0.7696 acc_train: 0.8301 loss_val: 0.7782 acc_val: 0.8635 time: 0.0080s\n",
      "Epoch: 1247 loss_train: 0.8014 acc_train: 0.8264 loss_val: 0.7777 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1248 loss_train: 0.7967 acc_train: 0.8066 loss_val: 0.7773 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1249 loss_train: 0.8011 acc_train: 0.8227 loss_val: 0.7769 acc_val: 0.8561 time: 0.0083s\n",
      "Epoch: 1250 loss_train: 0.7723 acc_train: 0.8218 loss_val: 0.7765 acc_val: 0.8561 time: 0.0084s\n",
      "Epoch: 1251 loss_train: 0.7651 acc_train: 0.8098 loss_val: 0.7761 acc_val: 0.8561 time: 0.0086s\n",
      "Epoch: 1252 loss_train: 0.7754 acc_train: 0.8116 loss_val: 0.7757 acc_val: 0.8561 time: 0.0078s\n",
      "Epoch: 1253 loss_train: 0.7921 acc_train: 0.8135 loss_val: 0.7752 acc_val: 0.8561 time: 0.0075s\n",
      "Epoch: 1254 loss_train: 0.7700 acc_train: 0.8209 loss_val: 0.7748 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1255 loss_train: 0.7998 acc_train: 0.8066 loss_val: 0.7744 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1256 loss_train: 0.7769 acc_train: 0.8121 loss_val: 0.7740 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1257 loss_train: 0.7823 acc_train: 0.8061 loss_val: 0.7737 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1258 loss_train: 0.7813 acc_train: 0.8102 loss_val: 0.7734 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1259 loss_train: 0.7871 acc_train: 0.8232 loss_val: 0.7730 acc_val: 0.8635 time: 0.0088s\n",
      "Epoch: 1260 loss_train: 0.7991 acc_train: 0.7955 loss_val: 0.7727 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1261 loss_train: 0.7722 acc_train: 0.8190 loss_val: 0.7724 acc_val: 0.8598 time: 0.0084s\n",
      "Epoch: 1262 loss_train: 0.7667 acc_train: 0.8172 loss_val: 0.7721 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1263 loss_train: 0.7640 acc_train: 0.8269 loss_val: 0.7716 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1264 loss_train: 0.7720 acc_train: 0.8264 loss_val: 0.7712 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1265 loss_train: 0.7817 acc_train: 0.8227 loss_val: 0.7707 acc_val: 0.8635 time: 0.0079s\n",
      "Epoch: 1266 loss_train: 0.7569 acc_train: 0.8227 loss_val: 0.7703 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1267 loss_train: 0.7610 acc_train: 0.8227 loss_val: 0.7698 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1268 loss_train: 0.7727 acc_train: 0.8213 loss_val: 0.7694 acc_val: 0.8635 time: 0.0079s\n",
      "Epoch: 1269 loss_train: 0.7738 acc_train: 0.8153 loss_val: 0.7691 acc_val: 0.8635 time: 0.0074s\n",
      "Epoch: 1270 loss_train: 0.7822 acc_train: 0.8098 loss_val: 0.7687 acc_val: 0.8635 time: 0.0075s\n",
      "Epoch: 1271 loss_train: 0.7815 acc_train: 0.8172 loss_val: 0.7683 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1272 loss_train: 0.7827 acc_train: 0.8089 loss_val: 0.7679 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1273 loss_train: 0.7791 acc_train: 0.8264 loss_val: 0.7675 acc_val: 0.8598 time: 0.0084s\n",
      "Epoch: 1274 loss_train: 0.7665 acc_train: 0.8269 loss_val: 0.7671 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1275 loss_train: 0.7488 acc_train: 0.8310 loss_val: 0.7667 acc_val: 0.8598 time: 0.0080s\n",
      "Epoch: 1276 loss_train: 0.7613 acc_train: 0.8287 loss_val: 0.7663 acc_val: 0.8598 time: 0.0079s\n",
      "Epoch: 1277 loss_train: 0.7554 acc_train: 0.8255 loss_val: 0.7658 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1278 loss_train: 0.7629 acc_train: 0.8227 loss_val: 0.7654 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1279 loss_train: 0.7540 acc_train: 0.8259 loss_val: 0.7649 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1280 loss_train: 0.7604 acc_train: 0.8273 loss_val: 0.7644 acc_val: 0.8635 time: 0.0075s\n",
      "Epoch: 1281 loss_train: 0.7642 acc_train: 0.8172 loss_val: 0.7640 acc_val: 0.8635 time: 0.0079s\n",
      "Epoch: 1282 loss_train: 0.7675 acc_train: 0.8218 loss_val: 0.7636 acc_val: 0.8635 time: 0.0090s\n",
      "Epoch: 1283 loss_train: 0.7662 acc_train: 0.8296 loss_val: 0.7631 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1284 loss_train: 0.7650 acc_train: 0.8241 loss_val: 0.7628 acc_val: 0.8635 time: 0.0086s\n",
      "Epoch: 1285 loss_train: 0.7767 acc_train: 0.8144 loss_val: 0.7624 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1286 loss_train: 0.7825 acc_train: 0.8066 loss_val: 0.7620 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1287 loss_train: 0.7701 acc_train: 0.8204 loss_val: 0.7616 acc_val: 0.8635 time: 0.0080s\n",
      "Epoch: 1288 loss_train: 0.7739 acc_train: 0.8144 loss_val: 0.7613 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1289 loss_train: 0.7649 acc_train: 0.8246 loss_val: 0.7609 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1290 loss_train: 0.7797 acc_train: 0.8186 loss_val: 0.7605 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1291 loss_train: 0.7572 acc_train: 0.8273 loss_val: 0.7602 acc_val: 0.8635 time: 0.0076s\n",
      "Epoch: 1292 loss_train: 0.7673 acc_train: 0.8223 loss_val: 0.7599 acc_val: 0.8635 time: 0.0079s\n",
      "Epoch: 1293 loss_train: 0.7788 acc_train: 0.8093 loss_val: 0.7597 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1294 loss_train: 0.7655 acc_train: 0.8163 loss_val: 0.7594 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1295 loss_train: 0.7835 acc_train: 0.8195 loss_val: 0.7592 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1296 loss_train: 0.7786 acc_train: 0.8158 loss_val: 0.7589 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1297 loss_train: 0.7683 acc_train: 0.8172 loss_val: 0.7586 acc_val: 0.8598 time: 0.0079s\n",
      "Epoch: 1298 loss_train: 0.7760 acc_train: 0.8255 loss_val: 0.7583 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1299 loss_train: 0.7483 acc_train: 0.8361 loss_val: 0.7579 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1300 loss_train: 0.7583 acc_train: 0.8176 loss_val: 0.7574 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1301 loss_train: 0.7755 acc_train: 0.8181 loss_val: 0.7569 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1302 loss_train: 0.7594 acc_train: 0.8232 loss_val: 0.7565 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1303 loss_train: 0.7655 acc_train: 0.8236 loss_val: 0.7561 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1304 loss_train: 0.7659 acc_train: 0.8324 loss_val: 0.7557 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1305 loss_train: 0.7501 acc_train: 0.8195 loss_val: 0.7553 acc_val: 0.8598 time: 0.0084s\n",
      "Epoch: 1306 loss_train: 0.7704 acc_train: 0.8250 loss_val: 0.7550 acc_val: 0.8598 time: 0.0085s\n",
      "Epoch: 1307 loss_train: 0.7544 acc_train: 0.8296 loss_val: 0.7546 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1308 loss_train: 0.7561 acc_train: 0.8176 loss_val: 0.7542 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1309 loss_train: 0.7629 acc_train: 0.8250 loss_val: 0.7538 acc_val: 0.8635 time: 0.0075s\n",
      "Epoch: 1310 loss_train: 0.7558 acc_train: 0.8296 loss_val: 0.7534 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1311 loss_train: 0.7590 acc_train: 0.8199 loss_val: 0.7531 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1312 loss_train: 0.7713 acc_train: 0.8250 loss_val: 0.7528 acc_val: 0.8598 time: 0.0076s\n",
      "Epoch: 1313 loss_train: 0.7513 acc_train: 0.8315 loss_val: 0.7526 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1314 loss_train: 0.7725 acc_train: 0.8093 loss_val: 0.7522 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1315 loss_train: 0.7444 acc_train: 0.8209 loss_val: 0.7518 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1316 loss_train: 0.7489 acc_train: 0.8209 loss_val: 0.7514 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1317 loss_train: 0.7558 acc_train: 0.8199 loss_val: 0.7511 acc_val: 0.8635 time: 0.0087s\n",
      "Epoch: 1318 loss_train: 0.7604 acc_train: 0.8259 loss_val: 0.7507 acc_val: 0.8635 time: 0.0076s\n",
      "Epoch: 1319 loss_train: 0.7383 acc_train: 0.8223 loss_val: 0.7503 acc_val: 0.8635 time: 0.0072s\n",
      "Epoch: 1320 loss_train: 0.7594 acc_train: 0.8213 loss_val: 0.7500 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1321 loss_train: 0.7459 acc_train: 0.8250 loss_val: 0.7496 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1322 loss_train: 0.7530 acc_train: 0.8269 loss_val: 0.7492 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1323 loss_train: 0.7489 acc_train: 0.8255 loss_val: 0.7489 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1324 loss_train: 0.7597 acc_train: 0.8255 loss_val: 0.7485 acc_val: 0.8598 time: 0.0078s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1325 loss_train: 0.7513 acc_train: 0.8195 loss_val: 0.7481 acc_val: 0.8598 time: 0.0087s\n",
      "Epoch: 1326 loss_train: 0.7503 acc_train: 0.8333 loss_val: 0.7477 acc_val: 0.8561 time: 0.0082s\n",
      "Epoch: 1327 loss_train: 0.7335 acc_train: 0.8181 loss_val: 0.7472 acc_val: 0.8561 time: 0.0083s\n",
      "Epoch: 1328 loss_train: 0.7393 acc_train: 0.8301 loss_val: 0.7467 acc_val: 0.8561 time: 0.0086s\n",
      "Epoch: 1329 loss_train: 0.7676 acc_train: 0.8024 loss_val: 0.7463 acc_val: 0.8561 time: 0.0078s\n",
      "Epoch: 1330 loss_train: 0.7471 acc_train: 0.8218 loss_val: 0.7459 acc_val: 0.8561 time: 0.0086s\n",
      "Epoch: 1331 loss_train: 0.7616 acc_train: 0.8227 loss_val: 0.7456 acc_val: 0.8561 time: 0.0087s\n",
      "Epoch: 1332 loss_train: 0.7396 acc_train: 0.8241 loss_val: 0.7453 acc_val: 0.8598 time: 0.0085s\n",
      "Epoch: 1333 loss_train: 0.7553 acc_train: 0.8319 loss_val: 0.7451 acc_val: 0.8598 time: 0.0085s\n",
      "Epoch: 1334 loss_train: 0.7649 acc_train: 0.8084 loss_val: 0.7448 acc_val: 0.8598 time: 0.0077s\n",
      "Epoch: 1335 loss_train: 0.7507 acc_train: 0.8352 loss_val: 0.7444 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1336 loss_train: 0.7292 acc_train: 0.8389 loss_val: 0.7442 acc_val: 0.8635 time: 0.0072s\n",
      "Epoch: 1337 loss_train: 0.7370 acc_train: 0.8416 loss_val: 0.7439 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1338 loss_train: 0.7522 acc_train: 0.8352 loss_val: 0.7435 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1339 loss_train: 0.7641 acc_train: 0.8209 loss_val: 0.7431 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1340 loss_train: 0.7489 acc_train: 0.8195 loss_val: 0.7427 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1341 loss_train: 0.7474 acc_train: 0.8259 loss_val: 0.7424 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1342 loss_train: 0.7324 acc_train: 0.8398 loss_val: 0.7420 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1343 loss_train: 0.7376 acc_train: 0.8343 loss_val: 0.7417 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1344 loss_train: 0.7602 acc_train: 0.8255 loss_val: 0.7412 acc_val: 0.8635 time: 0.0086s\n",
      "Epoch: 1345 loss_train: 0.7728 acc_train: 0.8356 loss_val: 0.7407 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1346 loss_train: 0.7416 acc_train: 0.8315 loss_val: 0.7401 acc_val: 0.8635 time: 0.0075s\n",
      "Epoch: 1347 loss_train: 0.7366 acc_train: 0.8204 loss_val: 0.7397 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1348 loss_train: 0.7260 acc_train: 0.8407 loss_val: 0.7392 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1349 loss_train: 0.7422 acc_train: 0.8186 loss_val: 0.7388 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1350 loss_train: 0.7322 acc_train: 0.8190 loss_val: 0.7385 acc_val: 0.8598 time: 0.0079s\n",
      "Epoch: 1351 loss_train: 0.7301 acc_train: 0.8292 loss_val: 0.7381 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1352 loss_train: 0.7205 acc_train: 0.8380 loss_val: 0.7378 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1353 loss_train: 0.7609 acc_train: 0.8186 loss_val: 0.7374 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1354 loss_train: 0.7211 acc_train: 0.8421 loss_val: 0.7372 acc_val: 0.8598 time: 0.0085s\n",
      "Epoch: 1355 loss_train: 0.7493 acc_train: 0.8296 loss_val: 0.7369 acc_val: 0.8598 time: 0.0086s\n",
      "Epoch: 1356 loss_train: 0.7222 acc_train: 0.8366 loss_val: 0.7366 acc_val: 0.8598 time: 0.0076s\n",
      "Epoch: 1357 loss_train: 0.7543 acc_train: 0.8301 loss_val: 0.7364 acc_val: 0.8598 time: 0.0074s\n",
      "Epoch: 1358 loss_train: 0.7345 acc_train: 0.8296 loss_val: 0.7362 acc_val: 0.8598 time: 0.0072s\n",
      "Epoch: 1359 loss_train: 0.7558 acc_train: 0.8186 loss_val: 0.7359 acc_val: 0.8598 time: 0.0081s\n",
      "Epoch: 1360 loss_train: 0.7391 acc_train: 0.8356 loss_val: 0.7356 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1361 loss_train: 0.7387 acc_train: 0.8315 loss_val: 0.7353 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1362 loss_train: 0.7438 acc_train: 0.8255 loss_val: 0.7350 acc_val: 0.8598 time: 0.0078s\n",
      "Epoch: 1363 loss_train: 0.7467 acc_train: 0.8246 loss_val: 0.7346 acc_val: 0.8598 time: 0.0082s\n",
      "Epoch: 1364 loss_train: 0.7347 acc_train: 0.8319 loss_val: 0.7343 acc_val: 0.8598 time: 0.0083s\n",
      "Epoch: 1365 loss_train: 0.7366 acc_train: 0.8319 loss_val: 0.7340 acc_val: 0.8561 time: 0.0084s\n",
      "Epoch: 1366 loss_train: 0.7209 acc_train: 0.8398 loss_val: 0.7336 acc_val: 0.8561 time: 0.0088s\n",
      "Epoch: 1367 loss_train: 0.7380 acc_train: 0.8310 loss_val: 0.7332 acc_val: 0.8561 time: 0.0076s\n",
      "Epoch: 1368 loss_train: 0.7385 acc_train: 0.8241 loss_val: 0.7328 acc_val: 0.8598 time: 0.0073s\n",
      "Epoch: 1369 loss_train: 0.7246 acc_train: 0.8407 loss_val: 0.7323 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1370 loss_train: 0.7277 acc_train: 0.8301 loss_val: 0.7318 acc_val: 0.8635 time: 0.0084s\n",
      "Epoch: 1371 loss_train: 0.7383 acc_train: 0.8347 loss_val: 0.7312 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1372 loss_train: 0.7323 acc_train: 0.8338 loss_val: 0.7306 acc_val: 0.8635 time: 0.0080s\n",
      "Epoch: 1373 loss_train: 0.7378 acc_train: 0.8301 loss_val: 0.7301 acc_val: 0.8635 time: 0.0078s\n",
      "Epoch: 1374 loss_train: 0.7321 acc_train: 0.8306 loss_val: 0.7297 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1375 loss_train: 0.7327 acc_train: 0.8444 loss_val: 0.7292 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1376 loss_train: 0.7495 acc_train: 0.8209 loss_val: 0.7288 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1377 loss_train: 0.7258 acc_train: 0.8370 loss_val: 0.7285 acc_val: 0.8635 time: 0.0087s\n",
      "Epoch: 1378 loss_train: 0.7459 acc_train: 0.8338 loss_val: 0.7282 acc_val: 0.8635 time: 0.0077s\n",
      "Epoch: 1379 loss_train: 0.7321 acc_train: 0.8319 loss_val: 0.7279 acc_val: 0.8635 time: 0.0074s\n",
      "Epoch: 1380 loss_train: 0.7511 acc_train: 0.8310 loss_val: 0.7276 acc_val: 0.8635 time: 0.0072s\n",
      "Epoch: 1381 loss_train: 0.7281 acc_train: 0.8407 loss_val: 0.7274 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1382 loss_train: 0.7420 acc_train: 0.8241 loss_val: 0.7271 acc_val: 0.8635 time: 0.0081s\n",
      "Epoch: 1383 loss_train: 0.7352 acc_train: 0.8264 loss_val: 0.7268 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1384 loss_train: 0.7395 acc_train: 0.8384 loss_val: 0.7265 acc_val: 0.8635 time: 0.0079s\n",
      "Epoch: 1385 loss_train: 0.7353 acc_train: 0.8324 loss_val: 0.7262 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1386 loss_train: 0.7456 acc_train: 0.8287 loss_val: 0.7259 acc_val: 0.8635 time: 0.0083s\n",
      "Epoch: 1387 loss_train: 0.7396 acc_train: 0.8269 loss_val: 0.7256 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1388 loss_train: 0.7314 acc_train: 0.8199 loss_val: 0.7252 acc_val: 0.8635 time: 0.0085s\n",
      "Epoch: 1389 loss_train: 0.7364 acc_train: 0.8223 loss_val: 0.7249 acc_val: 0.8672 time: 0.0078s\n",
      "Epoch: 1390 loss_train: 0.7382 acc_train: 0.8144 loss_val: 0.7247 acc_val: 0.8672 time: 0.0085s\n",
      "Epoch: 1391 loss_train: 0.7381 acc_train: 0.8393 loss_val: 0.7244 acc_val: 0.8672 time: 0.0085s\n",
      "Epoch: 1392 loss_train: 0.7112 acc_train: 0.8380 loss_val: 0.7241 acc_val: 0.8672 time: 0.0084s\n",
      "Epoch: 1393 loss_train: 0.7324 acc_train: 0.8283 loss_val: 0.7238 acc_val: 0.8672 time: 0.0085s\n",
      "Epoch: 1394 loss_train: 0.7151 acc_train: 0.8319 loss_val: 0.7235 acc_val: 0.8708 time: 0.0078s\n",
      "Epoch: 1395 loss_train: 0.7283 acc_train: 0.8430 loss_val: 0.7232 acc_val: 0.8708 time: 0.0076s\n",
      "Epoch: 1396 loss_train: 0.7321 acc_train: 0.8319 loss_val: 0.7229 acc_val: 0.8708 time: 0.0072s\n",
      "Epoch: 1397 loss_train: 0.7495 acc_train: 0.8315 loss_val: 0.7226 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1398 loss_train: 0.7243 acc_train: 0.8407 loss_val: 0.7223 acc_val: 0.8708 time: 0.0081s\n",
      "Epoch: 1399 loss_train: 0.7266 acc_train: 0.8306 loss_val: 0.7219 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1400 loss_train: 0.7178 acc_train: 0.8370 loss_val: 0.7216 acc_val: 0.8672 time: 0.0077s\n",
      "Epoch: 1401 loss_train: 0.7478 acc_train: 0.8241 loss_val: 0.7212 acc_val: 0.8672 time: 0.0085s\n",
      "Epoch: 1402 loss_train: 0.7420 acc_train: 0.8273 loss_val: 0.7208 acc_val: 0.8672 time: 0.0082s\n",
      "Epoch: 1403 loss_train: 0.7311 acc_train: 0.8310 loss_val: 0.7204 acc_val: 0.8708 time: 0.0084s\n",
      "Epoch: 1404 loss_train: 0.7189 acc_train: 0.8296 loss_val: 0.7199 acc_val: 0.8708 time: 0.0085s\n",
      "Epoch: 1405 loss_train: 0.7245 acc_train: 0.8343 loss_val: 0.7195 acc_val: 0.8708 time: 0.0077s\n",
      "Epoch: 1406 loss_train: 0.7478 acc_train: 0.8278 loss_val: 0.7190 acc_val: 0.8708 time: 0.0075s\n",
      "Epoch: 1407 loss_train: 0.7374 acc_train: 0.8310 loss_val: 0.7185 acc_val: 0.8708 time: 0.0072s\n",
      "Epoch: 1408 loss_train: 0.7377 acc_train: 0.8333 loss_val: 0.7180 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1409 loss_train: 0.7378 acc_train: 0.8292 loss_val: 0.7176 acc_val: 0.8708 time: 0.0081s\n",
      "Epoch: 1410 loss_train: 0.7196 acc_train: 0.8301 loss_val: 0.7172 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1411 loss_train: 0.7380 acc_train: 0.8218 loss_val: 0.7168 acc_val: 0.8708 time: 0.0079s\n",
      "Epoch: 1412 loss_train: 0.7170 acc_train: 0.8384 loss_val: 0.7164 acc_val: 0.8708 time: 0.0083s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1413 loss_train: 0.7081 acc_train: 0.8426 loss_val: 0.7162 acc_val: 0.8708 time: 0.0091s\n",
      "Epoch: 1414 loss_train: 0.7280 acc_train: 0.8375 loss_val: 0.7159 acc_val: 0.8708 time: 0.0085s\n",
      "Epoch: 1415 loss_train: 0.7195 acc_train: 0.8324 loss_val: 0.7158 acc_val: 0.8708 time: 0.0086s\n",
      "Epoch: 1416 loss_train: 0.7293 acc_train: 0.8255 loss_val: 0.7155 acc_val: 0.8708 time: 0.0078s\n",
      "Epoch: 1417 loss_train: 0.7417 acc_train: 0.8324 loss_val: 0.7153 acc_val: 0.8708 time: 0.0077s\n",
      "Epoch: 1418 loss_train: 0.7209 acc_train: 0.8366 loss_val: 0.7151 acc_val: 0.8708 time: 0.0077s\n",
      "Epoch: 1419 loss_train: 0.7567 acc_train: 0.8333 loss_val: 0.7149 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1420 loss_train: 0.7310 acc_train: 0.8315 loss_val: 0.7148 acc_val: 0.8708 time: 0.0081s\n",
      "Epoch: 1421 loss_train: 0.7197 acc_train: 0.8329 loss_val: 0.7146 acc_val: 0.8708 time: 0.0077s\n",
      "Epoch: 1422 loss_train: 0.7271 acc_train: 0.8241 loss_val: 0.7143 acc_val: 0.8708 time: 0.0079s\n",
      "Epoch: 1423 loss_train: 0.7159 acc_train: 0.8403 loss_val: 0.7140 acc_val: 0.8708 time: 0.0081s\n",
      "Epoch: 1424 loss_train: 0.7383 acc_train: 0.8236 loss_val: 0.7137 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1425 loss_train: 0.7235 acc_train: 0.8269 loss_val: 0.7133 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1426 loss_train: 0.7019 acc_train: 0.8453 loss_val: 0.7130 acc_val: 0.8708 time: 0.0086s\n",
      "Epoch: 1427 loss_train: 0.7073 acc_train: 0.8430 loss_val: 0.7125 acc_val: 0.8708 time: 0.0077s\n",
      "Epoch: 1428 loss_train: 0.7181 acc_train: 0.8250 loss_val: 0.7122 acc_val: 0.8708 time: 0.0073s\n",
      "Epoch: 1429 loss_train: 0.7158 acc_train: 0.8389 loss_val: 0.7118 acc_val: 0.8708 time: 0.0072s\n",
      "Epoch: 1430 loss_train: 0.7073 acc_train: 0.8389 loss_val: 0.7114 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1431 loss_train: 0.7183 acc_train: 0.8467 loss_val: 0.7111 acc_val: 0.8708 time: 0.0081s\n",
      "Epoch: 1432 loss_train: 0.7163 acc_train: 0.8310 loss_val: 0.7108 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1433 loss_train: 0.7095 acc_train: 0.8319 loss_val: 0.7106 acc_val: 0.8708 time: 0.0079s\n",
      "Epoch: 1434 loss_train: 0.7070 acc_train: 0.8458 loss_val: 0.7104 acc_val: 0.8708 time: 0.0084s\n",
      "Epoch: 1435 loss_train: 0.7221 acc_train: 0.8338 loss_val: 0.7102 acc_val: 0.8708 time: 0.0089s\n",
      "Epoch: 1436 loss_train: 0.7313 acc_train: 0.8306 loss_val: 0.7099 acc_val: 0.8708 time: 0.0085s\n",
      "Epoch: 1437 loss_train: 0.6916 acc_train: 0.8393 loss_val: 0.7095 acc_val: 0.8708 time: 0.0086s\n",
      "Epoch: 1438 loss_train: 0.7174 acc_train: 0.8306 loss_val: 0.7092 acc_val: 0.8708 time: 0.0077s\n",
      "Epoch: 1439 loss_train: 0.6987 acc_train: 0.8273 loss_val: 0.7090 acc_val: 0.8708 time: 0.0074s\n",
      "Epoch: 1440 loss_train: 0.7351 acc_train: 0.8269 loss_val: 0.7088 acc_val: 0.8708 time: 0.0072s\n",
      "Epoch: 1441 loss_train: 0.7124 acc_train: 0.8333 loss_val: 0.7085 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1442 loss_train: 0.6957 acc_train: 0.8356 loss_val: 0.7083 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1443 loss_train: 0.7088 acc_train: 0.8370 loss_val: 0.7081 acc_val: 0.8708 time: 0.0084s\n",
      "Epoch: 1444 loss_train: 0.7067 acc_train: 0.8278 loss_val: 0.7079 acc_val: 0.8708 time: 0.0078s\n",
      "Epoch: 1445 loss_train: 0.7056 acc_train: 0.8403 loss_val: 0.7078 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1446 loss_train: 0.7154 acc_train: 0.8398 loss_val: 0.7076 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1447 loss_train: 0.7174 acc_train: 0.8347 loss_val: 0.7075 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1448 loss_train: 0.7064 acc_train: 0.8366 loss_val: 0.7073 acc_val: 0.8708 time: 0.0085s\n",
      "Epoch: 1449 loss_train: 0.6989 acc_train: 0.8366 loss_val: 0.7070 acc_val: 0.8708 time: 0.0078s\n",
      "Epoch: 1450 loss_train: 0.7006 acc_train: 0.8370 loss_val: 0.7068 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1451 loss_train: 0.6905 acc_train: 0.8301 loss_val: 0.7065 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1452 loss_train: 0.7089 acc_train: 0.8319 loss_val: 0.7062 acc_val: 0.8708 time: 0.0085s\n",
      "Epoch: 1453 loss_train: 0.7179 acc_train: 0.8366 loss_val: 0.7060 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1454 loss_train: 0.7065 acc_train: 0.8472 loss_val: 0.7056 acc_val: 0.8708 time: 0.0075s\n",
      "Epoch: 1455 loss_train: 0.7321 acc_train: 0.8343 loss_val: 0.7053 acc_val: 0.8672 time: 0.0075s\n",
      "Epoch: 1456 loss_train: 0.7045 acc_train: 0.8352 loss_val: 0.7050 acc_val: 0.8672 time: 0.0077s\n",
      "Epoch: 1457 loss_train: 0.7149 acc_train: 0.8356 loss_val: 0.7047 acc_val: 0.8635 time: 0.0086s\n",
      "Epoch: 1458 loss_train: 0.6971 acc_train: 0.8453 loss_val: 0.7044 acc_val: 0.8635 time: 0.0082s\n",
      "Epoch: 1459 loss_train: 0.6989 acc_train: 0.8523 loss_val: 0.7040 acc_val: 0.8672 time: 0.0084s\n",
      "Epoch: 1460 loss_train: 0.7145 acc_train: 0.8393 loss_val: 0.7037 acc_val: 0.8672 time: 0.0074s\n",
      "Epoch: 1461 loss_train: 0.7132 acc_train: 0.8403 loss_val: 0.7034 acc_val: 0.8672 time: 0.0086s\n",
      "Epoch: 1462 loss_train: 0.7204 acc_train: 0.8301 loss_val: 0.7031 acc_val: 0.8672 time: 0.0082s\n",
      "Epoch: 1463 loss_train: 0.6888 acc_train: 0.8416 loss_val: 0.7027 acc_val: 0.8708 time: 0.0084s\n",
      "Epoch: 1464 loss_train: 0.6985 acc_train: 0.8393 loss_val: 0.7023 acc_val: 0.8708 time: 0.0084s\n",
      "Epoch: 1465 loss_train: 0.7099 acc_train: 0.8306 loss_val: 0.7019 acc_val: 0.8745 time: 0.0078s\n",
      "Epoch: 1466 loss_train: 0.7088 acc_train: 0.8324 loss_val: 0.7014 acc_val: 0.8745 time: 0.0076s\n",
      "Epoch: 1467 loss_train: 0.7063 acc_train: 0.8356 loss_val: 0.7010 acc_val: 0.8708 time: 0.0074s\n",
      "Epoch: 1468 loss_train: 0.6975 acc_train: 0.8476 loss_val: 0.7006 acc_val: 0.8708 time: 0.0081s\n",
      "Epoch: 1469 loss_train: 0.7053 acc_train: 0.8329 loss_val: 0.7001 acc_val: 0.8708 time: 0.0082s\n",
      "Epoch: 1470 loss_train: 0.7068 acc_train: 0.8370 loss_val: 0.6997 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1471 loss_train: 0.7059 acc_train: 0.8375 loss_val: 0.6994 acc_val: 0.8708 time: 0.0075s\n",
      "Epoch: 1472 loss_train: 0.7072 acc_train: 0.8430 loss_val: 0.6989 acc_val: 0.8708 time: 0.0086s\n",
      "Epoch: 1473 loss_train: 0.7165 acc_train: 0.8500 loss_val: 0.6985 acc_val: 0.8708 time: 0.0083s\n",
      "Epoch: 1474 loss_train: 0.6993 acc_train: 0.8407 loss_val: 0.6981 acc_val: 0.8708 time: 0.0086s\n",
      "Epoch: 1475 loss_train: 0.7113 acc_train: 0.8366 loss_val: 0.6977 acc_val: 0.8745 time: 0.0083s\n",
      "Epoch: 1476 loss_train: 0.6986 acc_train: 0.8440 loss_val: 0.6974 acc_val: 0.8745 time: 0.0079s\n",
      "Epoch: 1477 loss_train: 0.7062 acc_train: 0.8324 loss_val: 0.6970 acc_val: 0.8745 time: 0.0074s\n",
      "Epoch: 1478 loss_train: 0.6908 acc_train: 0.8440 loss_val: 0.6967 acc_val: 0.8745 time: 0.0074s\n",
      "Epoch: 1479 loss_train: 0.6944 acc_train: 0.8467 loss_val: 0.6964 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1480 loss_train: 0.6843 acc_train: 0.8440 loss_val: 0.6961 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1481 loss_train: 0.7028 acc_train: 0.8338 loss_val: 0.6958 acc_val: 0.8782 time: 0.0084s\n",
      "Epoch: 1482 loss_train: 0.6913 acc_train: 0.8449 loss_val: 0.6956 acc_val: 0.8782 time: 0.0075s\n",
      "Epoch: 1483 loss_train: 0.7025 acc_train: 0.8370 loss_val: 0.6953 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1484 loss_train: 0.7075 acc_train: 0.8398 loss_val: 0.6950 acc_val: 0.8782 time: 0.0084s\n",
      "Epoch: 1485 loss_train: 0.7060 acc_train: 0.8463 loss_val: 0.6947 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1486 loss_train: 0.7013 acc_train: 0.8440 loss_val: 0.6945 acc_val: 0.8782 time: 0.0082s\n",
      "Epoch: 1487 loss_train: 0.7100 acc_train: 0.8380 loss_val: 0.6942 acc_val: 0.8782 time: 0.0103s\n",
      "Epoch: 1488 loss_train: 0.6978 acc_train: 0.8356 loss_val: 0.6940 acc_val: 0.8782 time: 0.0078s\n",
      "Epoch: 1489 loss_train: 0.7417 acc_train: 0.8227 loss_val: 0.6938 acc_val: 0.8782 time: 0.0076s\n",
      "Epoch: 1490 loss_train: 0.7145 acc_train: 0.8319 loss_val: 0.6936 acc_val: 0.8782 time: 0.0087s\n",
      "Epoch: 1491 loss_train: 0.7064 acc_train: 0.8412 loss_val: 0.6935 acc_val: 0.8782 time: 0.0082s\n",
      "Epoch: 1492 loss_train: 0.6847 acc_train: 0.8467 loss_val: 0.6933 acc_val: 0.8782 time: 0.0078s\n",
      "Epoch: 1493 loss_train: 0.7124 acc_train: 0.8333 loss_val: 0.6931 acc_val: 0.8782 time: 0.0079s\n",
      "Epoch: 1494 loss_train: 0.7005 acc_train: 0.8463 loss_val: 0.6929 acc_val: 0.8782 time: 0.0080s\n",
      "Epoch: 1495 loss_train: 0.7050 acc_train: 0.8338 loss_val: 0.6926 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1496 loss_train: 0.7018 acc_train: 0.8366 loss_val: 0.6922 acc_val: 0.8782 time: 0.0084s\n",
      "Epoch: 1497 loss_train: 0.6931 acc_train: 0.8435 loss_val: 0.6919 acc_val: 0.8782 time: 0.0087s\n",
      "Epoch: 1498 loss_train: 0.7033 acc_train: 0.8366 loss_val: 0.6916 acc_val: 0.8782 time: 0.0079s\n",
      "Epoch: 1499 loss_train: 0.6967 acc_train: 0.8333 loss_val: 0.6913 acc_val: 0.8782 time: 0.0078s\n",
      "Epoch: 1500 loss_train: 0.6902 acc_train: 0.8453 loss_val: 0.6911 acc_val: 0.8782 time: 0.0078s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1501 loss_train: 0.7004 acc_train: 0.8398 loss_val: 0.6908 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1502 loss_train: 0.6772 acc_train: 0.8458 loss_val: 0.6906 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1503 loss_train: 0.6791 acc_train: 0.8541 loss_val: 0.6903 acc_val: 0.8782 time: 0.0077s\n",
      "Epoch: 1504 loss_train: 0.6869 acc_train: 0.8389 loss_val: 0.6900 acc_val: 0.8782 time: 0.0080s\n",
      "Epoch: 1505 loss_train: 0.6839 acc_train: 0.8467 loss_val: 0.6898 acc_val: 0.8782 time: 0.0080s\n",
      "Epoch: 1506 loss_train: 0.6964 acc_train: 0.8393 loss_val: 0.6895 acc_val: 0.8782 time: 0.0084s\n",
      "Epoch: 1507 loss_train: 0.6929 acc_train: 0.8370 loss_val: 0.6893 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1508 loss_train: 0.6933 acc_train: 0.8393 loss_val: 0.6890 acc_val: 0.8782 time: 0.0086s\n",
      "Epoch: 1509 loss_train: 0.6915 acc_train: 0.8375 loss_val: 0.6887 acc_val: 0.8782 time: 0.0077s\n",
      "Epoch: 1510 loss_train: 0.6976 acc_train: 0.8449 loss_val: 0.6883 acc_val: 0.8782 time: 0.0082s\n",
      "Epoch: 1511 loss_train: 0.6984 acc_train: 0.8504 loss_val: 0.6880 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1512 loss_train: 0.7094 acc_train: 0.8195 loss_val: 0.6876 acc_val: 0.8782 time: 0.0084s\n",
      "Epoch: 1513 loss_train: 0.6994 acc_train: 0.8403 loss_val: 0.6872 acc_val: 0.8782 time: 0.0085s\n",
      "Epoch: 1514 loss_train: 0.6791 acc_train: 0.8380 loss_val: 0.6869 acc_val: 0.8782 time: 0.0077s\n",
      "Epoch: 1515 loss_train: 0.6972 acc_train: 0.8398 loss_val: 0.6866 acc_val: 0.8782 time: 0.0074s\n",
      "Epoch: 1516 loss_train: 0.7074 acc_train: 0.8301 loss_val: 0.6864 acc_val: 0.8782 time: 0.0072s\n",
      "Epoch: 1517 loss_train: 0.6999 acc_train: 0.8329 loss_val: 0.6861 acc_val: 0.8782 time: 0.0082s\n",
      "Epoch: 1518 loss_train: 0.7114 acc_train: 0.8370 loss_val: 0.6859 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1519 loss_train: 0.7018 acc_train: 0.8319 loss_val: 0.6858 acc_val: 0.8745 time: 0.0083s\n",
      "Epoch: 1520 loss_train: 0.7036 acc_train: 0.8444 loss_val: 0.6857 acc_val: 0.8745 time: 0.0078s\n",
      "Epoch: 1521 loss_train: 0.6874 acc_train: 0.8504 loss_val: 0.6855 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1522 loss_train: 0.7044 acc_train: 0.8504 loss_val: 0.6853 acc_val: 0.8745 time: 0.0083s\n",
      "Epoch: 1523 loss_train: 0.6981 acc_train: 0.8273 loss_val: 0.6851 acc_val: 0.8745 time: 0.0091s\n",
      "Epoch: 1524 loss_train: 0.6920 acc_train: 0.8329 loss_val: 0.6848 acc_val: 0.8782 time: 0.0086s\n",
      "Epoch: 1525 loss_train: 0.6839 acc_train: 0.8361 loss_val: 0.6845 acc_val: 0.8782 time: 0.0077s\n",
      "Epoch: 1526 loss_train: 0.7035 acc_train: 0.8398 loss_val: 0.6842 acc_val: 0.8782 time: 0.0076s\n",
      "Epoch: 1527 loss_train: 0.6878 acc_train: 0.8449 loss_val: 0.6839 acc_val: 0.8782 time: 0.0074s\n",
      "Epoch: 1528 loss_train: 0.6900 acc_train: 0.8490 loss_val: 0.6836 acc_val: 0.8782 time: 0.0082s\n",
      "Epoch: 1529 loss_train: 0.6836 acc_train: 0.8352 loss_val: 0.6833 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1530 loss_train: 0.7051 acc_train: 0.8352 loss_val: 0.6830 acc_val: 0.8745 time: 0.0078s\n",
      "Epoch: 1531 loss_train: 0.7017 acc_train: 0.8398 loss_val: 0.6827 acc_val: 0.8745 time: 0.0078s\n",
      "Epoch: 1532 loss_train: 0.6793 acc_train: 0.8495 loss_val: 0.6823 acc_val: 0.8745 time: 0.0081s\n",
      "Epoch: 1533 loss_train: 0.6794 acc_train: 0.8380 loss_val: 0.6820 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1534 loss_train: 0.6867 acc_train: 0.8490 loss_val: 0.6816 acc_val: 0.8745 time: 0.0085s\n",
      "Epoch: 1535 loss_train: 0.7042 acc_train: 0.8343 loss_val: 0.6814 acc_val: 0.8745 time: 0.0086s\n",
      "Epoch: 1536 loss_train: 0.7062 acc_train: 0.8361 loss_val: 0.6811 acc_val: 0.8745 time: 0.0077s\n",
      "Epoch: 1537 loss_train: 0.6889 acc_train: 0.8449 loss_val: 0.6809 acc_val: 0.8745 time: 0.0073s\n",
      "Epoch: 1538 loss_train: 0.6770 acc_train: 0.8481 loss_val: 0.6806 acc_val: 0.8745 time: 0.0072s\n",
      "Epoch: 1539 loss_train: 0.6885 acc_train: 0.8426 loss_val: 0.6804 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1540 loss_train: 0.7043 acc_train: 0.8356 loss_val: 0.6801 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1541 loss_train: 0.6872 acc_train: 0.8306 loss_val: 0.6799 acc_val: 0.8745 time: 0.0083s\n",
      "Epoch: 1542 loss_train: 0.6783 acc_train: 0.8440 loss_val: 0.6797 acc_val: 0.8745 time: 0.0078s\n",
      "Epoch: 1543 loss_train: 0.7158 acc_train: 0.8287 loss_val: 0.6796 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1544 loss_train: 0.6683 acc_train: 0.8412 loss_val: 0.6795 acc_val: 0.8745 time: 0.0083s\n",
      "Epoch: 1545 loss_train: 0.6646 acc_train: 0.8527 loss_val: 0.6793 acc_val: 0.8745 time: 0.0090s\n",
      "Epoch: 1546 loss_train: 0.6899 acc_train: 0.8292 loss_val: 0.6792 acc_val: 0.8745 time: 0.0087s\n",
      "Epoch: 1547 loss_train: 0.6923 acc_train: 0.8412 loss_val: 0.6791 acc_val: 0.8745 time: 0.0077s\n",
      "Epoch: 1548 loss_train: 0.6668 acc_train: 0.8523 loss_val: 0.6789 acc_val: 0.8745 time: 0.0073s\n",
      "Epoch: 1549 loss_train: 0.6995 acc_train: 0.8361 loss_val: 0.6787 acc_val: 0.8745 time: 0.0072s\n",
      "Epoch: 1550 loss_train: 0.6762 acc_train: 0.8481 loss_val: 0.6785 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1551 loss_train: 0.7085 acc_train: 0.8292 loss_val: 0.6781 acc_val: 0.8745 time: 0.0081s\n",
      "Epoch: 1552 loss_train: 0.6838 acc_train: 0.8476 loss_val: 0.6777 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1553 loss_train: 0.6775 acc_train: 0.8426 loss_val: 0.6773 acc_val: 0.8782 time: 0.0078s\n",
      "Epoch: 1554 loss_train: 0.6771 acc_train: 0.8398 loss_val: 0.6769 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1555 loss_train: 0.6824 acc_train: 0.8523 loss_val: 0.6766 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1556 loss_train: 0.6856 acc_train: 0.8476 loss_val: 0.6762 acc_val: 0.8782 time: 0.0084s\n",
      "Epoch: 1557 loss_train: 0.6830 acc_train: 0.8407 loss_val: 0.6759 acc_val: 0.8782 time: 0.0086s\n",
      "Epoch: 1558 loss_train: 0.7027 acc_train: 0.8384 loss_val: 0.6756 acc_val: 0.8782 time: 0.0077s\n",
      "Epoch: 1559 loss_train: 0.6841 acc_train: 0.8370 loss_val: 0.6753 acc_val: 0.8782 time: 0.0074s\n",
      "Epoch: 1560 loss_train: 0.6826 acc_train: 0.8453 loss_val: 0.6750 acc_val: 0.8782 time: 0.0072s\n",
      "Epoch: 1561 loss_train: 0.6942 acc_train: 0.8467 loss_val: 0.6748 acc_val: 0.8782 time: 0.0082s\n",
      "Epoch: 1562 loss_train: 0.6992 acc_train: 0.8412 loss_val: 0.6748 acc_val: 0.8782 time: 0.0081s\n",
      "Epoch: 1563 loss_train: 0.6746 acc_train: 0.8527 loss_val: 0.6747 acc_val: 0.8745 time: 0.0083s\n",
      "Epoch: 1564 loss_train: 0.6830 acc_train: 0.8393 loss_val: 0.6746 acc_val: 0.8745 time: 0.0079s\n",
      "Epoch: 1565 loss_train: 0.7016 acc_train: 0.8366 loss_val: 0.6745 acc_val: 0.8745 time: 0.0082s\n",
      "Epoch: 1566 loss_train: 0.6708 acc_train: 0.8495 loss_val: 0.6743 acc_val: 0.8745 time: 0.0083s\n",
      "Epoch: 1567 loss_train: 0.6839 acc_train: 0.8578 loss_val: 0.6740 acc_val: 0.8745 time: 0.0090s\n",
      "Epoch: 1568 loss_train: 0.6960 acc_train: 0.8412 loss_val: 0.6738 acc_val: 0.8745 time: 0.0088s\n",
      "Epoch: 1569 loss_train: 0.6825 acc_train: 0.8292 loss_val: 0.6735 acc_val: 0.8782 time: 0.0077s\n",
      "Epoch: 1570 loss_train: 0.6606 acc_train: 0.8532 loss_val: 0.6732 acc_val: 0.8782 time: 0.0086s\n",
      "Epoch: 1571 loss_train: 0.6861 acc_train: 0.8375 loss_val: 0.6729 acc_val: 0.8782 time: 0.0083s\n",
      "Epoch: 1572 loss_train: 0.6815 acc_train: 0.8361 loss_val: 0.6727 acc_val: 0.8782 time: 0.0084s\n",
      "Epoch: 1573 loss_train: 0.6721 acc_train: 0.8426 loss_val: 0.6724 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1574 loss_train: 0.6754 acc_train: 0.8500 loss_val: 0.6722 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1575 loss_train: 0.6993 acc_train: 0.8500 loss_val: 0.6720 acc_val: 0.8856 time: 0.0075s\n",
      "Epoch: 1576 loss_train: 0.6882 acc_train: 0.8352 loss_val: 0.6718 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1577 loss_train: 0.6801 acc_train: 0.8467 loss_val: 0.6717 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1578 loss_train: 0.6724 acc_train: 0.8504 loss_val: 0.6715 acc_val: 0.8819 time: 0.0081s\n",
      "Epoch: 1579 loss_train: 0.6756 acc_train: 0.8366 loss_val: 0.6715 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1580 loss_train: 0.6897 acc_train: 0.8426 loss_val: 0.6713 acc_val: 0.8819 time: 0.0079s\n",
      "Epoch: 1581 loss_train: 0.6723 acc_train: 0.8430 loss_val: 0.6711 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1582 loss_train: 0.6627 acc_train: 0.8500 loss_val: 0.6708 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1583 loss_train: 0.6659 acc_train: 0.8532 loss_val: 0.6705 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1584 loss_train: 0.6841 acc_train: 0.8407 loss_val: 0.6702 acc_val: 0.8856 time: 0.0088s\n",
      "Epoch: 1585 loss_train: 0.6778 acc_train: 0.8467 loss_val: 0.6698 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1586 loss_train: 0.6746 acc_train: 0.8527 loss_val: 0.6694 acc_val: 0.8856 time: 0.0075s\n",
      "Epoch: 1587 loss_train: 0.6773 acc_train: 0.8513 loss_val: 0.6691 acc_val: 0.8819 time: 0.0073s\n",
      "Epoch: 1588 loss_train: 0.6907 acc_train: 0.8370 loss_val: 0.6688 acc_val: 0.8819 time: 0.0082s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1589 loss_train: 0.6677 acc_train: 0.8463 loss_val: 0.6684 acc_val: 0.8819 time: 0.0089s\n",
      "Epoch: 1590 loss_train: 0.6789 acc_train: 0.8356 loss_val: 0.6680 acc_val: 0.8819 time: 0.0078s\n",
      "Epoch: 1591 loss_train: 0.7042 acc_train: 0.8347 loss_val: 0.6676 acc_val: 0.8856 time: 0.0080s\n",
      "Epoch: 1592 loss_train: 0.6720 acc_train: 0.8509 loss_val: 0.6672 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1593 loss_train: 0.6745 acc_train: 0.8421 loss_val: 0.6668 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1594 loss_train: 0.6847 acc_train: 0.8398 loss_val: 0.6665 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1595 loss_train: 0.6908 acc_train: 0.8380 loss_val: 0.6662 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 1596 loss_train: 0.6772 acc_train: 0.8361 loss_val: 0.6659 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 1597 loss_train: 0.6698 acc_train: 0.8444 loss_val: 0.6656 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 1598 loss_train: 0.6617 acc_train: 0.8500 loss_val: 0.6654 acc_val: 0.8856 time: 0.0076s\n",
      "Epoch: 1599 loss_train: 0.6624 acc_train: 0.8504 loss_val: 0.6651 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1600 loss_train: 0.6638 acc_train: 0.8481 loss_val: 0.6649 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1601 loss_train: 0.6821 acc_train: 0.8361 loss_val: 0.6648 acc_val: 0.8856 time: 0.0077s\n",
      "Epoch: 1602 loss_train: 0.6659 acc_train: 0.8592 loss_val: 0.6646 acc_val: 0.8856 time: 0.0080s\n",
      "Epoch: 1603 loss_train: 0.6724 acc_train: 0.8490 loss_val: 0.6645 acc_val: 0.8856 time: 0.0080s\n",
      "Epoch: 1604 loss_train: 0.6856 acc_train: 0.8453 loss_val: 0.6644 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1605 loss_train: 0.6529 acc_train: 0.8546 loss_val: 0.6643 acc_val: 0.8819 time: 0.0084s\n",
      "Epoch: 1606 loss_train: 0.6842 acc_train: 0.8481 loss_val: 0.6642 acc_val: 0.8819 time: 0.0087s\n",
      "Epoch: 1607 loss_train: 0.6632 acc_train: 0.8481 loss_val: 0.6641 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1608 loss_train: 0.6831 acc_train: 0.8426 loss_val: 0.6639 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1609 loss_train: 0.6685 acc_train: 0.8384 loss_val: 0.6637 acc_val: 0.8856 time: 0.0071s\n",
      "Epoch: 1610 loss_train: 0.6644 acc_train: 0.8504 loss_val: 0.6636 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1611 loss_train: 0.6638 acc_train: 0.8546 loss_val: 0.6633 acc_val: 0.8856 time: 0.0087s\n",
      "Epoch: 1612 loss_train: 0.6775 acc_train: 0.8523 loss_val: 0.6630 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1613 loss_train: 0.6892 acc_train: 0.8407 loss_val: 0.6626 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1614 loss_train: 0.6546 acc_train: 0.8481 loss_val: 0.6622 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1615 loss_train: 0.6678 acc_train: 0.8500 loss_val: 0.6618 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1616 loss_train: 0.6492 acc_train: 0.8546 loss_val: 0.6613 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1617 loss_train: 0.6706 acc_train: 0.8550 loss_val: 0.6608 acc_val: 0.8819 time: 0.0086s\n",
      "Epoch: 1618 loss_train: 0.6771 acc_train: 0.8472 loss_val: 0.6603 acc_val: 0.8819 time: 0.0077s\n",
      "Epoch: 1619 loss_train: 0.6556 acc_train: 0.8495 loss_val: 0.6598 acc_val: 0.8819 time: 0.0074s\n",
      "Epoch: 1620 loss_train: 0.6710 acc_train: 0.8393 loss_val: 0.6593 acc_val: 0.8819 time: 0.0074s\n",
      "Epoch: 1621 loss_train: 0.6745 acc_train: 0.8444 loss_val: 0.6589 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1622 loss_train: 0.6618 acc_train: 0.8453 loss_val: 0.6584 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1623 loss_train: 0.6682 acc_train: 0.8398 loss_val: 0.6579 acc_val: 0.8856 time: 0.0079s\n",
      "Epoch: 1624 loss_train: 0.6608 acc_train: 0.8536 loss_val: 0.6575 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1625 loss_train: 0.6698 acc_train: 0.8546 loss_val: 0.6572 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1626 loss_train: 0.6743 acc_train: 0.8444 loss_val: 0.6569 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1627 loss_train: 0.6701 acc_train: 0.8440 loss_val: 0.6565 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1628 loss_train: 0.6865 acc_train: 0.8407 loss_val: 0.6562 acc_val: 0.8856 time: 0.0087s\n",
      "Epoch: 1629 loss_train: 0.6764 acc_train: 0.8435 loss_val: 0.6560 acc_val: 0.8856 time: 0.0077s\n",
      "Epoch: 1630 loss_train: 0.6948 acc_train: 0.8343 loss_val: 0.6557 acc_val: 0.8856 time: 0.0086s\n",
      "Epoch: 1631 loss_train: 0.6727 acc_train: 0.8486 loss_val: 0.6555 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1632 loss_train: 0.6710 acc_train: 0.8319 loss_val: 0.6552 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1633 loss_train: 0.6612 acc_train: 0.8523 loss_val: 0.6550 acc_val: 0.8856 time: 0.0086s\n",
      "Epoch: 1634 loss_train: 0.6813 acc_train: 0.8500 loss_val: 0.6549 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1635 loss_train: 0.6721 acc_train: 0.8587 loss_val: 0.6547 acc_val: 0.8856 time: 0.0075s\n",
      "Epoch: 1636 loss_train: 0.6516 acc_train: 0.8453 loss_val: 0.6546 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1637 loss_train: 0.6749 acc_train: 0.8495 loss_val: 0.6544 acc_val: 0.8856 time: 0.0080s\n",
      "Epoch: 1638 loss_train: 0.6800 acc_train: 0.8306 loss_val: 0.6543 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1639 loss_train: 0.6510 acc_train: 0.8573 loss_val: 0.6541 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1640 loss_train: 0.6796 acc_train: 0.8467 loss_val: 0.6540 acc_val: 0.8819 time: 0.0075s\n",
      "Epoch: 1641 loss_train: 0.6696 acc_train: 0.8416 loss_val: 0.6538 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1642 loss_train: 0.6642 acc_train: 0.8453 loss_val: 0.6536 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1643 loss_train: 0.6783 acc_train: 0.8393 loss_val: 0.6533 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1644 loss_train: 0.6605 acc_train: 0.8389 loss_val: 0.6530 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1645 loss_train: 0.6545 acc_train: 0.8476 loss_val: 0.6526 acc_val: 0.8856 time: 0.0080s\n",
      "Epoch: 1646 loss_train: 0.6659 acc_train: 0.8472 loss_val: 0.6523 acc_val: 0.8856 time: 0.0074s\n",
      "Epoch: 1647 loss_train: 0.6696 acc_train: 0.8449 loss_val: 0.6520 acc_val: 0.8819 time: 0.0074s\n",
      "Epoch: 1648 loss_train: 0.6545 acc_train: 0.8536 loss_val: 0.6517 acc_val: 0.8819 time: 0.0081s\n",
      "Epoch: 1649 loss_train: 0.6671 acc_train: 0.8486 loss_val: 0.6515 acc_val: 0.8819 time: 0.0081s\n",
      "Epoch: 1650 loss_train: 0.6462 acc_train: 0.8463 loss_val: 0.6513 acc_val: 0.8819 time: 0.0084s\n",
      "Epoch: 1651 loss_train: 0.6951 acc_train: 0.8319 loss_val: 0.6511 acc_val: 0.8819 time: 0.0074s\n",
      "Epoch: 1652 loss_train: 0.6638 acc_train: 0.8440 loss_val: 0.6509 acc_val: 0.8819 time: 0.0084s\n",
      "Epoch: 1653 loss_train: 0.6592 acc_train: 0.8509 loss_val: 0.6507 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1654 loss_train: 0.6737 acc_train: 0.8430 loss_val: 0.6505 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1655 loss_train: 0.6446 acc_train: 0.8472 loss_val: 0.6502 acc_val: 0.8856 time: 0.0088s\n",
      "Epoch: 1656 loss_train: 0.6387 acc_train: 0.8481 loss_val: 0.6499 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1657 loss_train: 0.6506 acc_train: 0.8564 loss_val: 0.6495 acc_val: 0.8856 time: 0.0075s\n",
      "Epoch: 1658 loss_train: 0.6448 acc_train: 0.8467 loss_val: 0.6492 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1659 loss_train: 0.6435 acc_train: 0.8541 loss_val: 0.6488 acc_val: 0.8819 time: 0.0081s\n",
      "Epoch: 1660 loss_train: 0.6466 acc_train: 0.8504 loss_val: 0.6484 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1661 loss_train: 0.6617 acc_train: 0.8569 loss_val: 0.6481 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1662 loss_train: 0.6714 acc_train: 0.8403 loss_val: 0.6478 acc_val: 0.8819 time: 0.0075s\n",
      "Epoch: 1663 loss_train: 0.6554 acc_train: 0.8606 loss_val: 0.6474 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1664 loss_train: 0.6730 acc_train: 0.8416 loss_val: 0.6472 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1665 loss_train: 0.6555 acc_train: 0.8430 loss_val: 0.6470 acc_val: 0.8819 time: 0.0084s\n",
      "Epoch: 1666 loss_train: 0.6620 acc_train: 0.8523 loss_val: 0.6469 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1667 loss_train: 0.6513 acc_train: 0.8412 loss_val: 0.6467 acc_val: 0.8819 time: 0.0076s\n",
      "Epoch: 1668 loss_train: 0.6394 acc_train: 0.8440 loss_val: 0.6466 acc_val: 0.8819 time: 0.0076s\n",
      "Epoch: 1669 loss_train: 0.6612 acc_train: 0.8495 loss_val: 0.6464 acc_val: 0.8819 time: 0.0080s\n",
      "Epoch: 1670 loss_train: 0.6435 acc_train: 0.8569 loss_val: 0.6463 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1671 loss_train: 0.6523 acc_train: 0.8518 loss_val: 0.6461 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1672 loss_train: 0.6490 acc_train: 0.8495 loss_val: 0.6459 acc_val: 0.8782 time: 0.0085s\n",
      "Epoch: 1673 loss_train: 0.6581 acc_train: 0.8421 loss_val: 0.6457 acc_val: 0.8819 time: 0.0075s\n",
      "Epoch: 1674 loss_train: 0.6542 acc_train: 0.8527 loss_val: 0.6453 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1675 loss_train: 0.6481 acc_train: 0.8560 loss_val: 0.6450 acc_val: 0.8819 time: 0.0084s\n",
      "Epoch: 1676 loss_train: 0.6551 acc_train: 0.8472 loss_val: 0.6447 acc_val: 0.8819 time: 0.0084s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1677 loss_train: 0.6296 acc_train: 0.8693 loss_val: 0.6443 acc_val: 0.8819 time: 0.0090s\n",
      "Epoch: 1678 loss_train: 0.6594 acc_train: 0.8560 loss_val: 0.6440 acc_val: 0.8819 time: 0.0077s\n",
      "Epoch: 1679 loss_train: 0.6471 acc_train: 0.8513 loss_val: 0.6436 acc_val: 0.8819 time: 0.0075s\n",
      "Epoch: 1680 loss_train: 0.6594 acc_train: 0.8472 loss_val: 0.6432 acc_val: 0.8819 time: 0.0073s\n",
      "Epoch: 1681 loss_train: 0.6445 acc_train: 0.8476 loss_val: 0.6429 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1682 loss_train: 0.6615 acc_train: 0.8444 loss_val: 0.6425 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1683 loss_train: 0.6550 acc_train: 0.8421 loss_val: 0.6421 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1684 loss_train: 0.6550 acc_train: 0.8352 loss_val: 0.6418 acc_val: 0.8819 time: 0.0078s\n",
      "Epoch: 1685 loss_train: 0.6533 acc_train: 0.8467 loss_val: 0.6416 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1686 loss_train: 0.6402 acc_train: 0.8523 loss_val: 0.6412 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1687 loss_train: 0.6546 acc_train: 0.8449 loss_val: 0.6409 acc_val: 0.8819 time: 0.0084s\n",
      "Epoch: 1688 loss_train: 0.6492 acc_train: 0.8444 loss_val: 0.6405 acc_val: 0.8819 time: 0.0086s\n",
      "Epoch: 1689 loss_train: 0.6498 acc_train: 0.8486 loss_val: 0.6401 acc_val: 0.8819 time: 0.0078s\n",
      "Epoch: 1690 loss_train: 0.6371 acc_train: 0.8583 loss_val: 0.6397 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1691 loss_train: 0.6335 acc_train: 0.8550 loss_val: 0.6394 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1692 loss_train: 0.6680 acc_train: 0.8416 loss_val: 0.6391 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1693 loss_train: 0.6540 acc_train: 0.8486 loss_val: 0.6390 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1694 loss_train: 0.6727 acc_train: 0.8463 loss_val: 0.6387 acc_val: 0.8856 time: 0.0079s\n",
      "Epoch: 1695 loss_train: 0.6616 acc_train: 0.8536 loss_val: 0.6386 acc_val: 0.8856 time: 0.0075s\n",
      "Epoch: 1696 loss_train: 0.6493 acc_train: 0.8527 loss_val: 0.6384 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1697 loss_train: 0.6609 acc_train: 0.8453 loss_val: 0.6383 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1698 loss_train: 0.6415 acc_train: 0.8592 loss_val: 0.6381 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1699 loss_train: 0.6540 acc_train: 0.8440 loss_val: 0.6379 acc_val: 0.8856 time: 0.0089s\n",
      "Epoch: 1700 loss_train: 0.6555 acc_train: 0.8421 loss_val: 0.6377 acc_val: 0.8856 time: 0.0079s\n",
      "Epoch: 1701 loss_train: 0.6316 acc_train: 0.8541 loss_val: 0.6374 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1702 loss_train: 0.6545 acc_train: 0.8555 loss_val: 0.6372 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1703 loss_train: 0.6441 acc_train: 0.8578 loss_val: 0.6369 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1704 loss_train: 0.6480 acc_train: 0.8564 loss_val: 0.6366 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1705 loss_train: 0.6347 acc_train: 0.8550 loss_val: 0.6363 acc_val: 0.8819 time: 0.0078s\n",
      "Epoch: 1706 loss_train: 0.6366 acc_train: 0.8541 loss_val: 0.6360 acc_val: 0.8819 time: 0.0074s\n",
      "Epoch: 1707 loss_train: 0.6399 acc_train: 0.8569 loss_val: 0.6358 acc_val: 0.8819 time: 0.0072s\n",
      "Epoch: 1708 loss_train: 0.6557 acc_train: 0.8440 loss_val: 0.6355 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1709 loss_train: 0.6340 acc_train: 0.8606 loss_val: 0.6352 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1710 loss_train: 0.6343 acc_train: 0.8523 loss_val: 0.6349 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1711 loss_train: 0.6426 acc_train: 0.8504 loss_val: 0.6346 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1712 loss_train: 0.6343 acc_train: 0.8467 loss_val: 0.6343 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1713 loss_train: 0.6562 acc_train: 0.8453 loss_val: 0.6340 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1714 loss_train: 0.6465 acc_train: 0.8490 loss_val: 0.6338 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1715 loss_train: 0.6490 acc_train: 0.8560 loss_val: 0.6335 acc_val: 0.8819 time: 0.0086s\n",
      "Epoch: 1716 loss_train: 0.6262 acc_train: 0.8573 loss_val: 0.6333 acc_val: 0.8819 time: 0.0077s\n",
      "Epoch: 1717 loss_train: 0.6381 acc_train: 0.8569 loss_val: 0.6330 acc_val: 0.8782 time: 0.0073s\n",
      "Epoch: 1718 loss_train: 0.6468 acc_train: 0.8486 loss_val: 0.6327 acc_val: 0.8782 time: 0.0071s\n",
      "Epoch: 1719 loss_train: 0.6491 acc_train: 0.8532 loss_val: 0.6325 acc_val: 0.8819 time: 0.0081s\n",
      "Epoch: 1720 loss_train: 0.6526 acc_train: 0.8523 loss_val: 0.6322 acc_val: 0.8819 time: 0.0081s\n",
      "Epoch: 1721 loss_train: 0.6444 acc_train: 0.8527 loss_val: 0.6319 acc_val: 0.8819 time: 0.0092s\n",
      "Epoch: 1722 loss_train: 0.6254 acc_train: 0.8587 loss_val: 0.6316 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1723 loss_train: 0.6443 acc_train: 0.8573 loss_val: 0.6312 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1724 loss_train: 0.6429 acc_train: 0.8578 loss_val: 0.6309 acc_val: 0.8819 time: 0.0082s\n",
      "Epoch: 1725 loss_train: 0.6310 acc_train: 0.8527 loss_val: 0.6307 acc_val: 0.8819 time: 0.0084s\n",
      "Epoch: 1726 loss_train: 0.6444 acc_train: 0.8500 loss_val: 0.6305 acc_val: 0.8819 time: 0.0085s\n",
      "Epoch: 1727 loss_train: 0.6477 acc_train: 0.8610 loss_val: 0.6303 acc_val: 0.8819 time: 0.0078s\n",
      "Epoch: 1728 loss_train: 0.6501 acc_train: 0.8624 loss_val: 0.6301 acc_val: 0.8856 time: 0.0077s\n",
      "Epoch: 1729 loss_train: 0.6176 acc_train: 0.8638 loss_val: 0.6300 acc_val: 0.8856 time: 0.0076s\n",
      "Epoch: 1730 loss_train: 0.6449 acc_train: 0.8449 loss_val: 0.6298 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1731 loss_train: 0.6399 acc_train: 0.8583 loss_val: 0.6297 acc_val: 0.8819 time: 0.0083s\n",
      "Epoch: 1732 loss_train: 0.6334 acc_train: 0.8527 loss_val: 0.6295 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1733 loss_train: 0.6403 acc_train: 0.8560 loss_val: 0.6290 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1734 loss_train: 0.6343 acc_train: 0.8481 loss_val: 0.6287 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1735 loss_train: 0.6229 acc_train: 0.8615 loss_val: 0.6283 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1736 loss_train: 0.6287 acc_train: 0.8536 loss_val: 0.6280 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1737 loss_train: 0.6412 acc_train: 0.8490 loss_val: 0.6275 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1738 loss_train: 0.6380 acc_train: 0.8601 loss_val: 0.6271 acc_val: 0.8856 time: 0.0077s\n",
      "Epoch: 1739 loss_train: 0.6378 acc_train: 0.8587 loss_val: 0.6267 acc_val: 0.8856 time: 0.0077s\n",
      "Epoch: 1740 loss_train: 0.6438 acc_train: 0.8490 loss_val: 0.6263 acc_val: 0.8856 time: 0.0076s\n",
      "Epoch: 1741 loss_train: 0.6449 acc_train: 0.8416 loss_val: 0.6260 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1742 loss_train: 0.6427 acc_train: 0.8546 loss_val: 0.6258 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1743 loss_train: 0.6377 acc_train: 0.8518 loss_val: 0.6254 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1744 loss_train: 0.6250 acc_train: 0.8592 loss_val: 0.6251 acc_val: 0.8856 time: 0.0079s\n",
      "Epoch: 1745 loss_train: 0.6367 acc_train: 0.8444 loss_val: 0.6247 acc_val: 0.8893 time: 0.0080s\n",
      "Epoch: 1746 loss_train: 0.6391 acc_train: 0.8555 loss_val: 0.6244 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1747 loss_train: 0.6544 acc_train: 0.8495 loss_val: 0.6241 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1748 loss_train: 0.6352 acc_train: 0.8509 loss_val: 0.6239 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1749 loss_train: 0.6335 acc_train: 0.8541 loss_val: 0.6237 acc_val: 0.8856 time: 0.0076s\n",
      "Epoch: 1750 loss_train: 0.6202 acc_train: 0.8490 loss_val: 0.6236 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 1751 loss_train: 0.6410 acc_train: 0.8532 loss_val: 0.6234 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1752 loss_train: 0.6656 acc_train: 0.8435 loss_val: 0.6232 acc_val: 0.8856 time: 0.0089s\n",
      "Epoch: 1753 loss_train: 0.6230 acc_train: 0.8592 loss_val: 0.6230 acc_val: 0.8856 time: 0.0086s\n",
      "Epoch: 1754 loss_train: 0.6273 acc_train: 0.8587 loss_val: 0.6229 acc_val: 0.8856 time: 0.0079s\n",
      "Epoch: 1755 loss_train: 0.6220 acc_train: 0.8587 loss_val: 0.6228 acc_val: 0.8856 time: 0.0074s\n",
      "Epoch: 1756 loss_train: 0.6485 acc_train: 0.8440 loss_val: 0.6227 acc_val: 0.8856 time: 0.0072s\n",
      "Epoch: 1757 loss_train: 0.6443 acc_train: 0.8527 loss_val: 0.6224 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1758 loss_train: 0.6301 acc_train: 0.8536 loss_val: 0.6222 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1759 loss_train: 0.6528 acc_train: 0.8601 loss_val: 0.6219 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1760 loss_train: 0.6241 acc_train: 0.8583 loss_val: 0.6216 acc_val: 0.8893 time: 0.0076s\n",
      "Epoch: 1761 loss_train: 0.6354 acc_train: 0.8624 loss_val: 0.6213 acc_val: 0.8856 time: 0.0089s\n",
      "Epoch: 1762 loss_train: 0.6275 acc_train: 0.8490 loss_val: 0.6211 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1763 loss_train: 0.6399 acc_train: 0.8546 loss_val: 0.6209 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1764 loss_train: 0.6337 acc_train: 0.8550 loss_val: 0.6206 acc_val: 0.8856 time: 0.0085s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1765 loss_train: 0.6360 acc_train: 0.8560 loss_val: 0.6203 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 1766 loss_train: 0.6364 acc_train: 0.8555 loss_val: 0.6200 acc_val: 0.8856 time: 0.0075s\n",
      "Epoch: 1767 loss_train: 0.6422 acc_train: 0.8500 loss_val: 0.6198 acc_val: 0.8856 time: 0.0072s\n",
      "Epoch: 1768 loss_train: 0.6413 acc_train: 0.8509 loss_val: 0.6196 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1769 loss_train: 0.6305 acc_train: 0.8472 loss_val: 0.6195 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1770 loss_train: 0.6394 acc_train: 0.8541 loss_val: 0.6193 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1771 loss_train: 0.6252 acc_train: 0.8513 loss_val: 0.6192 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1772 loss_train: 0.6335 acc_train: 0.8449 loss_val: 0.6190 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1773 loss_train: 0.6448 acc_train: 0.8412 loss_val: 0.6189 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1774 loss_train: 0.6278 acc_train: 0.8532 loss_val: 0.6186 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 1775 loss_train: 0.6202 acc_train: 0.8518 loss_val: 0.6182 acc_val: 0.8893 time: 0.0086s\n",
      "Epoch: 1776 loss_train: 0.6247 acc_train: 0.8615 loss_val: 0.6179 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 1777 loss_train: 0.6318 acc_train: 0.8583 loss_val: 0.6177 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1778 loss_train: 0.6344 acc_train: 0.8546 loss_val: 0.6174 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1779 loss_train: 0.6227 acc_train: 0.8536 loss_val: 0.6172 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1780 loss_train: 0.6384 acc_train: 0.8527 loss_val: 0.6170 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1781 loss_train: 0.6508 acc_train: 0.8573 loss_val: 0.6169 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1782 loss_train: 0.6326 acc_train: 0.8481 loss_val: 0.6166 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1783 loss_train: 0.6353 acc_train: 0.8560 loss_val: 0.6164 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1784 loss_train: 0.6168 acc_train: 0.8610 loss_val: 0.6161 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1785 loss_train: 0.6266 acc_train: 0.8546 loss_val: 0.6157 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1786 loss_train: 0.6269 acc_train: 0.8583 loss_val: 0.6154 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 1787 loss_train: 0.6325 acc_train: 0.8495 loss_val: 0.6151 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1788 loss_train: 0.6189 acc_train: 0.8592 loss_val: 0.6148 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1789 loss_train: 0.6221 acc_train: 0.8587 loss_val: 0.6146 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1790 loss_train: 0.6203 acc_train: 0.8657 loss_val: 0.6145 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1791 loss_train: 0.6273 acc_train: 0.8449 loss_val: 0.6144 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1792 loss_train: 0.6168 acc_train: 0.8643 loss_val: 0.6142 acc_val: 0.8893 time: 0.0079s\n",
      "Epoch: 1793 loss_train: 0.6192 acc_train: 0.8564 loss_val: 0.6140 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 1794 loss_train: 0.6113 acc_train: 0.8606 loss_val: 0.6138 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1795 loss_train: 0.6336 acc_train: 0.8587 loss_val: 0.6136 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1796 loss_train: 0.6322 acc_train: 0.8495 loss_val: 0.6134 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 1797 loss_train: 0.6101 acc_train: 0.8721 loss_val: 0.6133 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 1798 loss_train: 0.6051 acc_train: 0.8684 loss_val: 0.6130 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1799 loss_train: 0.6227 acc_train: 0.8550 loss_val: 0.6127 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1800 loss_train: 0.6455 acc_train: 0.8518 loss_val: 0.6125 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1801 loss_train: 0.6164 acc_train: 0.8629 loss_val: 0.6122 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1802 loss_train: 0.6407 acc_train: 0.8463 loss_val: 0.6119 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1803 loss_train: 0.6204 acc_train: 0.8620 loss_val: 0.6116 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1804 loss_train: 0.6014 acc_train: 0.8578 loss_val: 0.6113 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 1805 loss_train: 0.6479 acc_train: 0.8495 loss_val: 0.6110 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1806 loss_train: 0.6147 acc_train: 0.8629 loss_val: 0.6107 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 1807 loss_train: 0.6125 acc_train: 0.8555 loss_val: 0.6104 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 1808 loss_train: 0.6263 acc_train: 0.8615 loss_val: 0.6102 acc_val: 0.8893 time: 0.0086s\n",
      "Epoch: 1809 loss_train: 0.6325 acc_train: 0.8513 loss_val: 0.6100 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1810 loss_train: 0.6244 acc_train: 0.8615 loss_val: 0.6097 acc_val: 0.8893 time: 0.0087s\n",
      "Epoch: 1811 loss_train: 0.6373 acc_train: 0.8504 loss_val: 0.6096 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 1812 loss_train: 0.6222 acc_train: 0.8666 loss_val: 0.6094 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1813 loss_train: 0.6200 acc_train: 0.8583 loss_val: 0.6092 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1814 loss_train: 0.6137 acc_train: 0.8615 loss_val: 0.6090 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 1815 loss_train: 0.6128 acc_train: 0.8573 loss_val: 0.6088 acc_val: 0.8893 time: 0.0076s\n",
      "Epoch: 1816 loss_train: 0.6122 acc_train: 0.8615 loss_val: 0.6087 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1817 loss_train: 0.6166 acc_train: 0.8541 loss_val: 0.6084 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 1818 loss_train: 0.6190 acc_train: 0.8624 loss_val: 0.6082 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1819 loss_train: 0.6232 acc_train: 0.8527 loss_val: 0.6080 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1820 loss_train: 0.6389 acc_train: 0.8481 loss_val: 0.6077 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1821 loss_train: 0.6182 acc_train: 0.8596 loss_val: 0.6074 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 1822 loss_train: 0.6109 acc_train: 0.8596 loss_val: 0.6071 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1823 loss_train: 0.6149 acc_train: 0.8624 loss_val: 0.6069 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1824 loss_train: 0.6116 acc_train: 0.8615 loss_val: 0.6065 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1825 loss_train: 0.6069 acc_train: 0.8587 loss_val: 0.6062 acc_val: 0.8893 time: 0.0080s\n",
      "Epoch: 1826 loss_train: 0.6101 acc_train: 0.8666 loss_val: 0.6059 acc_val: 0.8893 time: 0.0076s\n",
      "Epoch: 1827 loss_train: 0.6068 acc_train: 0.8596 loss_val: 0.6056 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1828 loss_train: 0.6414 acc_train: 0.8472 loss_val: 0.6054 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1829 loss_train: 0.6270 acc_train: 0.8536 loss_val: 0.6052 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1830 loss_train: 0.6153 acc_train: 0.8592 loss_val: 0.6050 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1831 loss_train: 0.6080 acc_train: 0.8647 loss_val: 0.6048 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1832 loss_train: 0.6243 acc_train: 0.8546 loss_val: 0.6046 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1833 loss_train: 0.6345 acc_train: 0.8573 loss_val: 0.6044 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1834 loss_train: 0.6133 acc_train: 0.8606 loss_val: 0.6043 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1835 loss_train: 0.6119 acc_train: 0.8523 loss_val: 0.6041 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1836 loss_train: 0.6125 acc_train: 0.8504 loss_val: 0.6038 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1837 loss_train: 0.6234 acc_train: 0.8629 loss_val: 0.6034 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1838 loss_train: 0.6041 acc_train: 0.8555 loss_val: 0.6032 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1839 loss_train: 0.6215 acc_train: 0.8587 loss_val: 0.6029 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 1840 loss_train: 0.6122 acc_train: 0.8670 loss_val: 0.6027 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1841 loss_train: 0.6103 acc_train: 0.8629 loss_val: 0.6025 acc_val: 0.8930 time: 0.0129s\n",
      "Epoch: 1842 loss_train: 0.6064 acc_train: 0.8698 loss_val: 0.6022 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1843 loss_train: 0.6280 acc_train: 0.8601 loss_val: 0.6019 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1844 loss_train: 0.5937 acc_train: 0.8629 loss_val: 0.6015 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1845 loss_train: 0.6086 acc_train: 0.8592 loss_val: 0.6013 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1846 loss_train: 0.6175 acc_train: 0.8592 loss_val: 0.6010 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1847 loss_train: 0.6093 acc_train: 0.8629 loss_val: 0.6008 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1848 loss_train: 0.6359 acc_train: 0.8513 loss_val: 0.6006 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1849 loss_train: 0.6073 acc_train: 0.8546 loss_val: 0.6003 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1850 loss_train: 0.6172 acc_train: 0.8633 loss_val: 0.6001 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1851 loss_train: 0.6216 acc_train: 0.8555 loss_val: 0.5999 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1852 loss_train: 0.6097 acc_train: 0.8620 loss_val: 0.5997 acc_val: 0.8930 time: 0.0076s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1853 loss_train: 0.6244 acc_train: 0.8513 loss_val: 0.5996 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1854 loss_train: 0.6055 acc_train: 0.8629 loss_val: 0.5995 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1855 loss_train: 0.6024 acc_train: 0.8643 loss_val: 0.5994 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 1856 loss_train: 0.6186 acc_train: 0.8453 loss_val: 0.5992 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1857 loss_train: 0.6172 acc_train: 0.8536 loss_val: 0.5989 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1858 loss_train: 0.6064 acc_train: 0.8610 loss_val: 0.5986 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1859 loss_train: 0.6146 acc_train: 0.8596 loss_val: 0.5984 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1860 loss_train: 0.6216 acc_train: 0.8638 loss_val: 0.5981 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1861 loss_train: 0.6344 acc_train: 0.8564 loss_val: 0.5977 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1862 loss_train: 0.5882 acc_train: 0.8730 loss_val: 0.5974 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1863 loss_train: 0.6064 acc_train: 0.8523 loss_val: 0.5972 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1864 loss_train: 0.6070 acc_train: 0.8633 loss_val: 0.5970 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1865 loss_train: 0.6117 acc_train: 0.8601 loss_val: 0.5969 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1866 loss_train: 0.6223 acc_train: 0.8592 loss_val: 0.5967 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1867 loss_train: 0.5915 acc_train: 0.8638 loss_val: 0.5965 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1868 loss_train: 0.5945 acc_train: 0.8693 loss_val: 0.5964 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1869 loss_train: 0.6072 acc_train: 0.8601 loss_val: 0.5963 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1870 loss_train: 0.6006 acc_train: 0.8670 loss_val: 0.5962 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1871 loss_train: 0.6013 acc_train: 0.8652 loss_val: 0.5960 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 1872 loss_train: 0.6082 acc_train: 0.8573 loss_val: 0.5959 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1873 loss_train: 0.6124 acc_train: 0.8573 loss_val: 0.5957 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1874 loss_train: 0.6016 acc_train: 0.8596 loss_val: 0.5956 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 1875 loss_train: 0.6015 acc_train: 0.8578 loss_val: 0.5953 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 1876 loss_train: 0.6027 acc_train: 0.8647 loss_val: 0.5951 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1877 loss_train: 0.5976 acc_train: 0.8596 loss_val: 0.5948 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1878 loss_train: 0.6084 acc_train: 0.8564 loss_val: 0.5945 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1879 loss_train: 0.5880 acc_train: 0.8629 loss_val: 0.5943 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 1880 loss_train: 0.5992 acc_train: 0.8592 loss_val: 0.5941 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1881 loss_train: 0.5894 acc_train: 0.8652 loss_val: 0.5939 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1882 loss_train: 0.5978 acc_train: 0.8624 loss_val: 0.5937 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1883 loss_train: 0.6053 acc_train: 0.8596 loss_val: 0.5934 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1884 loss_train: 0.6095 acc_train: 0.8573 loss_val: 0.5932 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 1885 loss_train: 0.5983 acc_train: 0.8564 loss_val: 0.5928 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1886 loss_train: 0.6121 acc_train: 0.8661 loss_val: 0.5926 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1887 loss_train: 0.6175 acc_train: 0.8555 loss_val: 0.5924 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 1888 loss_train: 0.6066 acc_train: 0.8606 loss_val: 0.5923 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1889 loss_train: 0.5939 acc_train: 0.8670 loss_val: 0.5921 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1890 loss_train: 0.6026 acc_train: 0.8684 loss_val: 0.5919 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1891 loss_train: 0.6166 acc_train: 0.8527 loss_val: 0.5918 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 1892 loss_train: 0.6192 acc_train: 0.8458 loss_val: 0.5916 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1893 loss_train: 0.6006 acc_train: 0.8647 loss_val: 0.5914 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1894 loss_train: 0.6010 acc_train: 0.8601 loss_val: 0.5912 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1895 loss_train: 0.5826 acc_train: 0.8638 loss_val: 0.5910 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 1896 loss_train: 0.6000 acc_train: 0.8550 loss_val: 0.5908 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1897 loss_train: 0.5965 acc_train: 0.8560 loss_val: 0.5906 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1898 loss_train: 0.5961 acc_train: 0.8569 loss_val: 0.5905 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 1899 loss_train: 0.5935 acc_train: 0.8693 loss_val: 0.5904 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1900 loss_train: 0.6071 acc_train: 0.8550 loss_val: 0.5902 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1901 loss_train: 0.5914 acc_train: 0.8703 loss_val: 0.5900 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 1902 loss_train: 0.6019 acc_train: 0.8569 loss_val: 0.5897 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 1903 loss_train: 0.5913 acc_train: 0.8573 loss_val: 0.5896 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1904 loss_train: 0.5814 acc_train: 0.8652 loss_val: 0.5894 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1905 loss_train: 0.6007 acc_train: 0.8564 loss_val: 0.5893 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1906 loss_train: 0.5892 acc_train: 0.8652 loss_val: 0.5892 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1907 loss_train: 0.6099 acc_train: 0.8624 loss_val: 0.5892 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 1908 loss_train: 0.6002 acc_train: 0.8573 loss_val: 0.5891 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1909 loss_train: 0.5995 acc_train: 0.8610 loss_val: 0.5889 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1910 loss_train: 0.5910 acc_train: 0.8735 loss_val: 0.5888 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1911 loss_train: 0.5855 acc_train: 0.8633 loss_val: 0.5886 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1912 loss_train: 0.6152 acc_train: 0.8560 loss_val: 0.5884 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1913 loss_train: 0.6112 acc_train: 0.8624 loss_val: 0.5882 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1914 loss_train: 0.6020 acc_train: 0.8569 loss_val: 0.5880 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1915 loss_train: 0.5926 acc_train: 0.8698 loss_val: 0.5878 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1916 loss_train: 0.6014 acc_train: 0.8624 loss_val: 0.5875 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1917 loss_train: 0.6340 acc_train: 0.8458 loss_val: 0.5872 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1918 loss_train: 0.6119 acc_train: 0.8536 loss_val: 0.5869 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 1919 loss_train: 0.5948 acc_train: 0.8592 loss_val: 0.5866 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1920 loss_train: 0.5861 acc_train: 0.8606 loss_val: 0.5863 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1921 loss_train: 0.6169 acc_train: 0.8592 loss_val: 0.5860 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1922 loss_train: 0.5957 acc_train: 0.8657 loss_val: 0.5857 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 1923 loss_train: 0.6033 acc_train: 0.8555 loss_val: 0.5854 acc_val: 0.8856 time: 0.0079s\n",
      "Epoch: 1924 loss_train: 0.6093 acc_train: 0.8620 loss_val: 0.5852 acc_val: 0.8856 time: 0.0078s\n",
      "Epoch: 1925 loss_train: 0.6070 acc_train: 0.8620 loss_val: 0.5850 acc_val: 0.8856 time: 0.0081s\n",
      "Epoch: 1926 loss_train: 0.5939 acc_train: 0.8647 loss_val: 0.5848 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1927 loss_train: 0.5838 acc_train: 0.8666 loss_val: 0.5846 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1928 loss_train: 0.5950 acc_train: 0.8643 loss_val: 0.5844 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1929 loss_train: 0.5904 acc_train: 0.8730 loss_val: 0.5842 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 1930 loss_train: 0.5911 acc_train: 0.8601 loss_val: 0.5841 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1931 loss_train: 0.6085 acc_train: 0.8550 loss_val: 0.5839 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1932 loss_train: 0.6016 acc_train: 0.8564 loss_val: 0.5838 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1933 loss_train: 0.6120 acc_train: 0.8564 loss_val: 0.5836 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1934 loss_train: 0.5894 acc_train: 0.8578 loss_val: 0.5834 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1935 loss_train: 0.5734 acc_train: 0.8698 loss_val: 0.5832 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 1936 loss_train: 0.5995 acc_train: 0.8578 loss_val: 0.5829 acc_val: 0.8856 time: 0.0073s\n",
      "Epoch: 1937 loss_train: 0.6095 acc_train: 0.8573 loss_val: 0.5826 acc_val: 0.8856 time: 0.0080s\n",
      "Epoch: 1938 loss_train: 0.5793 acc_train: 0.8675 loss_val: 0.5824 acc_val: 0.8856 time: 0.0082s\n",
      "Epoch: 1939 loss_train: 0.5798 acc_train: 0.8647 loss_val: 0.5823 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 1940 loss_train: 0.5903 acc_train: 0.8583 loss_val: 0.5821 acc_val: 0.8893 time: 0.0076s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1941 loss_train: 0.5765 acc_train: 0.8606 loss_val: 0.5819 acc_val: 0.8893 time: 0.0089s\n",
      "Epoch: 1942 loss_train: 0.5873 acc_train: 0.8680 loss_val: 0.5818 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1943 loss_train: 0.5899 acc_train: 0.8652 loss_val: 0.5817 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 1944 loss_train: 0.5958 acc_train: 0.8633 loss_val: 0.5817 acc_val: 0.8893 time: 0.0086s\n",
      "Epoch: 1945 loss_train: 0.5777 acc_train: 0.8620 loss_val: 0.5816 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 1946 loss_train: 0.5825 acc_train: 0.8615 loss_val: 0.5815 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 1947 loss_train: 0.5992 acc_train: 0.8560 loss_val: 0.5814 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 1948 loss_train: 0.5955 acc_train: 0.8638 loss_val: 0.5812 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1949 loss_train: 0.5828 acc_train: 0.8624 loss_val: 0.5811 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1950 loss_train: 0.5878 acc_train: 0.8596 loss_val: 0.5809 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1951 loss_train: 0.5667 acc_train: 0.8721 loss_val: 0.5807 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1952 loss_train: 0.5833 acc_train: 0.8744 loss_val: 0.5805 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 1953 loss_train: 0.6097 acc_train: 0.8536 loss_val: 0.5802 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1954 loss_train: 0.6049 acc_train: 0.8684 loss_val: 0.5799 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1955 loss_train: 0.5820 acc_train: 0.8689 loss_val: 0.5797 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 1956 loss_train: 0.5954 acc_train: 0.8606 loss_val: 0.5795 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 1957 loss_train: 0.5911 acc_train: 0.8693 loss_val: 0.5793 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1958 loss_train: 0.5830 acc_train: 0.8647 loss_val: 0.5791 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1959 loss_train: 0.5800 acc_train: 0.8569 loss_val: 0.5789 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1960 loss_train: 0.5835 acc_train: 0.8624 loss_val: 0.5787 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 1961 loss_train: 0.5826 acc_train: 0.8726 loss_val: 0.5785 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 1962 loss_train: 0.5844 acc_train: 0.8620 loss_val: 0.5783 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1963 loss_train: 0.5814 acc_train: 0.8633 loss_val: 0.5782 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 1964 loss_train: 0.5970 acc_train: 0.8541 loss_val: 0.5780 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1965 loss_train: 0.5914 acc_train: 0.8666 loss_val: 0.5778 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 1966 loss_train: 0.5825 acc_train: 0.8680 loss_val: 0.5777 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 1967 loss_train: 0.5800 acc_train: 0.8661 loss_val: 0.5775 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 1968 loss_train: 0.5911 acc_train: 0.8573 loss_val: 0.5773 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1969 loss_train: 0.5836 acc_train: 0.8643 loss_val: 0.5770 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 1970 loss_train: 0.5751 acc_train: 0.8680 loss_val: 0.5767 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1971 loss_train: 0.5825 acc_train: 0.8629 loss_val: 0.5764 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1972 loss_train: 0.5797 acc_train: 0.8684 loss_val: 0.5761 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1973 loss_train: 0.5969 acc_train: 0.8643 loss_val: 0.5758 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 1974 loss_train: 0.5877 acc_train: 0.8666 loss_val: 0.5754 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1975 loss_train: 0.5869 acc_train: 0.8712 loss_val: 0.5750 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1976 loss_train: 0.5710 acc_train: 0.8735 loss_val: 0.5747 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 1977 loss_train: 0.5757 acc_train: 0.8661 loss_val: 0.5743 acc_val: 0.8893 time: 0.0087s\n",
      "Epoch: 1978 loss_train: 0.5898 acc_train: 0.8564 loss_val: 0.5741 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 1979 loss_train: 0.5842 acc_train: 0.8689 loss_val: 0.5739 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 1980 loss_train: 0.5794 acc_train: 0.8620 loss_val: 0.5738 acc_val: 0.8893 time: 0.0071s\n",
      "Epoch: 1981 loss_train: 0.5965 acc_train: 0.8541 loss_val: 0.5737 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1982 loss_train: 0.5836 acc_train: 0.8643 loss_val: 0.5736 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 1983 loss_train: 0.5762 acc_train: 0.8633 loss_val: 0.5734 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 1984 loss_train: 0.5816 acc_train: 0.8661 loss_val: 0.5733 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 1985 loss_train: 0.5744 acc_train: 0.8578 loss_val: 0.5732 acc_val: 0.8893 time: 0.0086s\n",
      "Epoch: 1986 loss_train: 0.5742 acc_train: 0.8629 loss_val: 0.5732 acc_val: 0.8893 time: 0.0090s\n",
      "Epoch: 1987 loss_train: 0.6048 acc_train: 0.8592 loss_val: 0.5731 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 1988 loss_train: 0.5971 acc_train: 0.8633 loss_val: 0.5730 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 1989 loss_train: 0.5838 acc_train: 0.8606 loss_val: 0.5729 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 1990 loss_train: 0.5731 acc_train: 0.8721 loss_val: 0.5727 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 1991 loss_train: 0.5940 acc_train: 0.8647 loss_val: 0.5726 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 1992 loss_train: 0.5827 acc_train: 0.8638 loss_val: 0.5724 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 1993 loss_train: 0.5752 acc_train: 0.8652 loss_val: 0.5723 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 1994 loss_train: 0.5883 acc_train: 0.8573 loss_val: 0.5723 acc_val: 0.8893 time: 0.0079s\n",
      "Epoch: 1995 loss_train: 0.6021 acc_train: 0.8601 loss_val: 0.5722 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 1996 loss_train: 0.5816 acc_train: 0.8633 loss_val: 0.5721 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 1997 loss_train: 0.5788 acc_train: 0.8643 loss_val: 0.5719 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 1998 loss_train: 0.5700 acc_train: 0.8624 loss_val: 0.5716 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 1999 loss_train: 0.5885 acc_train: 0.8680 loss_val: 0.5713 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2000 loss_train: 0.5745 acc_train: 0.8680 loss_val: 0.5710 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2001 loss_train: 0.5882 acc_train: 0.8675 loss_val: 0.5709 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2002 loss_train: 0.5749 acc_train: 0.8624 loss_val: 0.5707 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2003 loss_train: 0.5909 acc_train: 0.8583 loss_val: 0.5706 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2004 loss_train: 0.5921 acc_train: 0.8633 loss_val: 0.5706 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2005 loss_train: 0.5623 acc_train: 0.8666 loss_val: 0.5705 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2006 loss_train: 0.5816 acc_train: 0.8633 loss_val: 0.5705 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2007 loss_train: 0.5718 acc_train: 0.8712 loss_val: 0.5703 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2008 loss_train: 0.5817 acc_train: 0.8689 loss_val: 0.5702 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 2009 loss_train: 0.5882 acc_train: 0.8606 loss_val: 0.5700 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2010 loss_train: 0.5809 acc_train: 0.8592 loss_val: 0.5699 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2011 loss_train: 0.5881 acc_train: 0.8560 loss_val: 0.5697 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 2012 loss_train: 0.5701 acc_train: 0.8615 loss_val: 0.5695 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2013 loss_train: 0.5659 acc_train: 0.8689 loss_val: 0.5692 acc_val: 0.8856 time: 0.0083s\n",
      "Epoch: 2014 loss_train: 0.5810 acc_train: 0.8666 loss_val: 0.5688 acc_val: 0.8856 time: 0.0084s\n",
      "Epoch: 2015 loss_train: 0.5629 acc_train: 0.8749 loss_val: 0.5684 acc_val: 0.8856 time: 0.0085s\n",
      "Epoch: 2016 loss_train: 0.5744 acc_train: 0.8740 loss_val: 0.5681 acc_val: 0.8856 time: 0.0079s\n",
      "Epoch: 2017 loss_train: 0.6040 acc_train: 0.8541 loss_val: 0.5677 acc_val: 0.8856 time: 0.0074s\n",
      "Epoch: 2018 loss_train: 0.5977 acc_train: 0.8536 loss_val: 0.5675 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2019 loss_train: 0.5742 acc_train: 0.8675 loss_val: 0.5673 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 2020 loss_train: 0.5697 acc_train: 0.8629 loss_val: 0.5671 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 2021 loss_train: 0.5787 acc_train: 0.8684 loss_val: 0.5669 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2022 loss_train: 0.5886 acc_train: 0.8606 loss_val: 0.5666 acc_val: 0.8893 time: 0.0079s\n",
      "Epoch: 2023 loss_train: 0.5676 acc_train: 0.8680 loss_val: 0.5665 acc_val: 0.8893 time: 0.0088s\n",
      "Epoch: 2024 loss_train: 0.5657 acc_train: 0.8652 loss_val: 0.5663 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2025 loss_train: 0.5729 acc_train: 0.8629 loss_val: 0.5660 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 2026 loss_train: 0.5635 acc_train: 0.8620 loss_val: 0.5657 acc_val: 0.8893 time: 0.0086s\n",
      "Epoch: 2027 loss_train: 0.5782 acc_train: 0.8564 loss_val: 0.5655 acc_val: 0.8893 time: 0.0076s\n",
      "Epoch: 2028 loss_train: 0.5790 acc_train: 0.8703 loss_val: 0.5653 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 2029 loss_train: 0.5746 acc_train: 0.8643 loss_val: 0.5650 acc_val: 0.8893 time: 0.0072s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2030 loss_train: 0.5703 acc_train: 0.8712 loss_val: 0.5647 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2031 loss_train: 0.5806 acc_train: 0.8573 loss_val: 0.5645 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2032 loss_train: 0.5454 acc_train: 0.8726 loss_val: 0.5642 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 2033 loss_train: 0.5686 acc_train: 0.8721 loss_val: 0.5639 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 2034 loss_train: 0.5689 acc_train: 0.8740 loss_val: 0.5636 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2035 loss_train: 0.5792 acc_train: 0.8638 loss_val: 0.5635 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2036 loss_train: 0.5740 acc_train: 0.8583 loss_val: 0.5633 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 2037 loss_train: 0.5775 acc_train: 0.8647 loss_val: 0.5632 acc_val: 0.8893 time: 0.0086s\n",
      "Epoch: 2038 loss_train: 0.5749 acc_train: 0.8684 loss_val: 0.5630 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 2039 loss_train: 0.5880 acc_train: 0.8615 loss_val: 0.5629 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 2040 loss_train: 0.5876 acc_train: 0.8633 loss_val: 0.5628 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2041 loss_train: 0.5693 acc_train: 0.8647 loss_val: 0.5627 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2042 loss_train: 0.5973 acc_train: 0.8546 loss_val: 0.5625 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 2043 loss_train: 0.5588 acc_train: 0.8717 loss_val: 0.5625 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2044 loss_train: 0.5784 acc_train: 0.8657 loss_val: 0.5624 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2045 loss_train: 0.5817 acc_train: 0.8633 loss_val: 0.5623 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2046 loss_train: 0.5793 acc_train: 0.8601 loss_val: 0.5622 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2047 loss_train: 0.5755 acc_train: 0.8629 loss_val: 0.5620 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2048 loss_train: 0.5768 acc_train: 0.8749 loss_val: 0.5618 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2049 loss_train: 0.5957 acc_train: 0.8596 loss_val: 0.5616 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2050 loss_train: 0.5760 acc_train: 0.8666 loss_val: 0.5615 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2051 loss_train: 0.5736 acc_train: 0.8712 loss_val: 0.5614 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2052 loss_train: 0.5670 acc_train: 0.8666 loss_val: 0.5613 acc_val: 0.8893 time: 0.0092s\n",
      "Epoch: 2053 loss_train: 0.5767 acc_train: 0.8657 loss_val: 0.5612 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2054 loss_train: 0.5608 acc_train: 0.8620 loss_val: 0.5609 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 2055 loss_train: 0.5674 acc_train: 0.8615 loss_val: 0.5607 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 2056 loss_train: 0.5801 acc_train: 0.8592 loss_val: 0.5605 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2057 loss_train: 0.5769 acc_train: 0.8670 loss_val: 0.5602 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2058 loss_train: 0.5689 acc_train: 0.8592 loss_val: 0.5600 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2059 loss_train: 0.5717 acc_train: 0.8638 loss_val: 0.5597 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2060 loss_train: 0.5709 acc_train: 0.8721 loss_val: 0.5594 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2061 loss_train: 0.5767 acc_train: 0.8721 loss_val: 0.5591 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2062 loss_train: 0.5760 acc_train: 0.8633 loss_val: 0.5589 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2063 loss_train: 0.5647 acc_train: 0.8707 loss_val: 0.5588 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2064 loss_train: 0.5715 acc_train: 0.8587 loss_val: 0.5587 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2065 loss_train: 0.5695 acc_train: 0.8698 loss_val: 0.5586 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2066 loss_train: 0.5644 acc_train: 0.8643 loss_val: 0.5584 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2067 loss_train: 0.5675 acc_train: 0.8680 loss_val: 0.5581 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2068 loss_train: 0.5736 acc_train: 0.8666 loss_val: 0.5580 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2069 loss_train: 0.5846 acc_train: 0.8652 loss_val: 0.5579 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 2070 loss_train: 0.5481 acc_train: 0.8800 loss_val: 0.5577 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2071 loss_train: 0.5770 acc_train: 0.8633 loss_val: 0.5576 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 2072 loss_train: 0.5742 acc_train: 0.8601 loss_val: 0.5575 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2073 loss_train: 0.5762 acc_train: 0.8638 loss_val: 0.5574 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2074 loss_train: 0.5610 acc_train: 0.8698 loss_val: 0.5572 acc_val: 0.8930 time: 0.0089s\n",
      "Epoch: 2075 loss_train: 0.5833 acc_train: 0.8638 loss_val: 0.5572 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2076 loss_train: 0.5772 acc_train: 0.8592 loss_val: 0.5571 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2077 loss_train: 0.5706 acc_train: 0.8703 loss_val: 0.5570 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2078 loss_train: 0.5824 acc_train: 0.8647 loss_val: 0.5570 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2079 loss_train: 0.5848 acc_train: 0.8583 loss_val: 0.5569 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2080 loss_train: 0.5946 acc_train: 0.8707 loss_val: 0.5567 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2081 loss_train: 0.5671 acc_train: 0.8670 loss_val: 0.5565 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2082 loss_train: 0.5567 acc_train: 0.8684 loss_val: 0.5563 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2083 loss_train: 0.5654 acc_train: 0.8569 loss_val: 0.5560 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 2084 loss_train: 0.5693 acc_train: 0.8689 loss_val: 0.5556 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2085 loss_train: 0.5733 acc_train: 0.8767 loss_val: 0.5553 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2086 loss_train: 0.5655 acc_train: 0.8689 loss_val: 0.5550 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2087 loss_train: 0.5616 acc_train: 0.8767 loss_val: 0.5548 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2088 loss_train: 0.5690 acc_train: 0.8675 loss_val: 0.5546 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2089 loss_train: 0.5696 acc_train: 0.8652 loss_val: 0.5545 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2090 loss_train: 0.5768 acc_train: 0.8592 loss_val: 0.5544 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2091 loss_train: 0.5575 acc_train: 0.8670 loss_val: 0.5542 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2092 loss_train: 0.5775 acc_train: 0.8615 loss_val: 0.5541 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2093 loss_train: 0.5602 acc_train: 0.8689 loss_val: 0.5541 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 2094 loss_train: 0.5495 acc_train: 0.8684 loss_val: 0.5540 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2095 loss_train: 0.5556 acc_train: 0.8763 loss_val: 0.5538 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2096 loss_train: 0.5759 acc_train: 0.8661 loss_val: 0.5537 acc_val: 0.8930 time: 0.0092s\n",
      "Epoch: 2097 loss_train: 0.5444 acc_train: 0.8629 loss_val: 0.5535 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2098 loss_train: 0.5690 acc_train: 0.8638 loss_val: 0.5533 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2099 loss_train: 0.5780 acc_train: 0.8592 loss_val: 0.5530 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2100 loss_train: 0.5558 acc_train: 0.8735 loss_val: 0.5527 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2101 loss_train: 0.5777 acc_train: 0.8583 loss_val: 0.5524 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2102 loss_train: 0.5643 acc_train: 0.8675 loss_val: 0.5521 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2103 loss_train: 0.5751 acc_train: 0.8638 loss_val: 0.5519 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2104 loss_train: 0.5472 acc_train: 0.8753 loss_val: 0.5516 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2105 loss_train: 0.5479 acc_train: 0.8721 loss_val: 0.5513 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2106 loss_train: 0.5720 acc_train: 0.8744 loss_val: 0.5510 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2107 loss_train: 0.5718 acc_train: 0.8647 loss_val: 0.5507 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2108 loss_train: 0.5721 acc_train: 0.8643 loss_val: 0.5504 acc_val: 0.8893 time: 0.0087s\n",
      "Epoch: 2109 loss_train: 0.5624 acc_train: 0.8657 loss_val: 0.5503 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 2110 loss_train: 0.5696 acc_train: 0.8633 loss_val: 0.5501 acc_val: 0.8893 time: 0.0089s\n",
      "Epoch: 2111 loss_train: 0.5743 acc_train: 0.8767 loss_val: 0.5499 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 2112 loss_train: 0.5636 acc_train: 0.8707 loss_val: 0.5497 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2113 loss_train: 0.5676 acc_train: 0.8670 loss_val: 0.5496 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2114 loss_train: 0.5562 acc_train: 0.8712 loss_val: 0.5495 acc_val: 0.8893 time: 0.0080s\n",
      "Epoch: 2115 loss_train: 0.5430 acc_train: 0.8795 loss_val: 0.5494 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2116 loss_train: 0.5668 acc_train: 0.8721 loss_val: 0.5492 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 2117 loss_train: 0.5574 acc_train: 0.8735 loss_val: 0.5490 acc_val: 0.8893 time: 0.0080s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2118 loss_train: 0.5634 acc_train: 0.8698 loss_val: 0.5489 acc_val: 0.8893 time: 0.0089s\n",
      "Epoch: 2119 loss_train: 0.5476 acc_train: 0.8703 loss_val: 0.5488 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2120 loss_train: 0.5630 acc_train: 0.8689 loss_val: 0.5486 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2121 loss_train: 0.5764 acc_train: 0.8657 loss_val: 0.5485 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2122 loss_train: 0.5434 acc_train: 0.8721 loss_val: 0.5484 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2123 loss_train: 0.5488 acc_train: 0.8698 loss_val: 0.5483 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2124 loss_train: 0.5420 acc_train: 0.8744 loss_val: 0.5483 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2125 loss_train: 0.5749 acc_train: 0.8564 loss_val: 0.5483 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2126 loss_train: 0.5547 acc_train: 0.8606 loss_val: 0.5483 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2127 loss_train: 0.5712 acc_train: 0.8698 loss_val: 0.5483 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2128 loss_train: 0.5760 acc_train: 0.8666 loss_val: 0.5483 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2129 loss_train: 0.5553 acc_train: 0.8703 loss_val: 0.5481 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2130 loss_train: 0.5567 acc_train: 0.8596 loss_val: 0.5480 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2131 loss_train: 0.5692 acc_train: 0.8633 loss_val: 0.5478 acc_val: 0.8893 time: 0.0080s\n",
      "Epoch: 2132 loss_train: 0.5711 acc_train: 0.8624 loss_val: 0.5476 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2133 loss_train: 0.5691 acc_train: 0.8698 loss_val: 0.5474 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2134 loss_train: 0.5584 acc_train: 0.8652 loss_val: 0.5472 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2135 loss_train: 0.5560 acc_train: 0.8615 loss_val: 0.5471 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2136 loss_train: 0.5660 acc_train: 0.8569 loss_val: 0.5469 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 2137 loss_train: 0.5505 acc_train: 0.8735 loss_val: 0.5467 acc_val: 0.8893 time: 0.0074s\n",
      "Epoch: 2138 loss_train: 0.5622 acc_train: 0.8707 loss_val: 0.5465 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2139 loss_train: 0.5659 acc_train: 0.8657 loss_val: 0.5463 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2140 loss_train: 0.5768 acc_train: 0.8620 loss_val: 0.5462 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2141 loss_train: 0.5452 acc_train: 0.8693 loss_val: 0.5460 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2142 loss_train: 0.5440 acc_train: 0.8707 loss_val: 0.5459 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2143 loss_train: 0.5517 acc_train: 0.8767 loss_val: 0.5457 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2144 loss_train: 0.5599 acc_train: 0.8707 loss_val: 0.5456 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2145 loss_train: 0.5489 acc_train: 0.8837 loss_val: 0.5454 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2146 loss_train: 0.5547 acc_train: 0.8809 loss_val: 0.5454 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2147 loss_train: 0.5518 acc_train: 0.8703 loss_val: 0.5454 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2148 loss_train: 0.5471 acc_train: 0.8707 loss_val: 0.5454 acc_val: 0.8893 time: 0.0073s\n",
      "Epoch: 2149 loss_train: 0.5390 acc_train: 0.8786 loss_val: 0.5453 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2150 loss_train: 0.5695 acc_train: 0.8624 loss_val: 0.5452 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 2151 loss_train: 0.5440 acc_train: 0.8680 loss_val: 0.5451 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2152 loss_train: 0.5676 acc_train: 0.8633 loss_val: 0.5449 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2153 loss_train: 0.5422 acc_train: 0.8781 loss_val: 0.5448 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2154 loss_train: 0.5483 acc_train: 0.8684 loss_val: 0.5447 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2155 loss_train: 0.5524 acc_train: 0.8684 loss_val: 0.5447 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2156 loss_train: 0.5620 acc_train: 0.8693 loss_val: 0.5446 acc_val: 0.8893 time: 0.0084s\n",
      "Epoch: 2157 loss_train: 0.5647 acc_train: 0.8661 loss_val: 0.5445 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2158 loss_train: 0.5660 acc_train: 0.8712 loss_val: 0.5444 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 2159 loss_train: 0.5454 acc_train: 0.8763 loss_val: 0.5443 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 2160 loss_train: 0.5616 acc_train: 0.8657 loss_val: 0.5441 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2161 loss_train: 0.5501 acc_train: 0.8680 loss_val: 0.5440 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2162 loss_train: 0.5599 acc_train: 0.8652 loss_val: 0.5439 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 2163 loss_train: 0.5532 acc_train: 0.8693 loss_val: 0.5437 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2164 loss_train: 0.5515 acc_train: 0.8767 loss_val: 0.5435 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2165 loss_train: 0.5507 acc_train: 0.8758 loss_val: 0.5432 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2166 loss_train: 0.5588 acc_train: 0.8652 loss_val: 0.5429 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2167 loss_train: 0.5537 acc_train: 0.8758 loss_val: 0.5427 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2168 loss_train: 0.5567 acc_train: 0.8675 loss_val: 0.5424 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2169 loss_train: 0.5482 acc_train: 0.8786 loss_val: 0.5422 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2170 loss_train: 0.5487 acc_train: 0.8781 loss_val: 0.5421 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2171 loss_train: 0.5696 acc_train: 0.8629 loss_val: 0.5419 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2172 loss_train: 0.5630 acc_train: 0.8670 loss_val: 0.5418 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2173 loss_train: 0.5493 acc_train: 0.8735 loss_val: 0.5417 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2174 loss_train: 0.5793 acc_train: 0.8601 loss_val: 0.5417 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2175 loss_train: 0.5458 acc_train: 0.8666 loss_val: 0.5417 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2176 loss_train: 0.5518 acc_train: 0.8647 loss_val: 0.5417 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2177 loss_train: 0.5573 acc_train: 0.8670 loss_val: 0.5416 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 2178 loss_train: 0.5622 acc_train: 0.8689 loss_val: 0.5416 acc_val: 0.8893 time: 0.0086s\n",
      "Epoch: 2179 loss_train: 0.5558 acc_train: 0.8730 loss_val: 0.5415 acc_val: 0.8893 time: 0.0081s\n",
      "Epoch: 2180 loss_train: 0.5502 acc_train: 0.8698 loss_val: 0.5415 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2181 loss_train: 0.5736 acc_train: 0.8592 loss_val: 0.5413 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2182 loss_train: 0.5628 acc_train: 0.8652 loss_val: 0.5411 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2183 loss_train: 0.5534 acc_train: 0.8740 loss_val: 0.5410 acc_val: 0.8893 time: 0.0085s\n",
      "Epoch: 2184 loss_train: 0.5471 acc_train: 0.8707 loss_val: 0.5407 acc_val: 0.8893 time: 0.0088s\n",
      "Epoch: 2185 loss_train: 0.5458 acc_train: 0.8753 loss_val: 0.5405 acc_val: 0.8893 time: 0.0077s\n",
      "Epoch: 2186 loss_train: 0.5470 acc_train: 0.8698 loss_val: 0.5403 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2187 loss_train: 0.5493 acc_train: 0.8689 loss_val: 0.5401 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2188 loss_train: 0.5550 acc_train: 0.8680 loss_val: 0.5399 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2189 loss_train: 0.5512 acc_train: 0.8717 loss_val: 0.5397 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2190 loss_train: 0.5586 acc_train: 0.8633 loss_val: 0.5394 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2191 loss_train: 0.5520 acc_train: 0.8726 loss_val: 0.5391 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2192 loss_train: 0.5470 acc_train: 0.8703 loss_val: 0.5388 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2193 loss_train: 0.5760 acc_train: 0.8643 loss_val: 0.5385 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2194 loss_train: 0.5502 acc_train: 0.8675 loss_val: 0.5382 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2195 loss_train: 0.5502 acc_train: 0.8717 loss_val: 0.5380 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2196 loss_train: 0.5461 acc_train: 0.8717 loss_val: 0.5377 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2197 loss_train: 0.5461 acc_train: 0.8670 loss_val: 0.5375 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2198 loss_train: 0.5396 acc_train: 0.8661 loss_val: 0.5373 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2199 loss_train: 0.5473 acc_train: 0.8717 loss_val: 0.5371 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2200 loss_train: 0.5435 acc_train: 0.8790 loss_val: 0.5369 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2201 loss_train: 0.5319 acc_train: 0.8846 loss_val: 0.5367 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2202 loss_train: 0.5529 acc_train: 0.8721 loss_val: 0.5365 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2203 loss_train: 0.5393 acc_train: 0.8624 loss_val: 0.5364 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2204 loss_train: 0.5405 acc_train: 0.8749 loss_val: 0.5362 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2205 loss_train: 0.5425 acc_train: 0.8740 loss_val: 0.5360 acc_val: 0.8930 time: 0.0082s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2206 loss_train: 0.5605 acc_train: 0.8620 loss_val: 0.5360 acc_val: 0.8930 time: 0.0092s\n",
      "Epoch: 2207 loss_train: 0.5276 acc_train: 0.8740 loss_val: 0.5360 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2208 loss_train: 0.5468 acc_train: 0.8744 loss_val: 0.5360 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2209 loss_train: 0.5434 acc_train: 0.8703 loss_val: 0.5360 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2210 loss_train: 0.5490 acc_train: 0.8735 loss_val: 0.5359 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2211 loss_train: 0.5498 acc_train: 0.8735 loss_val: 0.5359 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2212 loss_train: 0.5609 acc_train: 0.8675 loss_val: 0.5358 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2213 loss_train: 0.5441 acc_train: 0.8740 loss_val: 0.5356 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2214 loss_train: 0.5595 acc_train: 0.8620 loss_val: 0.5355 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2215 loss_train: 0.5482 acc_train: 0.8763 loss_val: 0.5354 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2216 loss_train: 0.5359 acc_train: 0.8767 loss_val: 0.5353 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2217 loss_train: 0.5488 acc_train: 0.8675 loss_val: 0.5353 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2218 loss_train: 0.5704 acc_train: 0.8744 loss_val: 0.5352 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2219 loss_train: 0.5505 acc_train: 0.8680 loss_val: 0.5352 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2220 loss_train: 0.5533 acc_train: 0.8772 loss_val: 0.5352 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2221 loss_train: 0.5514 acc_train: 0.8717 loss_val: 0.5351 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2222 loss_train: 0.5409 acc_train: 0.8735 loss_val: 0.5350 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2223 loss_train: 0.5451 acc_train: 0.8675 loss_val: 0.5349 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2224 loss_train: 0.5392 acc_train: 0.8638 loss_val: 0.5348 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2225 loss_train: 0.5523 acc_train: 0.8633 loss_val: 0.5347 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2226 loss_train: 0.5589 acc_train: 0.8610 loss_val: 0.5345 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2227 loss_train: 0.5391 acc_train: 0.8721 loss_val: 0.5344 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2228 loss_train: 0.5530 acc_train: 0.8721 loss_val: 0.5342 acc_val: 0.8930 time: 0.0089s\n",
      "Epoch: 2229 loss_train: 0.5383 acc_train: 0.8744 loss_val: 0.5341 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2230 loss_train: 0.5314 acc_train: 0.8786 loss_val: 0.5340 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2231 loss_train: 0.5375 acc_train: 0.8850 loss_val: 0.5339 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2232 loss_train: 0.5476 acc_train: 0.8753 loss_val: 0.5338 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2233 loss_train: 0.5444 acc_train: 0.8712 loss_val: 0.5338 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2234 loss_train: 0.5648 acc_train: 0.8712 loss_val: 0.5338 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2235 loss_train: 0.5480 acc_train: 0.8703 loss_val: 0.5338 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2236 loss_train: 0.5663 acc_train: 0.8666 loss_val: 0.5338 acc_val: 0.8893 time: 0.0072s\n",
      "Epoch: 2237 loss_train: 0.5568 acc_train: 0.8703 loss_val: 0.5338 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2238 loss_train: 0.5432 acc_train: 0.8661 loss_val: 0.5337 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2239 loss_train: 0.5456 acc_train: 0.8726 loss_val: 0.5337 acc_val: 0.8893 time: 0.0083s\n",
      "Epoch: 2240 loss_train: 0.5479 acc_train: 0.8638 loss_val: 0.5336 acc_val: 0.8893 time: 0.0078s\n",
      "Epoch: 2241 loss_train: 0.5372 acc_train: 0.8698 loss_val: 0.5334 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2242 loss_train: 0.5368 acc_train: 0.8758 loss_val: 0.5333 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2243 loss_train: 0.5528 acc_train: 0.8703 loss_val: 0.5331 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2244 loss_train: 0.5217 acc_train: 0.8809 loss_val: 0.5329 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2245 loss_train: 0.5266 acc_train: 0.8850 loss_val: 0.5326 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2246 loss_train: 0.5464 acc_train: 0.8675 loss_val: 0.5324 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2247 loss_train: 0.5433 acc_train: 0.8703 loss_val: 0.5321 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2248 loss_train: 0.5565 acc_train: 0.8749 loss_val: 0.5318 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2249 loss_train: 0.5297 acc_train: 0.8777 loss_val: 0.5315 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2250 loss_train: 0.5515 acc_train: 0.8707 loss_val: 0.5313 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2251 loss_train: 0.5291 acc_train: 0.8873 loss_val: 0.5312 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 2252 loss_train: 0.5411 acc_train: 0.8712 loss_val: 0.5311 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2253 loss_train: 0.5466 acc_train: 0.8643 loss_val: 0.5311 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2254 loss_train: 0.5377 acc_train: 0.8809 loss_val: 0.5310 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2255 loss_train: 0.5326 acc_train: 0.8721 loss_val: 0.5310 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2256 loss_train: 0.5377 acc_train: 0.8818 loss_val: 0.5309 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2257 loss_train: 0.5313 acc_train: 0.8735 loss_val: 0.5309 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2258 loss_train: 0.5453 acc_train: 0.8707 loss_val: 0.5308 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2259 loss_train: 0.5407 acc_train: 0.8693 loss_val: 0.5308 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2260 loss_train: 0.5394 acc_train: 0.8717 loss_val: 0.5307 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2261 loss_train: 0.5388 acc_train: 0.8841 loss_val: 0.5306 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2262 loss_train: 0.5528 acc_train: 0.8629 loss_val: 0.5306 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2263 loss_train: 0.5408 acc_train: 0.8703 loss_val: 0.5305 acc_val: 0.8893 time: 0.0080s\n",
      "Epoch: 2264 loss_train: 0.5483 acc_train: 0.8763 loss_val: 0.5306 acc_val: 0.8893 time: 0.0082s\n",
      "Epoch: 2265 loss_train: 0.5454 acc_train: 0.8744 loss_val: 0.5306 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2266 loss_train: 0.5310 acc_train: 0.8777 loss_val: 0.5305 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2267 loss_train: 0.5532 acc_train: 0.8620 loss_val: 0.5302 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2268 loss_train: 0.5372 acc_train: 0.8730 loss_val: 0.5299 acc_val: 0.8893 time: 0.0076s\n",
      "Epoch: 2269 loss_train: 0.5530 acc_train: 0.8647 loss_val: 0.5297 acc_val: 0.8893 time: 0.0075s\n",
      "Epoch: 2270 loss_train: 0.5503 acc_train: 0.8643 loss_val: 0.5294 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2271 loss_train: 0.5284 acc_train: 0.8781 loss_val: 0.5291 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2272 loss_train: 0.5437 acc_train: 0.8657 loss_val: 0.5289 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2273 loss_train: 0.5198 acc_train: 0.8800 loss_val: 0.5288 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2274 loss_train: 0.5434 acc_train: 0.8670 loss_val: 0.5287 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2275 loss_train: 0.5487 acc_train: 0.8707 loss_val: 0.5286 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2276 loss_train: 0.5431 acc_train: 0.8707 loss_val: 0.5286 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2277 loss_train: 0.5477 acc_train: 0.8809 loss_val: 0.5285 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2278 loss_train: 0.5319 acc_train: 0.8767 loss_val: 0.5285 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2279 loss_train: 0.5397 acc_train: 0.8772 loss_val: 0.5285 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2280 loss_train: 0.5406 acc_train: 0.8689 loss_val: 0.5286 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2281 loss_train: 0.5464 acc_train: 0.8638 loss_val: 0.5286 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2282 loss_train: 0.5254 acc_train: 0.8712 loss_val: 0.5287 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2283 loss_train: 0.5610 acc_train: 0.8698 loss_val: 0.5287 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2284 loss_train: 0.5348 acc_train: 0.8758 loss_val: 0.5287 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2285 loss_train: 0.5375 acc_train: 0.8767 loss_val: 0.5286 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2286 loss_train: 0.5347 acc_train: 0.8795 loss_val: 0.5285 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2287 loss_train: 0.5358 acc_train: 0.8707 loss_val: 0.5284 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2288 loss_train: 0.5304 acc_train: 0.8730 loss_val: 0.5282 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2289 loss_train: 0.5261 acc_train: 0.8795 loss_val: 0.5280 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2290 loss_train: 0.5420 acc_train: 0.8730 loss_val: 0.5279 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2291 loss_train: 0.5404 acc_train: 0.8753 loss_val: 0.5277 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2292 loss_train: 0.5475 acc_train: 0.8703 loss_val: 0.5276 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2293 loss_train: 0.5418 acc_train: 0.8772 loss_val: 0.5273 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2294 loss_train: 0.5410 acc_train: 0.8795 loss_val: 0.5271 acc_val: 0.8930 time: 0.0079s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2295 loss_train: 0.5393 acc_train: 0.8703 loss_val: 0.5269 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2296 loss_train: 0.5378 acc_train: 0.8749 loss_val: 0.5267 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2297 loss_train: 0.5301 acc_train: 0.8772 loss_val: 0.5266 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2298 loss_train: 0.5437 acc_train: 0.8670 loss_val: 0.5265 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2299 loss_train: 0.5369 acc_train: 0.8703 loss_val: 0.5264 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2300 loss_train: 0.5216 acc_train: 0.8758 loss_val: 0.5263 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2301 loss_train: 0.5449 acc_train: 0.8666 loss_val: 0.5263 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2302 loss_train: 0.5531 acc_train: 0.8707 loss_val: 0.5263 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2303 loss_train: 0.5375 acc_train: 0.8795 loss_val: 0.5262 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2304 loss_train: 0.5342 acc_train: 0.8763 loss_val: 0.5260 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2305 loss_train: 0.5197 acc_train: 0.8763 loss_val: 0.5259 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2306 loss_train: 0.5256 acc_train: 0.8717 loss_val: 0.5257 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2307 loss_train: 0.5522 acc_train: 0.8661 loss_val: 0.5255 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2308 loss_train: 0.5410 acc_train: 0.8726 loss_val: 0.5254 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2309 loss_train: 0.5372 acc_train: 0.8693 loss_val: 0.5252 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2310 loss_train: 0.5494 acc_train: 0.8638 loss_val: 0.5250 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2311 loss_train: 0.5419 acc_train: 0.8698 loss_val: 0.5249 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2312 loss_train: 0.5223 acc_train: 0.8749 loss_val: 0.5249 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2313 loss_train: 0.5324 acc_train: 0.8675 loss_val: 0.5248 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2314 loss_train: 0.5413 acc_train: 0.8786 loss_val: 0.5246 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2315 loss_train: 0.5407 acc_train: 0.8703 loss_val: 0.5245 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2316 loss_train: 0.5423 acc_train: 0.8712 loss_val: 0.5243 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2317 loss_train: 0.5184 acc_train: 0.8767 loss_val: 0.5243 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2318 loss_train: 0.5392 acc_train: 0.8657 loss_val: 0.5242 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2319 loss_train: 0.5339 acc_train: 0.8786 loss_val: 0.5240 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2320 loss_train: 0.5441 acc_train: 0.8712 loss_val: 0.5240 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2321 loss_train: 0.5256 acc_train: 0.8726 loss_val: 0.5240 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2322 loss_train: 0.5387 acc_train: 0.8730 loss_val: 0.5240 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2323 loss_train: 0.5250 acc_train: 0.8675 loss_val: 0.5239 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2324 loss_train: 0.5292 acc_train: 0.8841 loss_val: 0.5238 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2325 loss_train: 0.5363 acc_train: 0.8703 loss_val: 0.5237 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2326 loss_train: 0.5418 acc_train: 0.8753 loss_val: 0.5235 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2327 loss_train: 0.5533 acc_train: 0.8786 loss_val: 0.5233 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2328 loss_train: 0.5258 acc_train: 0.8786 loss_val: 0.5232 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2329 loss_train: 0.5387 acc_train: 0.8804 loss_val: 0.5231 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2330 loss_train: 0.5511 acc_train: 0.8670 loss_val: 0.5230 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2331 loss_train: 0.5462 acc_train: 0.8670 loss_val: 0.5229 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2332 loss_train: 0.5409 acc_train: 0.8703 loss_val: 0.5229 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2333 loss_train: 0.5329 acc_train: 0.8767 loss_val: 0.5229 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2334 loss_train: 0.5439 acc_train: 0.8735 loss_val: 0.5229 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2335 loss_train: 0.5340 acc_train: 0.8666 loss_val: 0.5229 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2336 loss_train: 0.5301 acc_train: 0.8809 loss_val: 0.5228 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2337 loss_train: 0.5190 acc_train: 0.8809 loss_val: 0.5228 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2338 loss_train: 0.5287 acc_train: 0.8726 loss_val: 0.5226 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2339 loss_train: 0.5134 acc_train: 0.8795 loss_val: 0.5225 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2340 loss_train: 0.5498 acc_train: 0.8610 loss_val: 0.5222 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2341 loss_train: 0.5403 acc_train: 0.8744 loss_val: 0.5220 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2342 loss_train: 0.5378 acc_train: 0.8777 loss_val: 0.5218 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2343 loss_train: 0.5266 acc_train: 0.8753 loss_val: 0.5216 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2344 loss_train: 0.5384 acc_train: 0.8652 loss_val: 0.5215 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2345 loss_train: 0.5407 acc_train: 0.8661 loss_val: 0.5214 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2346 loss_train: 0.5202 acc_train: 0.8763 loss_val: 0.5212 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2347 loss_train: 0.5387 acc_train: 0.8740 loss_val: 0.5210 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2348 loss_train: 0.5335 acc_train: 0.8735 loss_val: 0.5209 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2349 loss_train: 0.5260 acc_train: 0.8717 loss_val: 0.5208 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2350 loss_train: 0.5242 acc_train: 0.8758 loss_val: 0.5206 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2351 loss_train: 0.5260 acc_train: 0.8703 loss_val: 0.5205 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2352 loss_train: 0.5350 acc_train: 0.8763 loss_val: 0.5204 acc_val: 0.8930 time: 0.0089s\n",
      "Epoch: 2353 loss_train: 0.5402 acc_train: 0.8703 loss_val: 0.5204 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2354 loss_train: 0.5463 acc_train: 0.8703 loss_val: 0.5204 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2355 loss_train: 0.5171 acc_train: 0.8823 loss_val: 0.5204 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2356 loss_train: 0.5459 acc_train: 0.8712 loss_val: 0.5204 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2357 loss_train: 0.5293 acc_train: 0.8721 loss_val: 0.5203 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2358 loss_train: 0.5250 acc_train: 0.8675 loss_val: 0.5203 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2359 loss_train: 0.5248 acc_train: 0.8800 loss_val: 0.5203 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2360 loss_train: 0.5274 acc_train: 0.8753 loss_val: 0.5203 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2361 loss_train: 0.5350 acc_train: 0.8781 loss_val: 0.5203 acc_val: 0.8930 time: 0.0094s\n",
      "Epoch: 2362 loss_train: 0.5409 acc_train: 0.8777 loss_val: 0.5202 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2363 loss_train: 0.5338 acc_train: 0.8670 loss_val: 0.5202 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2364 loss_train: 0.5248 acc_train: 0.8804 loss_val: 0.5201 acc_val: 0.8967 time: 0.0086s\n",
      "Epoch: 2365 loss_train: 0.5463 acc_train: 0.8684 loss_val: 0.5200 acc_val: 0.8967 time: 0.0076s\n",
      "Epoch: 2366 loss_train: 0.5426 acc_train: 0.8680 loss_val: 0.5198 acc_val: 0.8967 time: 0.0076s\n",
      "Epoch: 2367 loss_train: 0.5396 acc_train: 0.8680 loss_val: 0.5196 acc_val: 0.8967 time: 0.0072s\n",
      "Epoch: 2368 loss_train: 0.5227 acc_train: 0.8832 loss_val: 0.5194 acc_val: 0.8967 time: 0.0083s\n",
      "Epoch: 2369 loss_train: 0.5523 acc_train: 0.8717 loss_val: 0.5191 acc_val: 0.8967 time: 0.0081s\n",
      "Epoch: 2370 loss_train: 0.5290 acc_train: 0.8790 loss_val: 0.5189 acc_val: 0.8967 time: 0.0083s\n",
      "Epoch: 2371 loss_train: 0.5205 acc_train: 0.8753 loss_val: 0.5186 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2372 loss_train: 0.5420 acc_train: 0.8781 loss_val: 0.5184 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2373 loss_train: 0.5134 acc_train: 0.8809 loss_val: 0.5182 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2374 loss_train: 0.5403 acc_train: 0.8758 loss_val: 0.5179 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2375 loss_train: 0.5389 acc_train: 0.8666 loss_val: 0.5178 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2376 loss_train: 0.5220 acc_train: 0.8763 loss_val: 0.5177 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2377 loss_train: 0.5227 acc_train: 0.8763 loss_val: 0.5175 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2378 loss_train: 0.5247 acc_train: 0.8652 loss_val: 0.5175 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2379 loss_train: 0.5125 acc_train: 0.8763 loss_val: 0.5174 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2380 loss_train: 0.5194 acc_train: 0.8813 loss_val: 0.5173 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2381 loss_train: 0.5488 acc_train: 0.8693 loss_val: 0.5172 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2382 loss_train: 0.5415 acc_train: 0.8675 loss_val: 0.5172 acc_val: 0.8930 time: 0.0078s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2383 loss_train: 0.5216 acc_train: 0.8707 loss_val: 0.5172 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 2384 loss_train: 0.5273 acc_train: 0.8735 loss_val: 0.5171 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2385 loss_train: 0.5207 acc_train: 0.8730 loss_val: 0.5171 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2386 loss_train: 0.5297 acc_train: 0.8730 loss_val: 0.5170 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2387 loss_train: 0.5343 acc_train: 0.8744 loss_val: 0.5170 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2388 loss_train: 0.5280 acc_train: 0.8643 loss_val: 0.5170 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2389 loss_train: 0.5143 acc_train: 0.8712 loss_val: 0.5169 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2390 loss_train: 0.5366 acc_train: 0.8652 loss_val: 0.5167 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2391 loss_train: 0.5359 acc_train: 0.8712 loss_val: 0.5166 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2392 loss_train: 0.5423 acc_train: 0.8781 loss_val: 0.5164 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2393 loss_train: 0.5187 acc_train: 0.8777 loss_val: 0.5161 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2394 loss_train: 0.5422 acc_train: 0.8749 loss_val: 0.5159 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2395 loss_train: 0.5371 acc_train: 0.8670 loss_val: 0.5157 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2396 loss_train: 0.5210 acc_train: 0.8749 loss_val: 0.5155 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2397 loss_train: 0.5249 acc_train: 0.8786 loss_val: 0.5154 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2398 loss_train: 0.5305 acc_train: 0.8758 loss_val: 0.5154 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2399 loss_train: 0.5228 acc_train: 0.8804 loss_val: 0.5154 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2400 loss_train: 0.5282 acc_train: 0.8753 loss_val: 0.5153 acc_val: 0.8930 time: 0.0071s\n",
      "Epoch: 2401 loss_train: 0.5311 acc_train: 0.8703 loss_val: 0.5153 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2402 loss_train: 0.5279 acc_train: 0.8712 loss_val: 0.5153 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2403 loss_train: 0.5136 acc_train: 0.8827 loss_val: 0.5153 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2404 loss_train: 0.5426 acc_train: 0.8753 loss_val: 0.5153 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2405 loss_train: 0.5307 acc_train: 0.8744 loss_val: 0.5153 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 2406 loss_train: 0.5310 acc_train: 0.8703 loss_val: 0.5153 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2407 loss_train: 0.5213 acc_train: 0.8767 loss_val: 0.5152 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2408 loss_train: 0.5320 acc_train: 0.8818 loss_val: 0.5151 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2409 loss_train: 0.5141 acc_train: 0.8795 loss_val: 0.5151 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2410 loss_train: 0.5206 acc_train: 0.8744 loss_val: 0.5150 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2411 loss_train: 0.5126 acc_train: 0.8818 loss_val: 0.5150 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2412 loss_train: 0.5262 acc_train: 0.8772 loss_val: 0.5149 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2413 loss_train: 0.5313 acc_train: 0.8735 loss_val: 0.5148 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2414 loss_train: 0.5356 acc_train: 0.8684 loss_val: 0.5146 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2415 loss_train: 0.5238 acc_train: 0.8786 loss_val: 0.5144 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2416 loss_train: 0.5292 acc_train: 0.8744 loss_val: 0.5142 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2417 loss_train: 0.5115 acc_train: 0.8813 loss_val: 0.5140 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2418 loss_train: 0.5177 acc_train: 0.8735 loss_val: 0.5139 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2419 loss_train: 0.5318 acc_train: 0.8689 loss_val: 0.5137 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2420 loss_train: 0.5278 acc_train: 0.8698 loss_val: 0.5136 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2421 loss_train: 0.5195 acc_train: 0.8767 loss_val: 0.5134 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2422 loss_train: 0.5367 acc_train: 0.8707 loss_val: 0.5133 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2423 loss_train: 0.5210 acc_train: 0.8809 loss_val: 0.5132 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2424 loss_train: 0.5272 acc_train: 0.8717 loss_val: 0.5131 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2425 loss_train: 0.5222 acc_train: 0.8767 loss_val: 0.5130 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2426 loss_train: 0.5248 acc_train: 0.8753 loss_val: 0.5129 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2427 loss_train: 0.5340 acc_train: 0.8689 loss_val: 0.5128 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2428 loss_train: 0.5210 acc_train: 0.8841 loss_val: 0.5127 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2429 loss_train: 0.5330 acc_train: 0.8730 loss_val: 0.5125 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2430 loss_train: 0.5236 acc_train: 0.8744 loss_val: 0.5124 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2431 loss_train: 0.5283 acc_train: 0.8707 loss_val: 0.5122 acc_val: 0.8930 time: 0.0074s\n",
      "Epoch: 2432 loss_train: 0.5075 acc_train: 0.8832 loss_val: 0.5121 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2433 loss_train: 0.5196 acc_train: 0.8800 loss_val: 0.5120 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2434 loss_train: 0.5189 acc_train: 0.8726 loss_val: 0.5120 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2435 loss_train: 0.5435 acc_train: 0.8680 loss_val: 0.5119 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2436 loss_train: 0.5143 acc_train: 0.8800 loss_val: 0.5119 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2437 loss_train: 0.5243 acc_train: 0.8740 loss_val: 0.5119 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2438 loss_train: 0.5239 acc_train: 0.8800 loss_val: 0.5120 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2439 loss_train: 0.5212 acc_train: 0.8698 loss_val: 0.5120 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2440 loss_train: 0.5181 acc_train: 0.8744 loss_val: 0.5119 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2441 loss_train: 0.5149 acc_train: 0.8827 loss_val: 0.5119 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2442 loss_train: 0.5010 acc_train: 0.8795 loss_val: 0.5120 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2443 loss_train: 0.5071 acc_train: 0.8878 loss_val: 0.5119 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2444 loss_train: 0.5300 acc_train: 0.8684 loss_val: 0.5119 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2445 loss_train: 0.5393 acc_train: 0.8707 loss_val: 0.5119 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2446 loss_train: 0.5165 acc_train: 0.8767 loss_val: 0.5118 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2447 loss_train: 0.5081 acc_train: 0.8813 loss_val: 0.5116 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2448 loss_train: 0.5059 acc_train: 0.8832 loss_val: 0.5115 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2449 loss_train: 0.5204 acc_train: 0.8703 loss_val: 0.5113 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2450 loss_train: 0.5270 acc_train: 0.8740 loss_val: 0.5111 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2451 loss_train: 0.5098 acc_train: 0.8883 loss_val: 0.5109 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 2452 loss_train: 0.5175 acc_train: 0.8813 loss_val: 0.5106 acc_val: 0.8930 time: 0.0075s\n",
      "Epoch: 2453 loss_train: 0.5227 acc_train: 0.8730 loss_val: 0.5104 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2454 loss_train: 0.5280 acc_train: 0.8790 loss_val: 0.5101 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2455 loss_train: 0.5418 acc_train: 0.8693 loss_val: 0.5099 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2456 loss_train: 0.5183 acc_train: 0.8740 loss_val: 0.5097 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2457 loss_train: 0.5089 acc_train: 0.8763 loss_val: 0.5096 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2458 loss_train: 0.5334 acc_train: 0.8666 loss_val: 0.5095 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2459 loss_train: 0.5232 acc_train: 0.8684 loss_val: 0.5094 acc_val: 0.8930 time: 0.0072s\n",
      "Epoch: 2460 loss_train: 0.5177 acc_train: 0.8786 loss_val: 0.5094 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2461 loss_train: 0.5315 acc_train: 0.8772 loss_val: 0.5094 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2462 loss_train: 0.5139 acc_train: 0.8721 loss_val: 0.5094 acc_val: 0.8930 time: 0.0080s\n",
      "Epoch: 2463 loss_train: 0.5284 acc_train: 0.8763 loss_val: 0.5094 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2464 loss_train: 0.5245 acc_train: 0.8712 loss_val: 0.5094 acc_val: 0.8930 time: 0.0081s\n",
      "Epoch: 2465 loss_train: 0.5277 acc_train: 0.8772 loss_val: 0.5094 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2466 loss_train: 0.5299 acc_train: 0.8772 loss_val: 0.5094 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2467 loss_train: 0.5314 acc_train: 0.8717 loss_val: 0.5094 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2468 loss_train: 0.5069 acc_train: 0.8767 loss_val: 0.5093 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2469 loss_train: 0.5026 acc_train: 0.8823 loss_val: 0.5092 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2470 loss_train: 0.5119 acc_train: 0.8827 loss_val: 0.5091 acc_val: 0.8930 time: 0.0083s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2471 loss_train: 0.5251 acc_train: 0.8777 loss_val: 0.5090 acc_val: 0.8930 time: 0.0092s\n",
      "Epoch: 2472 loss_train: 0.5092 acc_train: 0.8795 loss_val: 0.5089 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2473 loss_train: 0.5367 acc_train: 0.8749 loss_val: 0.5089 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2474 loss_train: 0.5146 acc_train: 0.8712 loss_val: 0.5088 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2475 loss_train: 0.5238 acc_train: 0.8767 loss_val: 0.5088 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2476 loss_train: 0.5196 acc_train: 0.8730 loss_val: 0.5087 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2477 loss_train: 0.5179 acc_train: 0.8772 loss_val: 0.5088 acc_val: 0.8930 time: 0.0082s\n",
      "Epoch: 2478 loss_train: 0.5125 acc_train: 0.8795 loss_val: 0.5087 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2479 loss_train: 0.5230 acc_train: 0.8823 loss_val: 0.5087 acc_val: 0.8930 time: 0.0077s\n",
      "Epoch: 2480 loss_train: 0.5165 acc_train: 0.8837 loss_val: 0.5087 acc_val: 0.8930 time: 0.0079s\n",
      "Epoch: 2481 loss_train: 0.5275 acc_train: 0.8721 loss_val: 0.5087 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2482 loss_train: 0.5198 acc_train: 0.8800 loss_val: 0.5086 acc_val: 0.8930 time: 0.0083s\n",
      "Epoch: 2483 loss_train: 0.5136 acc_train: 0.8841 loss_val: 0.5084 acc_val: 0.8930 time: 0.0088s\n",
      "Epoch: 2484 loss_train: 0.5236 acc_train: 0.8772 loss_val: 0.5083 acc_val: 0.8930 time: 0.0076s\n",
      "Epoch: 2485 loss_train: 0.5180 acc_train: 0.8850 loss_val: 0.5081 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2486 loss_train: 0.5312 acc_train: 0.8740 loss_val: 0.5080 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2487 loss_train: 0.5320 acc_train: 0.8753 loss_val: 0.5078 acc_val: 0.8930 time: 0.0085s\n",
      "Epoch: 2488 loss_train: 0.5204 acc_train: 0.8753 loss_val: 0.5076 acc_val: 0.8930 time: 0.0087s\n",
      "Epoch: 2489 loss_train: 0.5256 acc_train: 0.8790 loss_val: 0.5074 acc_val: 0.8930 time: 0.0078s\n",
      "Epoch: 2490 loss_train: 0.5253 acc_train: 0.8790 loss_val: 0.5073 acc_val: 0.8930 time: 0.0073s\n",
      "Epoch: 2491 loss_train: 0.5143 acc_train: 0.8873 loss_val: 0.5071 acc_val: 0.8967 time: 0.0073s\n",
      "Epoch: 2492 loss_train: 0.5237 acc_train: 0.8712 loss_val: 0.5070 acc_val: 0.8967 time: 0.0083s\n",
      "Epoch: 2493 loss_train: 0.5307 acc_train: 0.8846 loss_val: 0.5068 acc_val: 0.8967 time: 0.0082s\n",
      "Epoch: 2494 loss_train: 0.5152 acc_train: 0.8763 loss_val: 0.5066 acc_val: 0.8967 time: 0.0080s\n",
      "Epoch: 2495 loss_train: 0.5110 acc_train: 0.8763 loss_val: 0.5064 acc_val: 0.8967 time: 0.0079s\n",
      "Epoch: 2496 loss_train: 0.5030 acc_train: 0.8786 loss_val: 0.5063 acc_val: 0.8967 time: 0.0080s\n",
      "Epoch: 2497 loss_train: 0.5229 acc_train: 0.8717 loss_val: 0.5063 acc_val: 0.8967 time: 0.0082s\n",
      "Epoch: 2498 loss_train: 0.5187 acc_train: 0.8790 loss_val: 0.5062 acc_val: 0.8930 time: 0.0084s\n",
      "Epoch: 2499 loss_train: 0.5162 acc_train: 0.8753 loss_val: 0.5062 acc_val: 0.8930 time: 0.0086s\n",
      "Epoch: 2500 loss_train: 0.5083 acc_train: 0.8740 loss_val: 0.5062 acc_val: 0.8967 time: 0.0078s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.0677s\n",
      "Test set results: loss= 0.5922 accuracy= 0.8672\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t_total = time.time()\n",
    "acc_trains, acc_vals, loss_trains, loss_vals = [], [], [], []\n",
    "for epoch in range(epochs):\n",
    "    loss_train, loss_val, acc_train, acc_val = train(epoch)\n",
    "    acc_trains.append(acc_train)\n",
    "    acc_vals.append(acc_val)\n",
    "    loss_trains.append(loss_train)\n",
    "    loss_vals.append(loss_val)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "# Testing\n",
    "acc_test = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e80999c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 5, 1, 2, 4, 6, 2, 0, 1, 0, 5, 1, 4, 4, 0, 1, 1, 1, 3, 2, 1, 2, 1, 2,\n",
       "         2, 2, 2, 1, 3, 5, 3, 2, 1, 0, 5, 6, 6, 2, 3, 6, 1, 0, 5, 6, 3, 5, 3, 5,\n",
       "         6, 1, 3, 2, 5, 0, 1, 2, 4, 2, 3, 1, 1, 1, 1, 1, 1, 5, 1, 0, 1, 2, 1, 3,\n",
       "         3, 2, 3, 0, 1, 2, 0, 0, 1, 0, 0, 5, 0, 1, 1, 2, 2, 1, 4, 1, 5, 5, 2, 1,\n",
       "         1, 4, 1, 6, 1, 1, 4, 1, 3, 1, 2, 5, 1, 2, 2, 3, 1, 4, 6, 1, 1, 0, 3, 5,\n",
       "         1, 2, 2, 3, 2, 1, 0, 0, 5, 2, 1, 5, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 3,\n",
       "         5, 1, 3, 1, 5, 1, 4, 2, 4, 1, 4, 2, 3, 1, 1, 1, 5, 0, 1, 0, 1, 4, 0, 0,\n",
       "         5, 1, 5, 1, 4, 1, 1, 1, 0, 5, 1, 5, 4, 3, 1, 2, 1, 1, 3, 0, 1, 5, 3, 6,\n",
       "         6, 0, 1, 1, 3, 2, 5, 5, 0, 0, 1, 5, 0, 6, 0, 3, 5, 0, 6, 1, 4, 1, 1, 0,\n",
       "         3, 2, 6, 5, 3, 6, 0, 2, 2, 1, 4, 0, 5, 6, 0, 4, 1, 1, 1, 6, 0, 1, 3, 1,\n",
       "         2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 6, 0, 6, 3, 1, 5, 2, 3, 3, 3, 2, 2, 2, 2,\n",
       "         1, 1, 0, 0, 0, 5, 1], device='cuda:0'),\n",
       " tensor([6, 1, 1, 1, 4, 6, 2, 6, 1, 0, 5, 1, 4, 4, 0, 1, 6, 1, 3, 2, 1, 2, 1, 2,\n",
       "         2, 2, 2, 2, 5, 5, 3, 2, 1, 0, 5, 6, 5, 2, 3, 3, 1, 0, 0, 6, 3, 5, 3, 5,\n",
       "         6, 1, 3, 2, 5, 0, 1, 2, 4, 6, 3, 1, 1, 1, 1, 1, 1, 5, 1, 0, 1, 2, 1, 3,\n",
       "         3, 2, 3, 0, 1, 2, 0, 0, 1, 0, 0, 5, 0, 1, 1, 2, 2, 1, 4, 3, 2, 1, 2, 2,\n",
       "         1, 4, 1, 6, 1, 1, 4, 1, 0, 1, 2, 5, 1, 2, 5, 3, 1, 4, 6, 1, 1, 0, 3, 5,\n",
       "         1, 2, 2, 3, 2, 1, 0, 0, 5, 2, 1, 5, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 3,\n",
       "         5, 1, 3, 1, 5, 6, 4, 2, 4, 2, 4, 2, 5, 1, 1, 2, 5, 0, 1, 0, 1, 4, 1, 0,\n",
       "         5, 1, 5, 1, 4, 1, 1, 1, 0, 5, 1, 5, 4, 3, 1, 2, 1, 5, 3, 0, 1, 5, 3, 6,\n",
       "         6, 0, 1, 1, 3, 2, 5, 4, 0, 0, 1, 4, 0, 1, 0, 3, 5, 0, 6, 1, 4, 4, 3, 5,\n",
       "         3, 2, 6, 5, 3, 5, 0, 2, 2, 1, 4, 0, 5, 6, 0, 4, 2, 1, 1, 1, 0, 1, 3, 1,\n",
       "         2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 6, 0, 3, 3, 1, 5, 2, 3, 3, 3, 2, 2, 2, 2,\n",
       "         1, 0, 0, 0, 0, 5, 1], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(features, adj)\n",
    "output[idx_test].max(1)[1].type_as(labels), labels[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6c8f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1_Score_Macro</th>\n",
       "      <th>F1_Score_Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCN</td>\n",
       "      <td>0.873961</td>\n",
       "      <td>0.867159</td>\n",
       "      <td>0.867159</td>\n",
       "      <td>0.852005</td>\n",
       "      <td>0.867483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Training Accuracy %  Testing Accuracy %  Accuracy Score  \\\n",
       "0   GCN             0.873961            0.867159        0.867159   \n",
       "\n",
       "   F1_Score_Macro  F1_Score_Weighted  \n",
       "0        0.852005           0.867483  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(features, adj)\n",
    "predict, y_test = output[idx_test].max(1)[1].type_as(labels).cpu(), labels[idx_test].cpu()\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "f1_score_macro = f1_score(y_test, predict, average='macro')\n",
    "f1_score_weighted = f1_score(y_test, predict, average='weighted')\n",
    "\n",
    "compare_model_adj = pd.DataFrame(data=[[\"GCN\", acc_trains[-1], acc_test, accuracy, f1_score_macro, f1_score_weighted]],\n",
    "                                 columns=['Model', 'Training Accuracy %', 'Testing Accuracy %', 'Accuracy Score', 'F1_Score_Macro',\n",
    "                                          'F1_Score_Weighted'])\n",
    "# compare_models = compare_models.append(compare_model_3,ignore_index=True)\n",
    "compare_model_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85cd85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_model_adj.to_csv('./compare_model_adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48c8c670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAopUlEQVR4nO3deZgU1dXH8e9hWBVENjd2FTWouDC4xyVGxZhI3OKGJi5B3I3GPUYFE6NJjLhEg4p7UBNR0URN9FWMW3BwBQzKLoKC4AZEFDjvH7cm3TNMzzQzXVPdXb/P8/TTVbeqq07NwJyue+vea+6OiIikV4ukAxARkWQpEYiIpJwSgYhIyikRiIiknBKBiEjKKRGIiKScEoGUJTN70sx+XOh9RcqRqR+BFAszW5q1ug6wAlgVrZ/i7vc3f1SNZ2Z7A/8HLAccmA/8xt3vTDAskTW0TDoAkWru3r562cxmAye7+zO19zOzlu6+sjlja4L57t7DzAwYAvzVzP7t7lOzdyqxa5Iyo6ohKXpmtreZzTOzC83sI+BOM+tkZk+Y2SIz+zRa7pH1mefN7ORo+Sdm9qKZ/S7ad5aZHdjIffua2Qtm9qWZPWNmN5vZfQ1dgwePAp8C/aPzvGRmfzCzJcAVZtbRzO6JrmmOmf3CzP73f9TMfmpm70bnnmpmO0blm5jZw9HnZpnZWVmf2cnMqszsCzP72Myui8rbmtl9ZrbYzD4zs9fMbMNG/5KkpCkRSKnYCOgM9AaGEf7t3hmt9wL+C9xUz+d3BqYBXYFrgTuib+lru++fgYlAF+AK4Lh8gjezFmZ2CLA+8E7WeWYCGwC/Am4EOgKbAnsBxwMnRJ8/Ijrf8cB6wMHA4ihRPA68BXQH9gXOMbMDonOMAka5+3rAZsBDUfmPo3P1jK5lOOFnKCmkRCClYjVwubuvcPf/uvtid3/Y3Ze7+5eEP6R71fP5Oe5+m7uvAu4GNgZyfQOuc18z6wUMAn7p7l+7+4vA+Abi3sTMPgM+AS4HjnP3adG2+e5+Y1Ql9DVwJHCxu3/p7rOB35NJNCcD17r7a9HdxXR3nxPF083dR0QxzQRuA46KPvcNsLmZdXX3pe7+alZ5F2Bzd1/l7pPc/YsGrkXKlNoIpFQscvevqlfMbB3gD8BgoFNU3MHMKqI/4LV9VL3g7sujL/jt69ivvn27AkvcfXnWvh8QvlXnMt/de+TY9kHWclegNTAnq2wO4Vs+0Tlm1HGM3mSSTbUK4F/R8knACOA/ZjYLuNLdnwDujY75gJmtD9wHXOru39RzLVKmdEcgpaL2423nAVsCO0fVHntG5bmqewphAdA5SkLV6ksCDcm+pk8I39J7Z5X1Aj6Mlj8gVO3U9gEwy93Xz3p1cPfvAbj7++5+NKH66RpCY/W67v6Nu1/p7v2B3YDvE6qdJIWUCKRUdSDUaX9mZp0J1S6xiqpiqggNu63NbFfgBwU69ipC/f2vzKyDmfUGziV8Uwe4Hfi5mQ20YPNon4nAF1FDejszqzCzbcxsEICZDTWzbu6+GvgsOtYqM9vHzLY1swrgC0ISqutOSlJAiUBK1fVAO8I36VeBp5rpvMcCuwKLgauABwn9HQrhTGAZoQH5RULD9BgAd/8LoR3kz8CXwKNA5yiB/ADYHphF+HncTmgIhlB1NiXqozEKOCqqYtsI+CshCbwLTCCTdCRl1KFMpAnM7EHgP+4e+x2JSFx0RyCyFsxskJltFj0OOpjQSezRhMMSaRI9NSSydjYCxhEevZwHnOrubyQbkkjTqGpIRCTlVDUkIpJyJVc11LVrV+/Tp0/SYYiIlJRJkyZ94u7d6tpWcomgT58+VFVVJR2GiEhJMbM5ubapakhEJOWUCEREUk6JQEQk5ZQIRERSTolARCTllAhERFJOiUBEJOXSkwhmzIBzzoHFi5OORESkqKQnEbz+OowaBV27wopCDR8vIlL60pMIfvhDWHfdsLzjjomGIiJSTNKTCFq1gs8+C8tTp8KWWyYajohIsUhPIgBo2RL++c+w/N57YAZLliQbk4hIwtKVCAC++93QVlCtSxe1GYhIqqUvEQCcdRY89lhmvW1b+Oqr5OIREUlQOhMBwMEHQ/Zw1httBB9+mFw8IiIJSW8iABg4EP70p7D8+efQowcsXZpsTCIizSzdiQBg2DC44YbMeocOcNddiYUjItLclAgAzjwTXnops37CCeElIpICSgTVdtutZhvBXXeF/gYiImVOiSDbJpuEJ4qqbb21+hmISNlTIqht1KiaTxN16QL/+hd8801yMYmIxEiJoC4DB8LTT2fW99wTWrdOLh4RkRjFlgjMbIyZLTSzyTm2dzSzx83sLTObYmbF1Tq7//7wyCM1y045JZlYRERiFOcdwV3A4Hq2nw5MdfftgL2B35tZcX3t/uEPQ/+CaqNHw5AhsGxZYiGJiBRabInA3V8A6mtpdaCDmRnQPtp3ZVzxNNp668EFF2TWx4+H9u3DgHUao0hEykCSbQQ3Ad8C5gPvAGe7++q6djSzYWZWZWZVixYtas4Yg2uugbrO+8QTzR+LiEiBJZkIDgDeBDYBtgduMrP16trR3Ue7e6W7V3br1q35IszWtSu4w89+lik7/HAYMyaZeERECiTJRHACMM6D6cAsYKsE48nPVVfVXD/ppFBNNGRIMvGIiDRRkolgLrAvgJltCGwJzEwwnvyss064M5g4sWb5+PEwblwyMYmINEGcj4+OBV4BtjSzeWZ2kpkNN7Ph0S4jgd3M7B3gWeBCd/8krngKbtAg+Mc/apYddhgccQTMLP58JiJSzdw96RjWSmVlpVdl9/xNmjvcfz8cd1ymbMMN4aOPkotJRKQWM5vk7pV1bVPP4qYyg6FDa5Z9/DGsLL4nYUVE6qJEUCjZHc8AWrWCX/86mVhERNaCEkGhrLcenHpqzbJLL4V33kkmHhGRPCkRFNK118I998ABB2TKBgxY825BRKSIKBEUUvv2odH4qafgxRcz5euvD3PnJhaWiEh9lAjisvvuNdd794Z3300mFhGReigRxKn2XUD//vDZZ4mEIiKSixJBnHr2hNdfr1l27bXJxCIikoMSQdx22CF0OmvbNqxffTU880yyMYmIZFEiaC6TJmWW99sPdtstJAgRkYQpETSX/v1rzoP8yiua2EZEioISQXPaf394/vnMuu4KRKQIKBE0t732yiy/8Qb84hdKBiKSKCWCJDz7bGb517+GY49NLhYRST0lgiT061dzfezYZOIQEUGJIBk9e4aG4iuuyJS9+qqqiEQkEUoESWndGi65JLO+667w5z8nF4+IpJYSQZJataq5PnQofPppMrGISGopESRtwoSa6507JxOHiKRWnJPXjzGzhWY2uZ599jazN81siplNyLVfWdtzT1i4MOkoRCTF4rwjuAsYnGujma0P/BE42N23Bo6IMZbi1q1bzfWvv04mDhFJpdgSgbu/ACypZ5djgHHuPjfaP91fi6+6KrPcpg3Mnp1YKCKSLkm2EWwBdDKz581skpkdn2tHMxtmZlVmVrVo0aJmDLEZXXopjBiRWT/vvORiEZFUMY/x2XUz6wM84e7b1LHtJqAS2BdoB7wCHOTu79V3zMrKSq+qqooh2iLgDi1a1FwXESkAM5vk7pV1bUvyjmAe8JS7L3P3T4AXgO0SjCd5ZqF/QbUddkguFhFJjSQTwWPAt82spZmtA+wMaFLf7Env33wTli9PLBQRSYc4Hx8dS6ju2dLM5pnZSWY23MyGA7j7u8BTwNvAROB2d8/5qGlqDBpUc+yhddeFefOSi0dEyl7LuA7s7kfnsc9vgd/GFUPJOuooWLkSjjsurJ98Mjz1VLIxiUjZUs/iYtWzZ2Y5e2YzEZECUyIoVttvX3P95psTCUNEyp8SQbHq2BG++iqzfsYZycUiImVNiaCYtWkDR2c1tVx2WXKxiEjZUiIodtlzFFx1FSxdmlwsIlKWlAhKwXXXZZY//DC5OESkLCkRlILhwzPLW20FixcnF4uIlB0lglLQrh385z+Z9fPPTy4WESk7SgSlYsstM8t33plcHCJSdpQISkn37pllNRqLSIEoEZSSt9/OLHfoAO+/n1wsIlI2lAhKSefONSev2WKL5GIRkbKhRFBqLr645vrVVycTh4iUDSWCUtOyJaxenVm/5JLkYhGRsqBEUIrMaq4vWJBMHCJSFpQIStUDD2SWN9kkuThEpOQpEZSqI4+EfffNrN96a3KxiEhJUyIoZc88k1k+9dTk4hCRkqZEUOr+/vfM8lVXwddfJxeLiJSkBhOBme1uZutGy0PN7Doz653H58aY2UIzq3dCejMbZGarzOzw/MOW/znwwMzyZZfBaaclF4uIlKR87ghuAZab2XbABcAc4J48PncXMLi+HcysArgG0KS8hXLHHUlHICIlJp9EsNLdHRgCjHL3UUCHhj7k7i8ASxrY7UzgYWBhHnFILscfX3Ndk92LyFrIJxF8aWYXA0OBv0Xf4ls19cRm1h04BGjwcRczG2ZmVWZWtWjRoqaeuvzccQdccEFmffBgWLYsuXhEpKTkkwiOBFYAJ7n7R0B34LcFOPf1wIXuvqqhHd19tLtXuntlt27dCnDqMtOyJVx0Uc2ya69NJhYRKTkWan3q2SE0FH/l7qvMbAtgK+BJd/+mwYOb9QGecPdt6tg2C6juItsVWA4Mc/dH6ztmZWWlV1VVNXTqdKrd43j58jCpjYiknplNcvfKurblc0fwAtAmqsp5FjiB0BDcJO7e1937uHsf4K/AaQ0lAWnAa6/VXM+e1UxEJId8EoG5+3LgUOBGdz8E2LrBD5mNBV4BtjSzeWZ2kpkNN7PhDX1WGqmyEubOzazvuKPmNxaRBrXMYx8zs12BY4GTorKKhj7k7kfnG4S7/yTffaUBPXvCTTfBGWeE9a5doYHqPxFJt3zuCM4BLgYecfcpZrYp8FysUUnTHHVUzfXaVUYiIlkavCNw9wnABDPrYGbt3X0mcFb8oUmjdekS5ixoEeX5nXbSXYGI5JTPEBPbmtkbwGRgqplNMrMG2wgkYbWfIBIRySGfqqE/Aee6e2937wWcB9wWb1hSEDffnFn+4IPk4hCRopZPIljX3f/XJuDuzwPrxhaRFM5xx2WWe/WClSuTi0VEilY+iWCmmV1mZn2i1y+AWXEHJgXQodaQUEOHJhOHiBS1fBLBiUA3YBzwSLR8QpxBSQHdeGNm+cEH4ZBDkotFRIpSPk8NfYqeEipdp5wShpq48MKw/uijiYYjIsUn51hDZvY4kPOZQ3c/OK6g6qOxhhop+ymit9+GbbbRk0UiKVLfWEP13RH8LqZ4JAknnghjxoTlAQPguuvgZz9LNiYRKQoNjj5abHRH0EhffAEdO9Yse/FF2H33ZOIRkWbV1NFHpRyst17N+Y0B9tgDLrkk9EIWkdRSIkiTxx+H++6rWXb11fDWW8nEIyJFQYkgTSoq4Nhj4fbba5a30D8DkTRr8PHRHE8PfQ5UAX9y96/iCExi1KrWlNNjxsCoUcnEIiKJy6tnMbCUML7QbcAXwMfAFmjModL0gx/UXL/hBnjppWRiEZHE5TMxzQ7uvmfW+uNm9oK772lmU+IKTGLUqRO8/z488wycemoo22OP0H7Qty/stluy8YlIs8onEXQzs17uPhfAzHoRJpsH+Dq2yCRem28eXtWJADJjEZXYI8Ui0jT5JILzgBfNbAZgQF/gNDNbF7g7zuBERCR+DbYRuPvfgX6EKSvPAbZ097+5+zJ3vz7X58xsjJktNLPJObYfa2ZvR6+XzWy7Rl2BNM3TT69Z9s03zR+HiCQm3+cGBwJbAwOAH5nZ8Xl85i5gcD3bZwF7ufsAYCQwOs9YpJD23x/uuKNm2ciRycQiIonIZ6rKewnjDu0BDIpedXZTzubuLwBL6tn+cjSyKcCrQI98ApYYnHgijB+fWR85MkxkM2hQcjGJSLPJp42gEujv8Q5KdBLwZK6NZjYMGAbQq1evGMNIscG1bt4++CC8ZsyAzTZLJiYRaRb5VA1NBjaKKwAz24eQCC7MtY+7j3b3Snev7NatW1yhpFurVuFpoYNrjS6++ebJxCMizSafO4KuwFQzmwisqC4sxHwEZjYAuB040N0XN/V4UgB33x36GWRbvBi6dEkmHhGJXT6J4Io4Thz1RxgHHOfu78VxDmmE9deHe+8N7QNbbRXKunYNyaBz50RDE5F45DNV5YTGHNjMxgJ7A13NbB5wOdAqOuatwC+BLsAfLcyUtTLXWNnSzIYOXbNT2ejRcNFFycQjIrGqb6rKF919DzP7kpqDzhng7r5ecwRYmyamaUZ1TWWpXsciJalRU1W6+x7Re4e4ApMSVJ0cli2DddZJNhYRKYi8OpSZWYWZbWJmvapfcQcmRWD69NzbJjSqxlBEilA+8xGcSajf/xiontPQCb2MpZxtthnMnAkTJ8JRR9XcNmNGMjGJSMHl89TQ2YTxhfR4Zxr17Rte77wDv/pVpvzMM2GvvWDbbZOLTUQKIp+qoQ8IM5JJmo0cCS++WLNswAA44YRk4hGRgsl3hrLnzexiMzu3+hV3YFJkzGD33eHhh2uW33UXfPRRIiGJSGHkkwjmAv8EWgMdsl6SRoceumbZxhvD6afD3LnNH4+INFk+HcqubI5ApISceircckvNsj/+MTQsP5lz7EARKVI5E4GZXe/u55jZ49TsUAYUZqwhKVG5RoB96qkw73H1lJciUhLquyO4N3r/XXMEIiXkvPPCwHTDh6+57bjjlAhESkx9PYsnRe/qOSQ1tWoFp5wSBqYbOHDN7V26wCOPwJ57Nn9sIrLW8ulQ1g+4GugPtK0ud/dNY4xLSsGOO8KKFdCmTc3yJUtCHwONSyRSEvJ5auhO4BZgJbAPcA+ZaiNJu9atc2/be+9mC0NEGi+fRNDO3Z8ljFQ6x92vAL4Tb1hSUubPr7t8woQwt4GIFLV8EsFXZtYCeN/MzjCzQ4ANYo5LSsnGG4dqIPc1ZzI7/vjQXiAiRSufRHAOsA5wFjAQGAr8OMaYpJQtXLhm2aGHhp7Jy5Y1fzwi0qB6E4GZVQA/cvel7j7P3U9w98Pc/dVmik9KTYsWYdTSurRvH2Y6++IL2GMPeP75Zg1NROqWMxGYWUt3XwUMNKtrqiqRHN5/H1avhgsvXHPbKadAx47w0kvwY91YihSD+u4IJkbvbwCPmdlxZnZo9auhA5vZGDNbaGaTc2w3M7vBzKab2dtmtmMj4pdiZBZel10Gu+6ae78VK5ovJhHJKZ82gs7AYsKTQt8HfhC9N+QuYHA92w8E+kWvYYRHVKWcrLsuvPxy7u0ffxyeOPryy+aLSUTWUF+Hsg2i4aYnE8Yayq4earCnkLu/YGZ96tllCHCPuzvwqpmtb2Ybu/uCPOKWUvLb38K4cfDKK2tu6949vC9fDu3aNW9cIgLUf0dQAbSPXh2ylqtfTdWdMOlNtXlRmZSbn/+8/jsDgH794JNPdHcgkoD67ggWuPuIGM9dVwN0nXcaZjaMUH1Er1wjX0pp+/BD6NYtLH/3u7D//nD++cnGJJIS9d0RxP2k0DygZ9Z6D6DOLqruPtrdK929slv1HwspPYsWwRNPwJVXwtNP597vmWfgggvgc82QKtIc6ksE+8Z87vHA8dHTQ7sAn6t9oMx17QoHHQS//GX4xr/99vXvP2AALF7cLKGJpFnORODuS5pyYDMbC7wCbGlm88zsJDMbbmbVg9j/nTAf8nTgNuC0ppxPStCTT8Jf/hI6l9Vl7tyQPEaODOvLl8PKlc0Xn0hKmJfYUMGVlZVeVVWVdBhSaFddFfod5DJrFvTtCwccEGZCE5G1YmaT3L2yrm359CMQid8FF4S7g1z69g3v2W0LCxZozgORAlAikOLQujUcfjhceml++7/4ImyyCVx3XbxxiaSAEoEUl5Ejwzf9+pjBt78dlh9/PP6YRMqcEoEUFzPYaKP8958wAW68Mb54RFJAiUCK22efNbzPWWeFtoM//hE+/TT2kETKjRKBFLeOHeEPf4ARI+oe1rra4MFw+unQuTMsXQrHHRcGtRORBunxUSlO8+ZBy5ZrVhOtzdQYnTvDJZdAp07w3/+GRCGSUvU9PqpEIKXl/fdh6tTQl+DWW9fusyX2b12kkOpLBPUNOidSfPr1C68hQ6CyEk4+OemIREqe2gikdA0dCsOG5b//7bfHF4tICVMikNLVpg386U91T3hTl5/+NLQxnHZaZtyi1avjjVGkBCgRSOnbZRfYe+8wf8Gzzza8/y23hGk0W7WCigolA0k9tRFIeXjuuczybbeFb//5qqgIM6NNmwYDBxY+NpEip0Qg5efkk6FXr9AZ7dxzw+xnDenQIbzPng29e8cZnUjRUdWQlKf994cf/QgmTQrJIN/B7B56KCQQs/AaOzbWMEWKgfoRSHo89xx861uw334weXL+n7vySvjZzzJ3DSIlSPMRiADss0/oqfzOO3Dkkfl/7vLL6580R6TEKRFIOj3wALz1VmZ9xx3r33/UKOjRIwxqV2J30SINUSKQ9BowIAxm9/LLoS2hIR9+GMYvqqhQ24GUlVgTgZkNNrNpZjbdzC6qY3tHM3vczN4ysylmdkKc8Yis4bLLYNddw7I7DB/e8Gfc4ZhjYP58OPTQ/PouiBSx2BKBmVUANwMHAv2Bo82sf63dTgemuvt2wN7A782sdVwxiTTolltCtVE+uneHRx6B7343PGE0cWK8sYnEJM47gp2A6e4+092/Bh4AhtTax4EOZmZAe2AJsDLGmEQatt56jfvczjvD+PFhyGuREhJnIugOfJC1Pi8qy3YT8C1gPvAOcLa7r9Hf38yGmVmVmVUtWrQornhFgt12C08XvfBCmPBmbQwZsnZPJIkUgTgTQV0ziNR+3OIA4E1gE2B74CYzW+PrmLuPdvdKd6/s1q1boeMUqaljR1iwAL79bXjsMXjjjVDeqlV4P/PM+j//+OOZ5dWrw+B2IkUszkQwD+iZtd6D8M0/2wnAOA+mA7OArWKMSWTttG4N228fGohXrAivG26Ae++t/3MdOoTPVVRkEohIkYozEbwG9DOzvlED8FHA+Fr7zAX2BTCzDYEtgZkxxiTSeGYhMUCYC+HTT+Hmm+ved+nSmv0Uunev+UTSyy/Dgw/GF6vIWoh1iAkz+x5wPVABjHH3X5nZcAB3v9XMNgHuAjYmVCX9xt3vq++YGmJCisqKFdC2bf77n356zeShzmnSTDRnsUicvv46dDbbdNO1/+wmm8B774X5EWpbsACWLIGtt256jJJ6GmtIJE6tW0PfvuHb/dr2JZg/H9q3hwkTwiipq1bB3/8eRkDt2xe22SaWkEWyKRGIFNKgQfD222H5sMNCv4J87L03/OEP0LIlHHQQdOoUqp0aMnkyfPNNo8MVAU1MI1J4224LH30EG2wQGpinTAmPpPbo0bjjPfMMtGsHO+wA66yTKZ8zJ5zrzDPDk0wijaQ7ApE4bLhhSAIA/fuHp4b+/OfGHWu//WCPPWCnncIxq+dS+Pzz8J49TadIIygRiDSXo4+GGTPg8MMb9/kpU8L7+eeH9+pHWfOpQhKphxKBSHPadFP4y19Cj+NsW20F06bld4ynnoLvfCfTMF3XnMyTJsFvftO0WCU11EYgkgSz8E2+RYvQQLy2nnsuUyW0fDl88AH06hXWZ8+GyugpwTZtwjSbIvXQHYFIUlq3XjMJvPpq+Ib/+uthiIp8VScBgD59MsvnnhuSzi23hJ7OO+8cGp5FsigRiBSTnXcOncx22CEMdnfnnYU57mmnhcQycSJ89VXNHs0XXhiqm6ZODaOtahjt1FEiEClmP/lJmEWt0LbeOtwpXHtteB14IJx9Njz9NPzrX4U/nxQ1DTEhUuxWrw7tAMuWhW/zjz8eehzvs08853vsMTj44HiOLYnREBMipaxFizAMxYYbQu/ecMYZoSfy4sVhroNLLgn7bbZZmGazc+emnW/IkNDLGcLxzzwT5s1r2jGlqCkRiJSqzp3DfAcjRoSxiaZPD7OjLV4M++/ftGNXj3t00klw003wgx+suc/q1XDeefk/9ipFS4lApNRVVIQhLLL9/vfh/R//gNtvb9xxW7aEe+4Jy2++CXfdBbNmZbZPmQLXXQeHHtq440vRUD8CkXK0zTaZJ4NWrw5VSwcdFKqZFiyAzTfP7Nu2bWh7aMgJJ4T3Aw8MdwkDBoT1qVPDQHurVoV5ns8+O0zMs2xZqM6SoqfGYpE0evjh8Af7ww9DQ3T2YHZNNWtWGEIbQjKaPj30XejevXDnkLWmxmIRqemww0IDsHv4I+0OH39cmGNfdVVm2Qz69Qsjry5cGKqSpk0LvZ/rMm0afPllYeKQvOmOQEQyXn01/PEeMSJMkBOnuv72mMGuu4Y5naWgdEcgIvnZZZfQu/mBB8Jdw5w5MHcu3HEHfP/7hT3X4sXhffbsMO5S9UB8r7xS2PNIg2JNBGY22Mymmdl0M7soxz57m9mbZjbFzCbEGY+I5KlDB/jrX8MYRj17woknhnaFl17K7HPEEZnl669f+3N8//thaO6+feGnPw1POFWbOVPDazej2KqGzKwCeA/YD5gHvAYc7e5Ts/ZZH3gZGOzuc81sA3dfWN9xVTUkkrB//zvMvlbdIFxt5cpQpTRyZOHO9bvfwd13Z6b//PrrMM9z9cB6X30VqpPatCncOctUUlVDOwHT3X2mu38NPAAMqbXPMcA4d58L0FASEJEisPPOayYBCP0ORowIM6pV+7//a9q5fv5zeOed8HTT55+HwfP69g29qFetCp3qNtss7PvFF+Elay3ORNAd+CBrfV5Ulm0LoJOZPW9mk8zs+LoOZGbDzKzKzKoWLVoUU7giUhBPPgmjR8PYsWE8JHdYsqRpx+zRA9ZfP7RVQKg6uu66MFJq9cQ8HTuG19lnh/Vly2D33cMorlKvOBOB1VFWux6qJTAQOAg4ALjMzLZY40Puo9290t0ru3XrVvhIRaRwKipCnf9RR2XKOnWCq6+GceMKd54LLsgsP/10ZvmGG0LiOeWU8PRR9dSeklOcPYvnAT2z1nsA8+vY5xN3XwYsM7MXgO0IbQsiUk4uip4Xef11+OQT6NoV7r8fbr01fHuHUNffmEbiwYNrrnfpkll+9lkYODD0rB4xIpy/bduQsNZZJzSGQxh1dcECGDYs3HFk974uc3E2Frck/EHfF/iQ0Fh8jLtPydrnW8BNhLuB1sBE4Ch3n5zruGosFikzixfDf/4Tejjvt19IBG3bNt/5p0yB/v1Do3Pt8s02g4cegqFD19xeYhJpLHb3lcAZwNPAu8BD7j7FzIab2fBon3eBp4C3CUng9vqSgIiUoS5dQl1+dSNzmzZhxrTx4zP7fPYZDBoE227buDme67P11mFWuNpmzYJzzoHjjw+D+JmFu4ts7iG2EqeexSJSvJ57LiSK6gHussu/851kYnr66TDMtztccw1cfHF4pHXjjTP7rFoVBvgrorsI9SwWkdK0zz5rJoHq8uXLwx/jVasy5fffHxqIDzkkvpgOOCD8gW/RIiQBgPvuC2Vmoad0y5Zh+/XXwzffhNdGG4XHX7PvdIqE7ghEpPSZhSGvP/oorI8dC8ccA++/D6+9FpaLydZbh57Z/ftnemj/9rew1Vaw3XZhzKcf/aigp6zvjkDzEYhI6XvyyTAHQ7Wjjw5/YFu2DE//zJ8fxlEaNy70P+jfH268EfbdN+z/m9+EBuGpU8MTTHHeUUBoiJ4SPTdz4IGh01zt6UC33BIuvDBMDtSuXRj2Iya6IxCR9JozJ1Tb1H5U9IgjwlhLAMceG6qckjZ8ONxyS6M/rjYCEZG69O5dd3+B++8PTyntskuo/6+qqpkMRo1qvhir3Xpr6H8RAyUCEZHaWreGiRMzQ2IPHBjmZj7yyDDj2llnhak7KyrgvfdClVK26mEuCm3s2FgOqzYCEZF8tG0b5mmoNmZMeFWrrmafPTuMjtqpU2iTeOKJ8E1+1qwwxwPA974X6vwffHDtYpgxoylXkJPuCERECql6iOzLL4e33gpDWOywQ7ijcA+vv/0tJBX3MIXnkiU1J/45Pmv8TffQoAw1G8QLSHcEIiJJqh5Ic/x4+PWvw13DVluFJ4aqZ2176CGYPDm0WcRATw2JiKSAnhoSEZGclAhERFJOiUBEJOWUCEREUk6JQEQk5ZQIRERSTolARCTllAhERFKu5DqUmdkiYE4jP94ViGf4vuKla04HXXM6NOWae7t7t7o2lFwiaAozq8rVs65c6ZrTQdecDnFds6qGRERSTolARCTl0pYIRicdQAJ0zemga06HWK45VW0EIiKyprTdEYiISC1KBCIiKZeaRGBmg81smplNN7OLko6nkMxstpm9Y2ZvmllVVNbZzP5pZu9H752y9r84+jlMM7MDkos8f2Y2xswWmtnkrLK1vkYzGxj9rKab2Q1mZs19LfnIcb1XmNmH0e/5TTP7Xta2kr5eADPraWbPmdm7ZjbFzM6Oysv595zrmpv3d+3uZf8CKoAZwKZAa+AtoH/ScRXw+mYDXWuVXQtcFC1fBFwTLfePrr8N0Df6uVQkfQ15XOOewI7A5KZcIzAR2BUw4EngwKSvbS2u9wrg53XsW/LXG8W6MbBjtNwBeC+6tnL+Pee65mb9XafljmAnYLq7z3T3r4EHgCEJxxS3IcDd0fLdwA+zyh9w9xXuPguYTvj5FDV3fwFYUqt4ra7RzDYG1nP3Vzz8z7kn6zNFJcf15lLy1wvg7gvc/fVo+UvgXaA75f17znXNucRyzWlJBN2BD7LW51H/D7vUOPAPM5tkZsOisg3dfQGEf2zABlF5Of0s1vYau0fLtctLyRlm9nZUdVRdRVJ212tmfYAdgH+Tkt9zrWuGZvxdpyUR1FVXVk7Pze7u7jsCBwKnm9me9exb7j8LyH2NpX7ttwCbAdsDC4DfR+Vldb1m1h54GDjH3b+ob9c6ykryuuu45mb9XaclEcwDemat9wDmJxRLwbn7/Oh9IfAIoarn4+h2keh9YbR7Of0s1vYa50XLtctLgrt/7O6r3H01cBuZKr2yuV4za0X4g3i/u4+Lisv691zXNTf37zotieA1oJ+Z9TWz1sBRwPiEYyoIM1vXzDpULwP7A5MJ1/fjaLcfA49Fy+OBo8ysjZn1BfoRGplK0VpdY1St8KWZ7RI9UXF81meKXvUfw8ghhN8zlMn1RjHeAbzr7tdlbSrb33Oua27233XSrebN9QK+R2iRnwFcmnQ8BbyuTQlPEbwFTKm+NqAL8CzwfvTeOeszl0Y/h2kU6dMUdVznWMIt8jeEbz8nNeYagcroP9UM4Cai3vXF9spxvfcC7wBvR38QNi6X641i3YNQnfE28Gb0+l6Z/55zXXOz/q41xISISMqlpWpIRERyUCIQEUk5JQIRkZRTIhARSTklAhGRlFMiEImY2aqs0R7ftAKOUmtmfbJHEhUpJi2TDkCkiPzX3bdPOgiR5qY7ApEGWJjv4Rozmxi9No/Ke5vZs9HAYM+aWa+ofEMze8TM3opeu0WHqjCz26Jx5/9hZu2i/c8ys6nRcR5I6DIlxZQIRDLa1aoaOjJr2xfuvhOhx+b1UdlNwD3uPgC4H7ghKr8BmODu2xHmFJgSlfcDbnb3rYHPgMOi8ouAHaLjDI/n0kRyU89ikYiZLXX39nWUzwa+4+4zowHCPnL3Lmb2CaHr/zdR+QJ372pmi4Ae7r4i6xh9gH+6e79o/UKglbtfZWZPAUuBR4FH3X1pzJcqUoPuCETy4zmWc+1TlxVZy6vItNEdBNwMDAQmmZna7qRZKRGI5OfIrPdXouWXCSPZAhwLvBgtPwucCmBmFWa2Xq6DmlkLoKe7PwdcAKwPrHFXIhInffMQyWhnZm9mrT/l7tWPkLYxs38TvjwdHZWdBYwxs/OBRcAJUfnZwGgzO4nwzf9UwkiidakA7jOzjoTJRf7g7p8V6HpE8qI2ApEGRG0Ele7+SdKxiMRBVUMiIimnOwIRkZTTHYGISMopEYiIpJwSgYhIyikRiIiknBKBiEjK/T8QXikUAI9QEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Training Process')\n",
    "plt.plot(range(len(loss_trains)), loss_trains, color='r')\n",
    "# plt.plot(range(len(loss_trains)), loss_trains, color='r')\n",
    "plt.ylabel('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig('training_loss.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd7bcef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0., len(loss_trains), 1)\n",
    "y1 = loss_trains\n",
    "y2 = acc_trains\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x, y1, 'b', label='Loss')\n",
    "ax1.set_ylabel('Training Loss')\n",
    "ax1.set_title(\"Train Process\")\n",
    "\n",
    "ax2 = ax1.twinx()  # this is the important function\n",
    "ax2.plot(x, y2, 'r', label='Accuracy')\n",
    "ax2.set_xlim([0, len(loss_trains)])\n",
    "ax2.set_ylabel('Training Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax1.legend(loc='lower right')\n",
    "ax2.legend(loc='lower left')\n",
    "plt.savefig('Training Process.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb8bc5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0., len(loss_vals), 1)\n",
    "y1 = loss_vals\n",
    "y2 = acc_vals\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x, y1, 'b', label='Loss')\n",
    "ax1.set_ylabel('Validation Loss')\n",
    "ax1.set_title(\"Validations\")\n",
    "\n",
    "ax2 = ax1.twinx()  # this is the important function\n",
    "ax2.plot(x, y2, 'r', label='Accuracy')\n",
    "ax2.set_xlim([0, len(loss_trains)])\n",
    "ax2.set_ylabel('Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax1.legend(loc='lower right')\n",
    "ax2.legend(loc='lower left')\n",
    "plt.savefig('Validations.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f5e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ida",
   "language": "python",
   "name": "ida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
